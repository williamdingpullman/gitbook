# Linear Mixed Models
Assume that $y$ is a function of $x$ and $u$, where $x$ is the fixed effect and $u$ is the random effect. Thus, we can get,

$$y|x, u = x'\beta+z'u+\epsilon$$

FOr random effect,one example can be that you want to test the treatment effect, and sample 8 observations from 4 groups. You measure before and after the treatment. In this case, $x$ represents the treatment effect, whereas $z$ represents the group effect (i.e., random effect). Note that, in this case, it reminds the paired t-test. Remember in SPSS, why do we do paired t-test? Typically, it is the case when we measure a subject (or, participant) twice. In this case, we can consider each participant as an unit of random effect (rather than as group in the last example.)


The following code generates 4 numbers ($N(0,10)$) for 4 groups. Then, replicate it within each group.That is, in the end, there are 8 observations. 

Note that, in the following code, there are no "independent variables". Both the linear model and mixed model are actually just trying to calculate the mean. 

```{R}
set.seed(123)
n.groups <- 4 # number of groups
n.repeats <- 2 # samples per group
#Generating index for observations belong to the same group
groups <- as.factor(rep(1:n.groups, each=n.repeats))
n <- length(groups)
#Generating 4 random numbers, assuming normal distribution
z0 <- rnorm(n.groups, 0, 10) 
z <- z0[as.numeric(groups)] # generate and inspect random group effects
z
```


```{R}
epsilon <- rnorm(n,0,1) # generate measurement error
beta0 <- 2 # this is the actual parameter of interest! The global mean.
y <- beta0 + z + epsilon # sample from an LMM

# fit a linear model assuming independence
# i.e., assume that there is no "group things".
lm.5 <- lm(y~1)

# fit a mixed-model that deals with the group dependence
#install.packages("lme4")
library(lme4)
lme.5 <- lmer(y~1|groups) 

summary(lm.5)
summary(lme.5)
```
