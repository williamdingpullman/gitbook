<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Linear Mixed Models | GLMM, Concepts, &amp; R</title>
  <meta name="description" content="The webpages are mainly about logit models." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Linear Mixed Models | GLMM, Concepts, &amp; R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The webpages are mainly about logit models." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Linear Mixed Models | GLMM, Concepts, &amp; R" />
  
  <meta name="twitter:description" content="The webpages are mainly about logit models." />
  

<meta name="author" content="Bill Last Updated:" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="intro.html"/>
<link rel="next" href="basic-stat-concepts.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bill's Stat Project</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface: Motivation</a></li>
<li class="chapter" data-level="1" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>1</b> Basics</a><ul>
<li class="chapter" data-level="1.1" data-path="basics.html"><a href="basics.html#logit"><i class="fa fa-check"></i><b>1.1</b> Logit</a></li>
<li class="chapter" data-level="1.2" data-path="basics.html"><a href="basics.html#probit"><i class="fa fa-check"></i><b>1.2</b> Probit</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> MLE</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#basic-idea-of-mle"><i class="fa fa-check"></i><b>2.1</b> Basic idea of MLE</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#coin-flip-example-probit-and-logit"><i class="fa fa-check"></i><b>2.2</b> Coin flip example, probit, and logit</a><ul>
<li class="chapter" data-level="2.2.1" data-path="intro.html"><a href="intro.html#probit-1"><i class="fa fa-check"></i><b>2.2.1</b> Probit</a></li>
<li class="chapter" data-level="2.2.2" data-path="intro.html"><a href="intro.html#logit-1"><i class="fa fa-check"></i><b>2.2.2</b> Logit</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#further-on-logit"><i class="fa fa-check"></i><b>2.3</b> Further on logit</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#references"><i class="fa fa-check"></i><b>2.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html"><i class="fa fa-check"></i><b>3</b> Linear Mixed Models</a><ul>
<li class="chapter" data-level="3.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#lm-and-glm"><i class="fa fa-check"></i><b>3.1</b> LM and GLM</a><ul>
<li class="chapter" data-level="3.1.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#lm"><i class="fa fa-check"></i><b>3.1.1</b> LM</a></li>
<li class="chapter" data-level="3.1.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#glm"><i class="fa fa-check"></i><b>3.1.2</b> GLM</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#lmm"><i class="fa fa-check"></i><b>3.2</b> LMM</a></li>
<li class="chapter" data-level="3.3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#calculate-mean"><i class="fa fa-check"></i><b>3.3</b> Calculate mean</a></li>
<li class="chapter" data-level="3.4" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#test-the-treatment-effect"><i class="fa fa-check"></i><b>3.4</b> Test the treatment effect</a></li>
<li class="chapter" data-level="3.5" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#another-example"><i class="fa fa-check"></i><b>3.5</b> Another example</a></li>
<li class="chapter" data-level="3.6" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#full-lmm-model"><i class="fa fa-check"></i><b>3.6</b> Full LMM model</a></li>
<li class="chapter" data-level="3.7" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#serial-correlations-in-time-and-space"><i class="fa fa-check"></i><b>3.7</b> Serial correlations in time and space</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html"><i class="fa fa-check"></i><b>4</b> Basic Stat Concepts</a><ul>
<li class="chapter" data-level="4.1" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#score"><i class="fa fa-check"></i><b>4.1</b> Score</a></li>
<li class="chapter" data-level="4.2" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#gradient-and-jacobian"><i class="fa fa-check"></i><b>4.2</b> Gradient and Jacobian</a></li>
<li class="chapter" data-level="4.3" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#hessian-and-fisher-information"><i class="fa fa-check"></i><b>4.3</b> Hessian and Fisher Information</a></li>
<li class="chapter" data-level="4.4" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#canonical-link-function"><i class="fa fa-check"></i><b>4.4</b> Canonical link function</a></li>
<li class="chapter" data-level="4.5" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#ordinary-least-squares-ols"><i class="fa fa-check"></i><b>4.5</b> Ordinary Least Squares (OLS)</a></li>
<li class="chapter" data-level="4.6" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#taylor-series"><i class="fa fa-check"></i><b>4.6</b> Taylor series</a></li>
<li class="chapter" data-level="4.7" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#fisher-scoring"><i class="fa fa-check"></i><b>4.7</b> Fisher scoring</a></li>
<li class="chapter" data-level="4.8" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#references-1"><i class="fa fa-check"></i><b>4.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="basic-r.html"><a href="basic-r.html"><i class="fa fa-check"></i><b>5</b> Basic R</a><ul>
<li class="chapter" data-level="5.1" data-path="basic-r.html"><a href="basic-r.html#apply-lapply-sapply"><i class="fa fa-check"></i><b>5.1</b> apply, lapply, sapply</a><ul>
<li class="chapter" data-level="5.1.1" data-path="basic-r.html"><a href="basic-r.html#apply"><i class="fa fa-check"></i><b>5.1.1</b> apply</a></li>
<li class="chapter" data-level="5.1.2" data-path="basic-r.html"><a href="basic-r.html#lapply"><i class="fa fa-check"></i><b>5.1.2</b> lapply</a></li>
<li class="chapter" data-level="5.1.3" data-path="basic-r.html"><a href="basic-r.html#sapply"><i class="fa fa-check"></i><b>5.1.3</b> sapply</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="basic-r.html"><a href="basic-r.html#c"><i class="fa fa-check"></i><b>5.2</b> C</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="computing-techniques.html"><a href="computing-techniques.html"><i class="fa fa-check"></i><b>6</b> Computing Techniques</a><ul>
<li class="chapter" data-level="6.1" data-path="computing-techniques.html"><a href="computing-techniques.html#monte-carlo-approximation"><i class="fa fa-check"></i><b>6.1</b> Monte carlo approximation</a></li>
<li class="chapter" data-level="6.2" data-path="computing-techniques.html"><a href="computing-techniques.html#importance-sampling"><i class="fa fa-check"></i><b>6.2</b> Importance sampling</a></li>
<li class="chapter" data-level="6.3" data-path="computing-techniques.html"><a href="computing-techniques.html#newton-raphson-algorithm"><i class="fa fa-check"></i><b>6.3</b> Newton Raphson algorithm</a><ul>
<li class="chapter" data-level="6.3.1" data-path="computing-techniques.html"><a href="computing-techniques.html#calculate-the-root"><i class="fa fa-check"></i><b>6.3.1</b> Calculate the root</a></li>
<li class="chapter" data-level="6.3.2" data-path="computing-techniques.html"><a href="computing-techniques.html#logistic-regression"><i class="fa fa-check"></i><b>6.3.2</b> Logistic regression</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="computing-techniques.html"><a href="computing-techniques.html#metropolis-hastings"><i class="fa fa-check"></i><b>6.4</b> Metropolis Hastings</a></li>
<li class="chapter" data-level="6.5" data-path="computing-techniques.html"><a href="computing-techniques.html#em"><i class="fa fa-check"></i><b>6.5</b> EM</a></li>
<li class="chapter" data-level="6.6" data-path="computing-techniques.html"><a href="computing-techniques.html#references-2"><i class="fa fa-check"></i><b>6.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html"><i class="fa fa-check"></i><b>7</b> Generalized Linear Mixed Models</a><ul>
<li class="chapter" data-level="7.1" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html#basics-of-glmm"><i class="fa fa-check"></i><b>7.1</b> Basics of GLMM</a></li>
<li class="chapter" data-level="7.2" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html#some-references"><i class="fa fa-check"></i><b>7.2</b> Some References</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="twitter-example.html"><a href="twitter-example.html"><i class="fa fa-check"></i><b>8</b> Twitter Example</a><ul>
<li class="chapter" data-level="8.1" data-path="twitter-example.html"><a href="twitter-example.html#model"><i class="fa fa-check"></i><b>8.1</b> Model</a></li>
<li class="chapter" data-level="8.2" data-path="twitter-example.html"><a href="twitter-example.html#simulating-data-of-senators-on-twitter"><i class="fa fa-check"></i><b>8.2</b> Simulating Data of Senators on Twitter</a></li>
<li class="chapter" data-level="8.3" data-path="twitter-example.html"><a href="twitter-example.html#simulating-data-of-conservative-users-on-twitter-and-model-testing"><i class="fa fa-check"></i><b>8.3</b> Simulating Data of Conservative Users on Twitter and Model Testing</a></li>
<li class="chapter" data-level="8.4" data-path="twitter-example.html"><a href="twitter-example.html#simulating-data-of-liberal-users-on-twitter-and-model-testing"><i class="fa fa-check"></i><b>8.4</b> Simulating Data of Liberal Users on Twitter and Model Testing</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="practice-learning-on-the-battle-field.html"><a href="practice-learning-on-the-battle-field.html"><i class="fa fa-check"></i><b>9</b> Practice: Learning on the Battle Field</a><ul>
<li class="chapter" data-level="9.1" data-path="practice-learning-on-the-battle-field.html"><a href="practice-learning-on-the-battle-field.html#r-code"><i class="fa fa-check"></i><b>9.1</b> R code</a></li>
<li class="chapter" data-level="9.2" data-path="practice-learning-on-the-battle-field.html"><a href="practice-learning-on-the-battle-field.html#references-3"><i class="fa fa-check"></i><b>9.2</b> References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="project-draft.html"><a href="project-draft.html"><i class="fa fa-check"></i><b>10</b> Project Draft</a><ul>
<li class="chapter" data-level="10.1" data-path="project-draft.html"><a href="project-draft.html#background"><i class="fa fa-check"></i><b>10.1</b> Background</a></li>
<li class="chapter" data-level="10.2" data-path="project-draft.html"><a href="project-draft.html#important-examples-with-r-code"><i class="fa fa-check"></i><b>10.2</b> Important Examples with R code</a></li>
<li class="chapter" data-level="10.3" data-path="project-draft.html"><a href="project-draft.html#references-4"><i class="fa fa-check"></i><b>10.3</b> References</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://www.williamsding.com/" target="blank">Bill's website</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">GLMM, Concepts, &amp; R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-mixed-models" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Linear Mixed Models</h1>
<div id="lm-and-glm" class="section level2">
<h2><span class="header-section-number">3.1</span> LM and GLM</h2>
<p>Before moving to LMM, I would like to review LM and GLM first.</p>
<div id="lm" class="section level3">
<h3><span class="header-section-number">3.1.1</span> LM</h3>
<p><span class="math display">\[Y|X \sim N(\mu(X),\sigma^2 I)\]</span></p>
<p><span class="math display">\[E(Y|X)=\mu(X)=X^T \beta\]</span></p>
<p>where,</p>
<p><span class="math inline">\(\mu(X): random component\)</span></p>
<p><span class="math inline">\(X^T \beta: covariates\)</span></p>
</div>
<div id="glm" class="section level3">
<h3><span class="header-section-number">3.1.2</span> GLM</h3>
<p>Ref: <a href="https://ocw.mit.edu/courses/mathematics/18-650-statistics-for-applications-fall-2016/lecture-slides/MIT18_650F16_GLM.pdf" class="uri">https://ocw.mit.edu/courses/mathematics/18-650-statistics-for-applications-fall-2016/lecture-slides/MIT18_650F16_GLM.pdf</a></p>
<p><span class="math display">\[Y \sim exponential family\]</span> Link function</p>
<p><span class="math display">\[g(\mu(X))=X^T \beta\]</span> Possion regression: <span class="math display">\[\mu_i = \gamma e^{\delta t_i}\]</span> Link function is log link, and it becomes: <span class="math display">\[log(\mu_i) = log(\gamma) + log(\delta t_i)=\beta_0+\beta_1 t_i\]</span> <span class="math display">\[\mu_i=\frac{\alpha x_i}{h+x_i}\]</span> Reciprocal link: <span class="math display">\[g(\mu_i)=\frac{1}{\mu_i}=\frac{1}{\alpha}+\frac{h}{\alpha}\frac{1}{x_i}=\beta_0+\beta_1 \frac{1}{x_i}\]</span> In a more general sense, for exponential family:</p>
<p><span class="math display">\[\begin{aligned} P_{\theta}(X)=P(X, \theta)&amp;= e^{\sum \eta_i(\theta)T_i(X)} C(\theta)h(x)\\ &amp;=e^{\sum \eta_i(\theta)T_i(X)} e^{-log(\frac{1}{c(\theta)})}h(x) \\ &amp;= e^{\sum \eta_i(\theta)T_i(X)-log(\frac{1}{c(\theta)})} h(x)  \\&amp;= e^{\sum \eta_i(\theta)T_i(X)-B(\theta)} h(x) \end{aligned}\]</span></p>
<p>For normal distributions, it belongs to exponential family.</p>
<p><span class="math display">\[\begin{aligned} P_{\theta}(X) &amp;= \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{1}{2}\frac{(x-\mu)^2}{\sigma^2}}\\ &amp;=e^{-\frac{1}{2}\frac{(x-\mu)^2}{\sigma^2}} e^{log(\frac{1}{\sigma\sqrt{2\pi}})} \\ &amp;= e^{-\frac{1}{2}\frac{(x-\mu)^2}{\sigma^2}-log (\sigma\sqrt{2\pi})} \\ &amp;= e^{-\frac{1}{2\sigma^2}x^2-\frac{1}{2\sigma^2} \mu^2+\frac{x\mu}{\sigma^2}-log(\sqrt{2\pi}\sigma)}\\ &amp;=e^{-\frac{1}{2\sigma^2}x^2+\frac{x\mu}{\sigma^2}-(\frac{1}{2\sigma^2} \mu^2+log(\sqrt{2\pi}\sigma))} \end{aligned}\]</span> Where,</p>
<p><span class="math inline">\(\eta_1 =-\frac{1}{2\sigma^2}\)</span> and <span class="math inline">\(T_1(x)=x^2\)</span></p>
<p><span class="math inline">\(\eta_2 =-\frac{\mu}{\sigma^2}\)</span> and <span class="math inline">\(T_2(x)=x\)</span></p>
<p><span class="math inline">\(B(\theta)=\frac{1}{2\sigma^2} \mu^2+log(\sqrt{2\pi}\sigma)\)</span></p>
<p><span class="math inline">\(h(x)=1\)</span></p>
<p>In the case above, <span class="math inline">\(\theta=(\mu, \sigma^2)\)</span>. If <span class="math inline">\(\sigma^2\)</span> is known, <span class="math inline">\(\theta=\mu\)</span>. In this case, we can rewrite the normal pdf as follows.</p>
<p><span class="math display">\[\begin{aligned} P_{\theta}(X) &amp;=e^{-\frac{1}{2\sigma^2}x^2-\frac{1}{2\sigma^2} \mu^2+\frac{x\mu}{\sigma^2}-log(\sqrt{2\pi}\sigma)}\\ &amp;=e^{\frac{x\mu}{\sigma^2}-\frac{1}{2\sigma^2} \mu^2}e^{-\frac{1}{2\sigma^2}x^2-log(\sqrt{2\pi}\sigma)} \end{aligned}\]</span> Where,</p>
<p><span class="math inline">\(\eta_1 =-\frac{\mu}{\sigma^2}\)</span> and <span class="math inline">\(T_1(x)=x\)</span></p>
<p><span class="math inline">\(B(\theta)=\frac{1}{2\sigma^2} \mu^2\)</span></p>
<p><span class="math inline">\(\begin{aligned} h(x) &amp;=e^{-\frac{1}{2\sigma^2}x^2-log(\sqrt{2\pi}\sigma)} \\&amp;=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}\frac{x^2}{\sigma^2}} \end{aligned}\)</span></p>
<p>Thus, we can see that <span class="math inline">\(h(x)\)</span> is a normal pdf <span class="math inline">\(\sim N(0, \sigma^2)\)</span>.</p>
<p>Another example, <span class="math inline">\(x\)</span> is descrete. For example, Bernoulli:</p>
<p><span class="math display">\[ \begin{aligned} &amp;= p^x(1-p)^{1-x}  \\ &amp;=e^{log(p^x(1-p)^{1-x})} \\ &amp;= e^{xlog(p)+(1-x)log(1-p)}\\ &amp;= e^{xlog(p)-xlog(1-p)+log(1-p)}\\ &amp;=e^{xlog(\frac{p}{1-p})+log(1-p)} \end{aligned}\]</span></p>
<p>Where,</p>
<p><span class="math inline">\(\eta_1 =log(\frac{p}{1-p})\)</span> and <span class="math inline">\(T_1(x)=x\)</span></p>
<p><span class="math inline">\(B(\theta)=log(\frac{1}{1-p})\)</span></p>
<p><span class="math inline">\(h(x) =1\)</span></p>
<p>Canonical exponential family:</p>
<p><span class="math display">\[f_{\theta}(x)=e^{\frac{x\theta-b(\theta)}{\phi}+c(x,\phi)}\]</span> where, <span class="math inline">\(b(.)\)</span> and <span class="math inline">\(c(.,.)\)</span> are known.</p>
<p>Again, use the normal pdf:</p>
<p><span class="math display">\[\begin{aligned} P_{\theta}(X) &amp;= \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{1}{2}\frac{(x-\mu)^2}{\sigma^2}}\\ &amp;=e^{-\frac{1}{2}\frac{(x-\mu)^2}{\sigma^2}} e^{log(\frac{1}{\sigma\sqrt{2\pi}})} \\ &amp;= e^{-\frac{1}{2}\frac{(x-\mu)^2}{\sigma^2}-log (\sigma\sqrt{2\pi})} \\ &amp;= e^{-\frac{1}{2\sigma^2}x^2-\frac{1}{2\sigma^2} \mu^2+\frac{x\mu}{\sigma^2}-log(\sqrt{2\pi}\sigma)}\\ &amp;= e^{\frac{x\mu}{\sigma^2}-\frac{\mu^2}{2\sigma^2}+(-\frac{1}{2\sigma^2}x^2-log(\sqrt{2\pi}\sigma)) } \\ &amp;=e^{\frac{x\mu-\frac{1}{2}\mu^2}{\sigma^2}+(-\frac{1}{2\sigma^2}x^2-log(\sqrt{2\pi}\sigma)) } \end{aligned}\]</span></p>
<p>Where (we assume <span class="math inline">\(\sigma^2\)</span> is known.),</p>
<p><span class="math inline">\(\theta=\mu\)</span></p>
<p><span class="math inline">\(\phi =\sigma^2\)</span></p>
<p><span class="math inline">\(b(\theta)=\frac{1}{2}\mu^2\)</span></p>
<p><span class="math inline">\(\begin{aligned} c(x, \phi) &amp;=-\frac{1}{2\sigma^2}x^2-log(\sqrt{2\pi}\sigma) \\ &amp;=-\frac{1}{2\sigma^2}x^2-\frac{1}{2}log(2\pi\sigma^2) \\ &amp;=-\frac{1}{2}(\frac{x^2}{\sigma^2}+log(2\pi\sigma^2)) \\ &amp;=-\frac{1}{2}(\frac{x^2}{\phi}+log(2\pi \phi)) \end{aligned}\)</span></p>
<p>Canonical exponential family:</p>
<p><span class="math display">\[f_{\theta}(x)=e^{\frac{x\theta-b(\theta)}{\phi}+c(x,\phi)}\]</span></p>
<p>log likelihood (only one observation) <span class="math display">\[log f_{\theta}(x)\]</span></p>
<p><span class="math display">\[\begin{aligned} E[\frac{\partial (logf_{\theta}(X))}{\partial \theta} ] &amp;=E[\frac{\frac{\partial f_{\theta}(X)}{\partial \theta}}{f_{\theta}(X)}] \\ &amp;= \int \frac{\frac{\partial f_{\theta}(X)}{\partial \theta}}{f_{\theta}(X)} f_{\theta}(X) dx  \\ &amp;= \int \frac{\partial f_{\theta}(X)}{\partial \theta} dx \\ &amp;= \frac{\partial}{\partial \theta} \int f_{\theta}(X)dx \\ &amp;= \frac{\partial 1}{\partial \theta} \\ &amp;=0  \end{aligned}\]</span> Second derivative</p>
<p><span class="math display">\[\begin{aligned} E[\frac{\partial^2 (logf_{\theta}(X))}{\partial \theta^2} ] &amp;=E[ \frac{\partial}{\partial \theta}(\frac{\frac{\partial f_{\theta}(X)}{\partial \theta}}{f_{\theta}(X)})] \\  
&amp;=E[\frac{\frac{\partial^2 f_{\theta}(X)}{\partial \theta^2}f_{\theta}(X)-(\frac{\partial f_{\theta}(X)}{\partial \theta})^2}{f^2_{\theta}(X)}] \\ &amp;= \int \frac{\frac{\partial^2 f_{\theta}(X)}{\partial \theta^2}f_{\theta}(X)-(\frac{\partial f_{\theta}(X)}{\partial \theta})^2}{f_{\theta}(X)}dx \\ &amp;=\int (\frac{\partial^2 f_{\theta}(X)}{\partial \theta^2} - \frac{(\frac{\partial f_{\theta}(X)}{\partial \theta})^2}{f_{\theta}(X)})dx  \\ 
&amp;= \int \frac{\partial^2 f_{\theta}(X)}{\partial \theta^2} dx -\int \frac{(\frac{\partial f_{\theta}(X)}{\partial \theta})^2}{f_{\theta}(X)}dx \\ 
&amp;=\frac{\partial^2}{\partial \theta^2}\int f_{\theta}(X) dx -\int \frac{(\frac{\partial f_{\theta}(X)}{\partial \theta})^2}{f_{\theta}(X)}dx \\ 
&amp;=0-\int \frac{(\frac{\partial f_{\theta}(X)}{\partial \theta})^2}{f_{\theta}(X)}dx \\
&amp;=0-\int \frac{(\frac{\partial f_{\theta}(X)}{\partial \theta})^2}{(f_{\theta}(X))^2}f_{\theta}(x)dx \\ &amp;= - E[(\frac{\frac{\partial f_{\theta}(X)}{\partial \theta}}{f_{\theta}(X)})^2]\\ &amp;= -E[(\frac{\partial (logf_{\theta}(X))}{\partial \theta})^2] \end{aligned}\]</span></p>
<p>Based on the first derivative, we can get:</p>
<p><span class="math display">\[log(f_{\theta}(X))=\frac{X\theta-b(\theta)}{\phi}+c(X,\phi)\]</span> <span class="math display">\[E[\frac{\partial (log(f_{\theta}(X)))}{\partial \theta}]= E[\frac{X-b^{&#39;}(\theta)}{\phi}]=\frac{E(X)-b^{&#39;}(\theta)}{\phi}=0\]</span> Thus, we can get that <span class="math inline">\(E(X)=b^{&#39;}(\theta)\)</span>.</p>
<p>For second derivative, from the calculation above, we know that,</p>
<p><span class="math display">\[\begin{aligned} E[\frac{\partial^2 (logf_{\theta}(X))}{\partial \theta^2}]&amp;=-E[(\frac{\partial (logf_{\theta}(X))}{\partial \theta})^2] \\ &amp;= -E[(\frac{X-b^{&#39;}(\theta)}{\phi})^2]\\ &amp;=-E[(\frac{X-E(X)}{\phi})^2] \\ &amp;= -\frac{Var(X)}{\phi^2}\end{aligned}\]</span> At the same time, <span class="math display">\[\begin{aligned} E[\frac{\partial^2 (logf_{\theta}(X))}{\partial \theta^2}]&amp;=E[\frac{\partial (\frac{X-b^{&#39;}(\theta)}{\phi})}{\partial \theta}] \\ &amp;= E[-\frac{b^{&#39;&#39;}(\theta)}{\phi}]\\ &amp;= - \frac{b^{&#39;&#39;}(\theta)}{\phi} \end{aligned}\]</span> Thus,</p>
<p><span class="math display">\[Var(X)=b^{&#39;&#39;}(\theta) \phi\]</span></p>
</div>
</div>
<div id="lmm" class="section level2">
<h2><span class="header-section-number">3.2</span> LMM</h2>
<p>The following is a shortened version of Jonathan Rosenblatt’s LMM tutorial. <a href="http://www.john-ros.com/Rcourse/lme.html" class="uri">http://www.john-ros.com/Rcourse/lme.html</a>.</p>
<p>In addition, another reference is from Douglas Bates’s R package document. <a href="https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf?fbclid=IwAR1nmmRP9A0BrhKdgBibNjM5acR_spTpXV8QlQGdmTWyQz3ZtV3LYn6kCbQ" class="uri">https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf?fbclid=IwAR1nmmRP9A0BrhKdgBibNjM5acR_spTpXV8QlQGdmTWyQz3ZtV3LYn6kCbQ</a></p>
<p>Assume that <span class="math inline">\(y\)</span> is a function of <span class="math inline">\(x\)</span> and <span class="math inline">\(u\)</span>, where <span class="math inline">\(x\)</span> is the fixed effect and <span class="math inline">\(u\)</span> is the random effect. Thus, we can get,</p>
<p><span class="math display">\[y|x, u = x&#39;\beta+z&#39;u+\epsilon\]</span></p>
<p>For random effect, one example can be that you want to test the treatment effect, and sample 8 observations from 4 groups. You measure before and after the treatment. In this case, <span class="math inline">\(x\)</span> represents the treatment effect, whereas <span class="math inline">\(z\)</span> represents the group effect (i.e., random effect). Note that, in this case, it reminds the paired t-test. Remember in SPSS, why do we do paired t-test? Typically, it is the case when we measure a subject (or, participant) twice. In this case, we can consider each participant as an unit of random effect (rather than as group in the last example.)</p>
</div>
<div id="calculate-mean" class="section level2">
<h2><span class="header-section-number">3.3</span> Calculate mean</h2>
<p>The following code generates 4 numbers (<span class="math inline">\(N(0,10)\)</span>) for 4 groups. Then, replicate it within each group.That is, in the end, there are 8 observations.</p>
<p>Note that, in the following code, there are no “independent variables”. Both the linear model and mixed model are actually just trying to calculate the mean. Note that lmer(y~1+1|groups) and lmer(y~1|groups) will generate the same results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">123</span>)
n.groups &lt;-<span class="st"> </span><span class="dv">4</span> <span class="co"># number of groups</span>
n.repeats &lt;-<span class="st"> </span><span class="dv">2</span> <span class="co"># samples per group</span>
<span class="co">#Generating index for observations belong to the same group</span>
groups &lt;-<span class="st"> </span><span class="kw">as.factor</span>(<span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>n.groups, <span class="dt">each=</span>n.repeats))
n &lt;-<span class="st"> </span><span class="kw">length</span>(groups)
<span class="co">#Generating 4 random numbers, assuming normal distribution</span>
z0 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n.groups, <span class="dv">0</span>, <span class="dv">10</span>) 
z &lt;-<span class="st"> </span>z0[<span class="kw">as.numeric</span>(groups)] <span class="co"># generate and inspect random group effects</span>
z</code></pre></div>
<pre><code>## [1] -5.6047565 -5.6047565 -2.3017749 -2.3017749 15.5870831 15.5870831  0.7050839
## [8]  0.7050839</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">epsilon &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">1</span>) <span class="co"># generate measurement error</span>
beta0 &lt;-<span class="st"> </span><span class="dv">2</span> <span class="co"># this is the actual parameter of interest! The global mean.</span>
y &lt;-<span class="st"> </span>beta0 <span class="op">+</span><span class="st"> </span>z <span class="op">+</span><span class="st"> </span>epsilon <span class="co"># sample from an LMM</span>

<span class="co"># fit a linear model assuming independence</span>
<span class="co"># i.e., assume that there is no &quot;group things&quot;.</span>
lm.<span class="dv">5</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(y<span class="op">~</span><span class="dv">1</span>)

<span class="co"># fit a mixed-model that deals with the group dependence</span>
<span class="co">#install.packages(&quot;lme4&quot;)</span>
<span class="kw">library</span>(lme4)</code></pre></div>
<pre><code>## Loading required package: Matrix</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lme.<span class="fl">5.</span>a &lt;-<span class="st"> </span><span class="kw">lmer</span>(y<span class="op">~</span><span class="dv">1</span><span class="op">+</span><span class="dv">1</span><span class="op">|</span>groups) 
lme.<span class="fl">5.</span>b &lt;-<span class="st"> </span><span class="kw">lmer</span>(y<span class="op">~</span><span class="dv">1</span><span class="op">|</span>groups) 
lm.<span class="dv">5</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ 1)
## 
## Coefficients:
## (Intercept)  
##       4.283</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lme.<span class="fl">5.</span>a </code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: y ~ 1 + 1 | groups
## REML criterion at convergence: 36.1666
## Random effects:
##  Groups   Name        Std.Dev.
##  groups   (Intercept) 8.8521  
##  Residual             0.8873  
## Number of obs: 8, groups:  groups, 4
## Fixed Effects:
## (Intercept)  
##       4.283</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lme.<span class="fl">5.</span>b </code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: y ~ 1 | groups
## REML criterion at convergence: 36.1666
## Random effects:
##  Groups   Name        Std.Dev.
##  groups   (Intercept) 8.8521  
##  Residual             0.8873  
## Number of obs: 8, groups:  groups, 4
## Fixed Effects:
## (Intercept)  
##       4.283</code></pre>
</div>
<div id="test-the-treatment-effect" class="section level2">
<h2><span class="header-section-number">3.4</span> Test the treatment effect</h2>
<p>As we can see that, LLM and paired t-test generate the same t-value.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">times&lt;-<span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>),<span class="dv">4</span>) <span class="co"># first time and second time</span>
times</code></pre></div>
<pre><code>## [1] 1 2 1 2 1 2 1 2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_combined&lt;-<span class="kw">cbind</span>(y,groups,times)
data_combined</code></pre></div>
<pre><code>##               y groups times
## [1,] -3.4754687      1     1
## [2,] -1.8896915      1     2
## [3,]  0.1591413      2     1
## [4,] -1.5668361      2     2
## [5,] 16.9002303      3     1
## [6,] 17.1414212      3     2
## [7,]  3.9291657      4     1
## [8,]  3.0648977      4     2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lme_diff_times&lt;-<span class="st"> </span><span class="kw">lmer</span>(y<span class="op">~</span>times<span class="op">+</span>(<span class="dv">1</span><span class="op">|</span>groups)) 


t_results&lt;-<span class="kw">t.test</span>(y<span class="op">~</span>times, <span class="dt">paired=</span><span class="ot">TRUE</span>)

lme_diff_times</code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: y ~ times + (1 | groups)
## REML criterion at convergence: 35.0539
## Random effects:
##  Groups   Name        Std.Dev.
##  groups   (Intercept) 8.845   
##  Residual             1.013   
## Number of obs: 8, groups:  groups, 4
## Fixed Effects:
## (Intercept)        times  
##      4.5691      -0.1908</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="st">&quot;The following results are from paired t-test&quot;</span>)</code></pre></div>
<pre><code>## [1] &quot;The following results are from paired t-test&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t_results<span class="op">$</span>statistic</code></pre></div>
<pre><code>##         t 
## 0.2664793</code></pre>
</div>
<div id="another-example" class="section level2">
<h2><span class="header-section-number">3.5</span> Another example</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(Dyestuff, <span class="dt">package=</span><span class="st">&#39;lme4&#39;</span>)
<span class="kw">attach</span>(Dyestuff)
Dyestuff</code></pre></div>
<pre><code>##    Batch Yield
## 1      A  1545
## 2      A  1440
## 3      A  1440
## 4      A  1520
## 5      A  1580
## 6      B  1540
## 7      B  1555
## 8      B  1490
## 9      B  1560
## 10     B  1495
## 11     C  1595
## 12     C  1550
## 13     C  1605
## 14     C  1510
## 15     C  1560
## 16     D  1445
## 17     D  1440
## 18     D  1595
## 19     D  1465
## 20     D  1545
## 21     E  1595
## 22     E  1630
## 23     E  1515
## 24     E  1635
## 25     E  1625
## 26     F  1520
## 27     F  1455
## 28     F  1450
## 29     F  1480
## 30     F  1445</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lme_batch&lt;-<span class="st"> </span><span class="kw">lmer</span>( Yield <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>Batch)  , Dyestuff )
<span class="kw">summary</span>(lme_batch)</code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: Yield ~ 1 + (1 | Batch)
##    Data: Dyestuff
## 
## REML criterion at convergence: 319.7
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -1.4117 -0.7634  0.1418  0.7792  1.8296 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  Batch    (Intercept) 1764     42.00   
##  Residual             2451     49.51   
## Number of obs: 30, groups:  Batch, 6
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  1527.50      19.38    78.8</code></pre>
</div>
<div id="full-lmm-model" class="section level2">
<h2><span class="header-section-number">3.6</span> Full LMM model</h2>
<p>In the following, I used the data from the package of lme4. For Days + (1 | Subject), it only has random intercept; in contrast, Days + ( Days| Subject ) has both random intercept and random slope for Days. Note that, random effects do not generate specific slopes for each level of Days, but rather just a variance of all the slopes.</p>
<p>Therefore, we can see that “Days + ( Days| Subject )” and “Days + ( 1+Days| Subject )” generate the same results. For more discussion, you can refer to the following link: <a href="https://www.jaredknowles.com/journal/2013/11/25/getting-started-with-mixed-effect-models-in-r" class="uri">https://www.jaredknowles.com/journal/2013/11/25/getting-started-with-mixed-effect-models-in-r</a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(sleepstudy, <span class="dt">package=</span><span class="st">&#39;lme4&#39;</span>)
<span class="kw">attach</span>(sleepstudy)

fm1 &lt;-<span class="st"> </span><span class="kw">lmer</span>(Reaction <span class="op">~</span><span class="st"> </span>Days <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>Subject), sleepstudy)
<span class="kw">summary</span>(fm1)</code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: Reaction ~ Days + (1 | Subject)
##    Data: sleepstudy
## 
## REML criterion at convergence: 1786.5
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.2257 -0.5529  0.0109  0.5188  4.2506 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  Subject  (Intercept) 1378.2   37.12   
##  Residual              960.5   30.99   
## Number of obs: 180, groups:  Subject, 18
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 251.4051     9.7467   25.79
## Days         10.4673     0.8042   13.02
## 
## Correlation of Fixed Effects:
##      (Intr)
## Days -0.371</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fm2&lt;-<span class="kw">lmer</span> ( Reaction <span class="op">~</span><span class="st"> </span>Days <span class="op">+</span><span class="st"> </span>( Days<span class="op">|</span><span class="st"> </span>Subject ) , <span class="dt">data=</span> sleepstudy )
<span class="kw">summary</span>(fm2)</code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: Reaction ~ Days + (Days | Subject)
##    Data: sleepstudy
## 
## REML criterion at convergence: 1743.6
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.9536 -0.4634  0.0231  0.4633  5.1793 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  Subject  (Intercept) 611.90   24.737       
##           Days         35.08    5.923   0.07
##  Residual             654.94   25.592       
## Number of obs: 180, groups:  Subject, 18
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  251.405      6.824  36.843
## Days          10.467      1.546   6.771
## 
## Correlation of Fixed Effects:
##      (Intr)
## Days -0.138</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fm3&lt;-<span class="kw">lmer</span> ( Reaction <span class="op">~</span><span class="st"> </span>Days <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">+</span>Days<span class="op">|</span><span class="st"> </span>Subject ) , <span class="dt">data=</span> sleepstudy )
<span class="kw">summary</span>(fm3)</code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: Reaction ~ Days + (1 + Days | Subject)
##    Data: sleepstudy
## 
## REML criterion at convergence: 1743.6
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.9536 -0.4634  0.0231  0.4633  5.1793 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  Subject  (Intercept) 611.90   24.737       
##           Days         35.08    5.923   0.07
##  Residual             654.94   25.592       
## Number of obs: 180, groups:  Subject, 18
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  251.405      6.824  36.843
## Days          10.467      1.546   6.771
## 
## Correlation of Fixed Effects:
##      (Intr)
## Days -0.138</code></pre>
</div>
<div id="serial-correlations-in-time-and-space" class="section level2">
<h2><span class="header-section-number">3.7</span> Serial correlations in time and space</h2>
<p>The hierarchical model of <span class="math inline">\(y|x, u = x&#39;\beta+z&#39;u+\epsilon\)</span> can work well for correlations within blocks, but not for correlations in time as the correlations decay in time. The following uses nlme package to calculate time serial data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(nlme)</code></pre></div>
<pre><code>## 
## Attaching package: &#39;nlme&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:lme4&#39;:
## 
##     lmList</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(nlme<span class="op">::</span>Ovary,<span class="dt">n=</span><span class="dv">50</span>)</code></pre></div>
<pre><code>## Grouped Data: follicles ~ Time | Mare
##    Mare        Time follicles
## 1     1 -0.13636360        20
## 2     1 -0.09090910        15
## 3     1 -0.04545455        19
## 4     1  0.00000000        16
## 5     1  0.04545455        13
## 6     1  0.09090910        10
## 7     1  0.13636360        12
## 8     1  0.18181820        14
## 9     1  0.22727270        13
## 10    1  0.27272730        20
## 11    1  0.31818180        22
## 12    1  0.36363640        15
## 13    1  0.40909090        18
## 14    1  0.45454550        17
## 15    1  0.50000000        14
## 16    1  0.54545450        18
## 17    1  0.59090910        14
## 18    1  0.63636360        16
## 19    1  0.68181820        17
## 20    1  0.72727270        18
## 21    1  0.77272730        18
## 22    1  0.81818180        17
## 23    1  0.86363640        14
## 24    1  0.90909090        12
## 25    1  0.95454550        12
## 26    1  1.00000000        14
## 27    1  1.04545500        10
## 28    1  1.09090900        11
## 29    1  1.13636400        16
## 30    2 -0.15000000         6
## 31    2 -0.10000000         6
## 32    2 -0.05000000         8
## 33    2  0.00000000         7
## 34    2  0.05000000        16
## 35    2  0.10000000        10
## 36    2  0.15000000        13
## 37    2  0.20000000         9
## 38    2  0.25000000         7
## 39    2  0.30000000         6
## 40    2  0.35000000         8
## 41    2  0.40000000         8
## 42    2  0.45000000         6
## 43    2  0.50000000         8
## 44    2  0.55000000         7
## 45    2  0.60000000         9
## 46    2  0.65000000         6
## 47    2  0.70000000         4
## 48    2  0.75000000         5
## 49    2  0.80000000         8
## 50    2  0.85000000        11</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fm1Ovar.lme &lt;-<span class="st"> </span>nlme<span class="op">::</span><span class="kw">lme</span>(<span class="dt">fixed=</span>follicles <span class="op">~</span><span class="st"> </span><span class="kw">sin</span>(<span class="dv">2</span><span class="op">*</span>pi<span class="op">*</span>Time) <span class="op">+</span><span class="st"> </span><span class="kw">cos</span>(<span class="dv">2</span><span class="op">*</span>pi<span class="op">*</span>Time), 
                   <span class="dt">data =</span> Ovary, 
                   <span class="dt">random =</span> <span class="kw">pdDiag</span>(<span class="op">~</span><span class="kw">sin</span>(<span class="dv">2</span><span class="op">*</span>pi<span class="op">*</span>Time)), 
                   <span class="dt">correlation=</span><span class="kw">corAR1</span>() )
<span class="kw">summary</span>(fm1Ovar.lme)</code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: Ovary 
##        AIC     BIC   logLik
##   1563.448 1589.49 -774.724
## 
## Random effects:
##  Formula: ~sin(2 * pi * Time) | Mare
##  Structure: Diagonal
##         (Intercept) sin(2 * pi * Time) Residual
## StdDev:    2.858385           1.257977 3.507053
## 
## Correlation Structure: AR(1)
##  Formula: ~1 | Mare 
##  Parameter estimate(s):
##       Phi 
## 0.5721866 
## Fixed effects: follicles ~ sin(2 * pi * Time) + cos(2 * pi * Time) 
##                        Value Std.Error  DF   t-value p-value
## (Intercept)        12.188089 0.9436602 295 12.915760  0.0000
## sin(2 * pi * Time) -2.985297 0.6055968 295 -4.929513  0.0000
## cos(2 * pi * Time) -0.877762 0.4777821 295 -1.837159  0.0672
##  Correlation: 
##                    (Intr) s(*p*T
## sin(2 * pi * Time)  0.000       
## cos(2 * pi * Time) -0.123  0.000
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -2.34910093 -0.58969626 -0.04577893  0.52931186  3.37167486 
## 
## Number of Observations: 308
## Number of Groups: 11</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="basic-stat-concepts.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/07-lmm.rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
