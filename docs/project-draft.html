<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Project Draft | GLMM, Concepts, &amp; R</title>
  <meta name="description" content="The webpages are mainly about logit models." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Project Draft | GLMM, Concepts, &amp; R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The webpages are mainly about logit models." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Project Draft | GLMM, Concepts, &amp; R" />
  
  <meta name="twitter:description" content="The webpages are mainly about logit models." />
  

<meta name="author" content="Bill Last Updated:" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="practice-learning-on-the-battle-field.html"/>
<link rel="next" href="bayesian.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bill's Stat Project</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface: Motivation</a></li>
<li class="chapter" data-level="1" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>1</b> Basics</a><ul>
<li class="chapter" data-level="1.1" data-path="basics.html"><a href="basics.html#logit"><i class="fa fa-check"></i><b>1.1</b> Logit</a></li>
<li class="chapter" data-level="1.2" data-path="basics.html"><a href="basics.html#probit"><i class="fa fa-check"></i><b>1.2</b> Probit</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> MLE</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#basic-idea-of-mle"><i class="fa fa-check"></i><b>2.1</b> Basic idea of MLE</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#coin-flip-example-probit-and-logit"><i class="fa fa-check"></i><b>2.2</b> Coin flip example, probit, and logit</a><ul>
<li class="chapter" data-level="2.2.1" data-path="intro.html"><a href="intro.html#probit-1"><i class="fa fa-check"></i><b>2.2.1</b> Probit</a></li>
<li class="chapter" data-level="2.2.2" data-path="intro.html"><a href="intro.html#logit-1"><i class="fa fa-check"></i><b>2.2.2</b> Logit</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#further-on-logit"><i class="fa fa-check"></i><b>2.3</b> Further on logit</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#references"><i class="fa fa-check"></i><b>2.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html"><i class="fa fa-check"></i><b>3</b> Linear Mixed Models</a><ul>
<li class="chapter" data-level="3.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#lm-and-glm"><i class="fa fa-check"></i><b>3.1</b> LM and GLM</a><ul>
<li class="chapter" data-level="3.1.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#lm"><i class="fa fa-check"></i><b>3.1.1</b> LM</a></li>
<li class="chapter" data-level="3.1.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#glm-definition"><i class="fa fa-check"></i><b>3.1.2</b> GLM-Definition</a></li>
<li class="chapter" data-level="3.1.3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#glm-log-link-example"><i class="fa fa-check"></i><b>3.1.3</b> GLM-log link example</a></li>
<li class="chapter" data-level="3.1.4" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#glm-reciprocal-link"><i class="fa fa-check"></i><b>3.1.4</b> GLM-Reciprocal link:</a></li>
<li class="chapter" data-level="3.1.5" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#glm-exponential-family"><i class="fa fa-check"></i><b>3.1.5</b> GLM-exponential family:</a></li>
<li class="chapter" data-level="3.1.6" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#canonical-exponential-family"><i class="fa fa-check"></i><b>3.1.6</b> Canonical exponential family</a></li>
<li class="chapter" data-level="3.1.7" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#canonical-exponential-family---expected-value-and-variance"><i class="fa fa-check"></i><b>3.1.7</b> Canonical exponential family - Expected value and variance</a></li>
<li class="chapter" data-level="3.1.8" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#expected-value-and-variance---possion-example"><i class="fa fa-check"></i><b>3.1.8</b> Expected value and variance - Possion Example</a></li>
<li class="chapter" data-level="3.1.9" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#canonical-link"><i class="fa fa-check"></i><b>3.1.9</b> Canonical link</a></li>
<li class="chapter" data-level="3.1.10" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#canonical-link---bernoulli"><i class="fa fa-check"></i><b>3.1.10</b> Canonical link - Bernoulli</a></li>
<li class="chapter" data-level="3.1.11" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#nr---bernoulli"><i class="fa fa-check"></i><b>3.1.11</b> NR - Bernoulli</a></li>
<li class="chapter" data-level="3.1.12" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#iteratively-re-weighted-least-squares"><i class="fa fa-check"></i><b>3.1.12</b> Iteratively Re-weighted Least Squares</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#lmm"><i class="fa fa-check"></i><b>3.2</b> LMM</a></li>
<li class="chapter" data-level="3.3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#calculate-mean"><i class="fa fa-check"></i><b>3.3</b> Calculate mean</a></li>
<li class="chapter" data-level="3.4" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#test-the-treatment-effect"><i class="fa fa-check"></i><b>3.4</b> Test the treatment effect</a></li>
<li class="chapter" data-level="3.5" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#another-example"><i class="fa fa-check"></i><b>3.5</b> Another example</a></li>
<li class="chapter" data-level="3.6" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#full-lmm-model"><i class="fa fa-check"></i><b>3.6</b> Full LMM model</a></li>
<li class="chapter" data-level="3.7" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#serial-correlations-in-time-and-space"><i class="fa fa-check"></i><b>3.7</b> Serial correlations in time and space</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html"><i class="fa fa-check"></i><b>4</b> Basic Stat Concepts</a><ul>
<li class="chapter" data-level="4.1" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#score"><i class="fa fa-check"></i><b>4.1</b> Score</a></li>
<li class="chapter" data-level="4.2" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#gradient-and-jacobian"><i class="fa fa-check"></i><b>4.2</b> Gradient and Jacobian</a></li>
<li class="chapter" data-level="4.3" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#hessian-and-fisher-information"><i class="fa fa-check"></i><b>4.3</b> Hessian and Fisher Information</a></li>
<li class="chapter" data-level="4.4" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#canonical-link-function"><i class="fa fa-check"></i><b>4.4</b> Canonical link function</a></li>
<li class="chapter" data-level="4.5" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#ordinary-least-squares-ols"><i class="fa fa-check"></i><b>4.5</b> Ordinary Least Squares (OLS)</a></li>
<li class="chapter" data-level="4.6" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#taylor-series"><i class="fa fa-check"></i><b>4.6</b> Taylor series</a></li>
<li class="chapter" data-level="4.7" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#fisher-scoring"><i class="fa fa-check"></i><b>4.7</b> Fisher scoring</a></li>
<li class="chapter" data-level="4.8" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#references-1"><i class="fa fa-check"></i><b>4.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="basic-r.html"><a href="basic-r.html"><i class="fa fa-check"></i><b>5</b> Basic R</a><ul>
<li class="chapter" data-level="5.1" data-path="basic-r.html"><a href="basic-r.html#apply-lapply-sapply"><i class="fa fa-check"></i><b>5.1</b> apply, lapply, sapply</a><ul>
<li class="chapter" data-level="5.1.1" data-path="basic-r.html"><a href="basic-r.html#apply"><i class="fa fa-check"></i><b>5.1.1</b> apply</a></li>
<li class="chapter" data-level="5.1.2" data-path="basic-r.html"><a href="basic-r.html#lapply"><i class="fa fa-check"></i><b>5.1.2</b> lapply</a></li>
<li class="chapter" data-level="5.1.3" data-path="basic-r.html"><a href="basic-r.html#sapply"><i class="fa fa-check"></i><b>5.1.3</b> sapply</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="basic-r.html"><a href="basic-r.html#c"><i class="fa fa-check"></i><b>5.2</b> C</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="computing-techniques.html"><a href="computing-techniques.html"><i class="fa fa-check"></i><b>6</b> Computing Techniques</a><ul>
<li class="chapter" data-level="6.1" data-path="computing-techniques.html"><a href="computing-techniques.html#monte-carlo-approximation"><i class="fa fa-check"></i><b>6.1</b> Monte carlo approximation</a></li>
<li class="chapter" data-level="6.2" data-path="computing-techniques.html"><a href="computing-techniques.html#importance-sampling"><i class="fa fa-check"></i><b>6.2</b> Importance sampling</a></li>
<li class="chapter" data-level="6.3" data-path="computing-techniques.html"><a href="computing-techniques.html#newton-raphson-algorithm"><i class="fa fa-check"></i><b>6.3</b> Newton Raphson algorithm</a><ul>
<li class="chapter" data-level="6.3.1" data-path="computing-techniques.html"><a href="computing-techniques.html#calculate-the-root"><i class="fa fa-check"></i><b>6.3.1</b> Calculate the root</a></li>
<li class="chapter" data-level="6.3.2" data-path="computing-techniques.html"><a href="computing-techniques.html#logistic-regression"><i class="fa fa-check"></i><b>6.3.2</b> Logistic regression</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="computing-techniques.html"><a href="computing-techniques.html#metropolis-hastings"><i class="fa fa-check"></i><b>6.4</b> Metropolis Hastings</a></li>
<li class="chapter" data-level="6.5" data-path="computing-techniques.html"><a href="computing-techniques.html#em"><i class="fa fa-check"></i><b>6.5</b> EM</a></li>
<li class="chapter" data-level="6.6" data-path="computing-techniques.html"><a href="computing-techniques.html#references-2"><i class="fa fa-check"></i><b>6.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html"><i class="fa fa-check"></i><b>7</b> Generalized Linear Mixed Models</a><ul>
<li class="chapter" data-level="7.1" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html#basics-of-glmm"><i class="fa fa-check"></i><b>7.1</b> Basics of GLMM</a></li>
<li class="chapter" data-level="7.2" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html#some-references"><i class="fa fa-check"></i><b>7.2</b> Some References</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="twitter-example.html"><a href="twitter-example.html"><i class="fa fa-check"></i><b>8</b> Twitter Example</a><ul>
<li class="chapter" data-level="8.1" data-path="twitter-example.html"><a href="twitter-example.html#model"><i class="fa fa-check"></i><b>8.1</b> Model</a></li>
<li class="chapter" data-level="8.2" data-path="twitter-example.html"><a href="twitter-example.html#simulating-data-of-senators-on-twitter"><i class="fa fa-check"></i><b>8.2</b> Simulating Data of Senators on Twitter</a></li>
<li class="chapter" data-level="8.3" data-path="twitter-example.html"><a href="twitter-example.html#simulating-data-of-conservative-users-on-twitter-and-model-testing"><i class="fa fa-check"></i><b>8.3</b> Simulating Data of Conservative Users on Twitter and Model Testing</a></li>
<li class="chapter" data-level="8.4" data-path="twitter-example.html"><a href="twitter-example.html#simulating-data-of-liberal-users-on-twitter-and-model-testing"><i class="fa fa-check"></i><b>8.4</b> Simulating Data of Liberal Users on Twitter and Model Testing</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="practice-learning-on-the-battle-field.html"><a href="practice-learning-on-the-battle-field.html"><i class="fa fa-check"></i><b>9</b> Practice: Learning on the Battle Field</a><ul>
<li class="chapter" data-level="9.1" data-path="practice-learning-on-the-battle-field.html"><a href="practice-learning-on-the-battle-field.html#r-code"><i class="fa fa-check"></i><b>9.1</b> R code</a></li>
<li class="chapter" data-level="9.2" data-path="practice-learning-on-the-battle-field.html"><a href="practice-learning-on-the-battle-field.html#references-3"><i class="fa fa-check"></i><b>9.2</b> References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="project-draft.html"><a href="project-draft.html"><i class="fa fa-check"></i><b>10</b> Project Draft</a><ul>
<li class="chapter" data-level="10.1" data-path="project-draft.html"><a href="project-draft.html#background"><i class="fa fa-check"></i><b>10.1</b> Background</a></li>
<li class="chapter" data-level="10.2" data-path="project-draft.html"><a href="project-draft.html#important-examples-with-r-code"><i class="fa fa-check"></i><b>10.2</b> Important Examples with R code</a></li>
<li class="chapter" data-level="10.3" data-path="project-draft.html"><a href="project-draft.html#references-4"><i class="fa fa-check"></i><b>10.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="bayesian.html"><a href="bayesian.html"><i class="fa fa-check"></i><b>11</b> Bayesian</a><ul>
<li class="chapter" data-level="11.1" data-path="bayesian.html"><a href="bayesian.html#frequentist-perspective"><i class="fa fa-check"></i><b>11.1</b> Frequentist perspective</a></li>
<li class="chapter" data-level="11.2" data-path="bayesian.html"><a href="bayesian.html#bayesian-perspective"><i class="fa fa-check"></i><b>11.2</b> Bayesian perspective</a></li>
<li class="chapter" data-level="11.3" data-path="bayesian.html"><a href="bayesian.html#continous-parameters"><i class="fa fa-check"></i><b>11.3</b> Continous parameters</a><ul>
<li class="chapter" data-level="11.3.1" data-path="bayesian.html"><a href="bayesian.html#uniform"><i class="fa fa-check"></i><b>11.3.1</b> Uniform</a></li>
<li class="chapter" data-level="11.3.2" data-path="bayesian.html"><a href="bayesian.html#uniform-prior-versus-posterior"><i class="fa fa-check"></i><b>11.3.2</b> Uniform: prior versus posterior</a></li>
<li class="chapter" data-level="11.3.3" data-path="bayesian.html"><a href="bayesian.html#uniform-equal-tailed-versus-hpd"><i class="fa fa-check"></i><b>11.3.3</b> Uniform: equal tailed versus HPD</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="bayesian.html"><a href="bayesian.html#bernoullibinomial-likelihood-with-uniform-prior"><i class="fa fa-check"></i><b>11.4</b> Bernoulli/binomial likelihood with uniform prior</a></li>
<li class="chapter" data-level="11.5" data-path="bayesian.html"><a href="bayesian.html#conjugate-priors"><i class="fa fa-check"></i><b>11.5</b> Conjugate priors</a></li>
<li class="chapter" data-level="11.6" data-path="bayesian.html"><a href="bayesian.html#poisson-distribution"><i class="fa fa-check"></i><b>11.6</b> Poisson distribution</a></li>
<li class="chapter" data-level="11.7" data-path="bayesian.html"><a href="bayesian.html#exponential-data"><i class="fa fa-check"></i><b>11.7</b> Exponential data</a></li>
<li class="chapter" data-level="11.8" data-path="bayesian.html"><a href="bayesian.html#normal-likelihood"><i class="fa fa-check"></i><b>11.8</b> Normal likelihood</a><ul>
<li class="chapter" data-level="11.8.1" data-path="bayesian.html"><a href="bayesian.html#when-variance-is-known"><i class="fa fa-check"></i><b>11.8.1</b> When variance is known</a></li>
<li class="chapter" data-level="11.8.2" data-path="bayesian.html"><a href="bayesian.html#when-variance-is-unknown"><i class="fa fa-check"></i><b>11.8.2</b> When variance is unknown</a></li>
</ul></li>
<li class="chapter" data-level="11.9" data-path="bayesian.html"><a href="bayesian.html#non-informative-priors"><i class="fa fa-check"></i><b>11.9</b> Non-informative priors</a><ul>
<li class="chapter" data-level="11.9.1" data-path="bayesian.html"><a href="bayesian.html#bernoulli"><i class="fa fa-check"></i><b>11.9.1</b> Bernoulli</a></li>
<li class="chapter" data-level="11.9.2" data-path="bayesian.html"><a href="bayesian.html#gaussian"><i class="fa fa-check"></i><b>11.9.2</b> Gaussian</a></li>
</ul></li>
<li class="chapter" data-level="11.10" data-path="bayesian.html"><a href="bayesian.html#jeffreys-priors"><i class="fa fa-check"></i><b>11.10</b> Jeffreys Priors</a><ul>
<li class="chapter" data-level="11.10.1" data-path="bayesian.html"><a href="bayesian.html#gaussian-1"><i class="fa fa-check"></i><b>11.10.1</b> Gaussian</a></li>
<li class="chapter" data-level="11.10.2" data-path="bayesian.html"><a href="bayesian.html#bernoulli-1"><i class="fa fa-check"></i><b>11.10.2</b> Bernoulli</a></li>
<li class="chapter" data-level="11.10.3" data-path="bayesian.html"><a href="bayesian.html#side-note-fisher-information"><i class="fa fa-check"></i><b>11.10.3</b> Side Note: Fisher Information</a></li>
<li class="chapter" data-level="11.10.4" data-path="bayesian.html"><a href="bayesian.html#prior-predictive-distribution"><i class="fa fa-check"></i><b>11.10.4</b> Prior predictive distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="trying.html"><a href="trying.html"><i class="fa fa-check"></i><b>12</b> Trying</a><ul>
<li class="chapter" data-level="12.1" data-path="trying.html"><a href="trying.html#the-basic-idea"><i class="fa fa-check"></i><b>12.1</b> The Basic Idea</a></li>
<li class="chapter" data-level="12.2" data-path="trying.html"><a href="trying.html#model-and-r-code"><i class="fa fa-check"></i><b>12.2</b> Model and R Code</a></li>
<li class="chapter" data-level="12.3" data-path="trying.html"><a href="trying.html#glmmtmb-package"><i class="fa fa-check"></i><b>12.3</b> glmmTMB package</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://www.williamsding.com/" target="blank">Bill's website</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">GLMM, Concepts, &amp; R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="project-draft" class="section level1">
<h1><span class="header-section-number">Chapter 10</span> Project Draft</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mydata3&lt;-<span class="kw">read.csv</span>(<span class="st">&#39;Schnibbe 1502 Binary Data.csv&#39;</span>)
<span class="kw">head</span>(mydata3)</code></pre></div>
<pre><code>##   X0
## 1  0
## 2  1
## 3  0
## 4  0
## 5  1
## 6  0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">NO_new&lt;-<span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">222</span>)
mydata4&lt;-<span class="kw">cbind</span>(mydata3,NO_new)
<span class="kw">head</span>(mydata4)</code></pre></div>
<pre><code>##   X0 NO_new
## 1  0      1
## 2  1      2
## 3  0      3
## 4  0      4
## 5  1      5
## 6  0      6</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">a1 =<span class="st"> </span><span class="kw">glmer</span>(X0 <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>NO_new), <span class="dt">data =</span> mydata4,<span class="dt">family=</span>binomial)
<span class="kw">summary</span>(a1)</code></pre></div>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: X0 ~ 1 + (1 | NO_new)
##    Data: mydata4
## 
##      AIC      BIC   logLik deviance df.resid 
##    243.3    250.1   -119.6    239.3      220 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -0.5461 -0.5461 -0.5461 -0.5461  1.8311 
## 
## Random effects:
##  Groups Name        Variance  Std.Dev.
##  NO_new (Intercept) 1.246e-07 0.000353
## Number of obs: 222, groups:  NO_new, 222
## 
## Fixed effects:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -1.2098     0.1603  -7.549 4.38e-14 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">a2 =<span class="st"> </span><span class="kw">glm</span>(X0 <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> mydata4,<span class="dt">family=</span>binomial)
<span class="kw">summary</span>(a2)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = X0 ~ 1, family = binomial, data = mydata4)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.7225  -0.7225  -0.7225  -0.7225   1.7151  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -1.2098     0.1595  -7.583 3.38e-14 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 239.29  on 221  degrees of freedom
## Residual deviance: 239.29  on 221  degrees of freedom
## AIC: 241.29
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div id="background" class="section level2">
<h2><span class="header-section-number">10.1</span> Background</h2>
<p>The following code is from this website: <a href="http://www.biostat.umn.edu/~baolin/teaching/probmods/GLMM_mcmc.html" class="uri">http://www.biostat.umn.edu/~baolin/teaching/probmods/GLMM_mcmc.html</a>. I will remove it on this page after I complete my practice and learning.</p>
<p>In this example, it simulates a longitudinal data with 4 variables for each of 1000 separate individuals. Specifically, there are three continuous covariates (varying over time) and one ordinal covariate (constant over time). We will consider a random intercept model (mean zero and variance 100), and fit the data with glmer() from lme4 R package.</p>
<p>The R code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n =<span class="st"> </span><span class="dv">1000</span>; p =<span class="st"> </span><span class="dv">3</span>; K =<span class="st"> </span><span class="dv">4</span>; sig =<span class="st"> </span><span class="dv">10</span>
<span class="kw">set.seed</span>(<span class="dv">123</span>)

## time varying covariates
Xl =<span class="st"> </span><span class="kw">vector</span>(<span class="st">&#39;list&#39;</span>, K)
<span class="co"># 4 list, each 1000 individuals</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>K) Xl[[i]] =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n<span class="op">*</span>p), n,p)

## constant covariate
Z =<span class="st"> </span><span class="kw">rbinom</span>(n, <span class="dv">2</span>,<span class="fl">0.2</span>)

## random effects
<span class="co">#just 1000 random numubers?</span>
U =<span class="st"> </span><span class="kw">rnorm</span>(n)<span class="op">*</span>sig

## fixed effects
<span class="co"># It ends a 1000*4 matrix</span>
etaX =<span class="st"> </span><span class="kw">sapply</span>(Xl, rowSums)

## random errors
eps =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n<span class="op">*</span>K), n,K)

## logit model
eta =<span class="st"> </span>etaX <span class="op">+</span><span class="st"> </span>U <span class="op">+</span><span class="st"> </span>eps
<span class="co"># calculate probability</span>
prb =<span class="st"> </span><span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(<span class="op">-</span>eta))
D =<span class="st"> </span><span class="dv">1</span><span class="op">*</span>(<span class="kw">matrix</span>(<span class="kw">runif</span>(n<span class="op">*</span>K),n,K)<span class="op">&lt;</span>prb) <span class="co"># comparing it to prb, and change to 1 and 0; 1000*4</span>
<span class="co"># Select the first list from &quot;Xl&quot;, and then add other 3 lists--&gt; 4000 * 3</span>
Xs =<span class="st"> </span>Xl[[<span class="dv">1</span>]]
<span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>K) Xs =<span class="st"> </span><span class="kw">rbind</span>(Xs, Xl[[k]])

## GLMM model
<span class="kw">library</span>(lme4)
sid =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>n, K) <span class="co"># a vector of 1-1000, 4 repetitions</span>
## model fit with GLMMM (default to Laplace approximation)
<span class="co"># subjects as the random effect</span>
a1 =<span class="st"> </span><span class="kw">glmer</span>(<span class="kw">c</span>(D) <span class="op">~</span><span class="st"> </span>Xs <span class="op">+</span><span class="st"> </span>Z[sid] <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>sid), <span class="dt">family=</span>binomial)

a1</code></pre></div>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: c(D) ~ Xs + Z[sid] + (1 | sid)
##       AIC       BIC    logLik  deviance  df.resid 
##  3213.666  3251.430 -1600.833  3201.666      3994 
## Random effects:
##  Groups Name        Std.Dev.
##  sid    (Intercept) 5.816   
## Number of obs: 4000, groups:  sid, 1000
## Fixed Effects:
## (Intercept)          Xs1          Xs2          Xs3       Z[sid]  
##      0.1537       0.6650       0.6429       0.6074       0.0199</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## MH sampling of random effects | data
## logit\Pr(D_i|eta_i,U) = eta_i+U; U \sim N(0,Vu)
## proposal dist: N(Uc,Vc)

U.mh &lt;-<span class="st"> </span><span class="cf">function</span>(Di,eta, Vu, Uc,Vc, <span class="dt">B=</span><span class="dv">100</span>){
  ub =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, B)
  ub[<span class="dv">1</span>] =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>)<span class="op">*</span><span class="kw">sqrt</span>(Vc)<span class="op">+</span>Uc <span class="co"># random starting value</span>
  prb =<span class="st"> </span><span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(<span class="op">-</span>eta<span class="op">-</span>ub[<span class="dv">1</span>]))
  llk0 =<span class="st"> </span><span class="kw">dnorm</span>(ub[<span class="dv">1</span>],<span class="dt">sd=</span><span class="kw">sqrt</span>(Vu), <span class="dt">log=</span><span class="ot">TRUE</span>) <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(Di<span class="op">*</span>prb<span class="op">+</span>(<span class="dv">1</span><span class="op">-</span>Di)<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>prb))) <span class="op">-</span><span class="st"> </span><span class="kw">dnorm</span>(ub[<span class="dv">1</span>],Uc,<span class="kw">sqrt</span>(Vc), <span class="dt">log=</span><span class="ot">TRUE</span>) <span class="co"># likelihood function? </span>
  <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>B){
    ub[k] =<span class="st"> </span>ub[k<span class="op">-</span><span class="dv">1</span>]
    uk =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>)<span class="op">*</span><span class="kw">sqrt</span>(Vc)<span class="op">+</span>Uc
    prb =<span class="st"> </span><span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(<span class="op">-</span>eta<span class="op">-</span>uk))
    llk1 =<span class="st"> </span><span class="kw">dnorm</span>(uk,<span class="dt">sd=</span><span class="kw">sqrt</span>(Vu), <span class="dt">log=</span><span class="ot">TRUE</span>) <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(Di<span class="op">*</span>prb<span class="op">+</span>(<span class="dv">1</span><span class="op">-</span>Di)<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>prb))) <span class="op">-</span><span class="st"> </span><span class="kw">dnorm</span>(uk,Uc,<span class="kw">sqrt</span>(Vc), <span class="dt">log=</span><span class="ot">TRUE</span>)
    alpha =<span class="st"> </span><span class="kw">exp</span>( llk1 <span class="op">-</span><span class="st"> </span>llk0  )
    <span class="cf">if</span>(alpha<span class="op">&gt;=</span><span class="dv">1</span>){
      ub[k] =<span class="st"> </span>uk
      llk0 =<span class="st"> </span>llk1
    } <span class="cf">else</span>{
      aa =<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>)
      <span class="cf">if</span>(aa<span class="op">&lt;</span>alpha){
        ub[k] =<span class="st"> </span>uk
        llk0 =<span class="st"> </span>llk1
      }
    }
  }
  <span class="kw">return</span>(ub)
}

<span class="kw">library</span>(numDeriv)
UV.est &lt;-<span class="st"> </span><span class="cf">function</span>(Di,eta,Vu,Uc){
  llk0 =<span class="st"> </span><span class="cf">function</span>(xpar){
    Uc =<span class="st"> </span>xpar
    prb =<span class="st"> </span><span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(<span class="op">-</span>eta<span class="op">-</span>Uc))
    res =<span class="st"> </span><span class="kw">dnorm</span>(Uc,<span class="dt">sd=</span><span class="kw">sqrt</span>(Vu), <span class="dt">log=</span><span class="ot">TRUE</span>) <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(Di<span class="op">*</span>prb<span class="op">+</span>(<span class="dv">1</span><span class="op">-</span>Di)<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>prb)))
    <span class="op">-</span>res
  }
  tmp =<span class="st"> </span><span class="kw">try</span>(<span class="kw">optim</span>(Uc, llk0, <span class="dt">method=</span><span class="st">&#39;Brent&#39;</span>, <span class="dt">lower=</span>Uc<span class="op">-</span><span class="dv">10</span>,<span class="dt">upper=</span>Uc<span class="op">+</span><span class="dv">10</span>) )
  <span class="cf">if</span>(<span class="kw">class</span>(tmp)<span class="op">==</span><span class="st">&#39;try-error&#39;</span>) tmp =<span class="st"> </span><span class="kw">optim</span>(Uc, llk0)
  Uc =<span class="st"> </span>tmp<span class="op">$</span>par
  Vc =<span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="kw">hessian</span>(llk0, Uc)
  <span class="kw">c</span>(Uc,Vc)
}
UV.mh &lt;-<span class="st"> </span><span class="cf">function</span>(Vu,beta,Uc, D,X,subj){
  ## Cov matrix
  sid =<span class="st"> </span><span class="kw">unique</span>(subj);  n =<span class="st"> </span><span class="kw">length</span>(sid)
  Uc =<span class="st"> </span>Vc =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,n)
  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n){
    ij =<span class="st"> </span><span class="kw">which</span>(subj<span class="op">==</span>sid[i]);  ni =<span class="st"> </span><span class="kw">length</span>(ij)
    Xi =<span class="st"> </span>X[ij,,drop=<span class="ot">FALSE</span>]
    eta =<span class="st"> </span>Xi<span class="op">%*%</span>beta
    zi =<span class="st"> </span><span class="kw">UV.est</span>(D[ij],eta,Vu,Uc[i])
    Uc[i] =<span class="st"> </span>zi[<span class="dv">1</span>]; Vc[i] =<span class="st"> </span>zi[<span class="dv">2</span>]
  }
  <span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">Uc=</span>Uc,<span class="dt">Vc=</span>Vc) )
}

<span class="co">#Newton Raphson update</span>
<span class="co"># Compute first/second derives of complete data log likelihood</span>
## score and fisher information
SF.mh &lt;-<span class="st"> </span><span class="cf">function</span>(Vu,beta,Uc,Vc, D,X,subj){
  ## S/hessian matrix
  sid =<span class="st"> </span><span class="kw">unique</span>(subj);  n =<span class="st"> </span><span class="kw">length</span>(sid)
  p =<span class="st"> </span><span class="kw">dim</span>(X)[<span class="dv">2</span>]
  S =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, p)
  FI =<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, p,p)
  sig2 =<span class="st"> </span><span class="dv">0</span>
  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n)
    {
    ij =<span class="st"> </span><span class="kw">which</span>(subj<span class="op">==</span>sid[i]);  ni =<span class="st"> </span><span class="kw">length</span>(ij)
    Xi =<span class="st"> </span>X[ij,,drop=<span class="ot">FALSE</span>]
    eta =<span class="st"> </span>Xi<span class="op">%*%</span>beta
    zi =<span class="st"> </span><span class="kw">U.mh</span>(D[ij],eta,Vu,Uc[i],Vc[i], <span class="dt">B=</span><span class="fl">5e3</span>)[<span class="op">-</span>(<span class="dv">1</span><span class="op">:</span><span class="fl">1e3</span>)]
    theta =<span class="st"> </span><span class="kw">sapply</span>(eta, <span class="cf">function</span>(b0)  <span class="kw">mean</span>(<span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(<span class="op">-</span>b0<span class="op">-</span>zi))) )
    theta2 =<span class="st"> </span><span class="kw">sapply</span>(eta, <span class="cf">function</span>(b0) <span class="kw">mean</span>(<span class="kw">exp</span>(b0<span class="op">+</span>zi)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(b0<span class="op">+</span>zi))<span class="op">^</span><span class="dv">2</span>) )
    FI =<span class="st"> </span>FI <span class="op">+</span><span class="st"> </span><span class="kw">t</span>(Xi)<span class="op">%*%</span>(theta2<span class="op">*</span>Xi)
    S =<span class="st"> </span>S<span class="op">+</span><span class="kw">colSums</span>((D[ij]<span class="op">-</span>theta)<span class="op">*</span>Xi)
    sig2 =<span class="st"> </span>sig2 <span class="op">+</span><span class="st"> </span><span class="kw">mean</span>(zi<span class="op">^</span><span class="dv">2</span>)
    }
  <span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">S=</span>S, <span class="dt">FI=</span>FI, <span class="dt">sig2=</span>sig2<span class="op">/</span>n) )
}

<span class="kw">library</span>(lme4)
sid =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>n, K)
a1 =<span class="st"> </span><span class="kw">glmer</span>(<span class="kw">c</span>(D) <span class="op">~</span><span class="st"> </span>Xs <span class="op">+</span><span class="st"> </span>Z[sid] <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>sid), <span class="dt">family=</span>binomial)
## extract variance and fixed effects parameters; + mode/variance of (random effects|data)
Vu =<span class="st"> </span>(<span class="kw">getME</span>(a1,<span class="st">&#39;theta&#39;</span>))<span class="op">^</span><span class="dv">2</span>; beta =<span class="st"> </span><span class="kw">fixef</span>(a1); Um =<span class="st"> </span><span class="kw">ranef</span>(a1,<span class="dt">condVar=</span><span class="ot">TRUE</span>)
D =<span class="st"> </span><span class="kw">c</span>(D); X =<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>,Xs,Z[sid]); subj =<span class="st"> </span>sid
Uc =<span class="st"> </span><span class="kw">unlist</span>(Um[[<span class="dv">1</span>]]); Vc =<span class="st"> </span><span class="kw">c</span>( <span class="kw">attr</span>(Um[[<span class="dv">1</span>]], <span class="st">&#39;postVar&#39;</span>) )
<span class="cf">for</span>(b <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100</span>){
  ## NR updates with MH sampling
  obj =<span class="st"> </span><span class="kw">SF.mh</span>(Vu,beta,Uc,Vc, D,X,subj)
  Vu =<span class="st"> </span>obj<span class="op">$</span>sig2
  tmp =<span class="st"> </span><span class="kw">solve</span>(obj<span class="op">$</span>FI,obj<span class="op">$</span>S)
  beta =<span class="st"> </span>beta <span class="op">+</span><span class="st"> </span>tmp
  ## Proposal dist update
  tmp1 =<span class="st"> </span><span class="kw">UV.mh</span>(Vu,beta,Uc, D,X,subj)
  Uc =<span class="st"> </span>tmp1<span class="op">$</span>Uc; Vc =<span class="st"> </span>tmp1<span class="op">$</span>Vc
  <span class="kw">cat</span>(b, <span class="st">&#39;:&#39;</span>, tmp, <span class="st">&#39;;&#39;</span>, obj<span class="op">$</span>S<span class="op">/</span>n, <span class="st">&#39;</span><span class="ch">\n\t</span><span class="st">&#39;</span>, <span class="kw">sqrt</span>(Vu), beta, <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>)
}</code></pre></div>
</div>
<div id="important-examples-with-r-code" class="section level2">
<h2><span class="header-section-number">10.2</span> Important Examples with R code</h2>
<ol style="list-style-type: decimal">
<li>Fitting mixed models with (temporal) correlations in R</li>
</ol>
<p><a href="https://bbolker.github.io/mixedmodels-misc/notes/corr_braindump.html" class="uri">https://bbolker.github.io/mixedmodels-misc/notes/corr_braindump.html</a></p>
<ol start="2" style="list-style-type: decimal">
<li>Mixed effects logistic regression</li>
</ol>
<p><a href="https://stats.idre.ucla.edu/r/dae/mixed-effects-logistic-regression/" class="uri">https://stats.idre.ucla.edu/r/dae/mixed-effects-logistic-regression/</a></p>
</div>
<div id="references-4" class="section level2">
<h2><span class="header-section-number">10.3</span> References</h2>
<ol style="list-style-type: decimal">
<li>Data</li>
</ol>
<p><a href="http://www.michelecoscia.com/?page_id=379" class="uri">http://www.michelecoscia.com/?page_id=379</a></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="practice-learning-on-the-battle-field.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bayesian.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/30-projectdraft.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
