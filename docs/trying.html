<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Trying | GLMM, Concepts, &amp; R</title>
  <meta name="description" content="The webpages are mainly about logit models." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Trying | GLMM, Concepts, &amp; R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The webpages are mainly about logit models." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Trying | GLMM, Concepts, &amp; R" />
  
  <meta name="twitter:description" content="The webpages are mainly about logit models." />
  

<meta name="author" content="Bill Last Updated:" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="project-draft.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://williamdingpullman.github.io/" target="blank">Bill's Stats Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface: Motivation</a></li>
<li class="chapter" data-level="1" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>1</b> Basics</a><ul>
<li class="chapter" data-level="1.1" data-path="basics.html"><a href="basics.html#logit"><i class="fa fa-check"></i><b>1.1</b> Logit</a></li>
<li class="chapter" data-level="1.2" data-path="basics.html"><a href="basics.html#probit"><i class="fa fa-check"></i><b>1.2</b> Probit</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> MLE</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#basic-idea-of-mle"><i class="fa fa-check"></i><b>2.1</b> Basic idea of MLE</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#coin-flip-example-probit-and-logit"><i class="fa fa-check"></i><b>2.2</b> Coin flip example, probit, and logit</a><ul>
<li class="chapter" data-level="2.2.1" data-path="intro.html"><a href="intro.html#probit-1"><i class="fa fa-check"></i><b>2.2.1</b> Probit</a></li>
<li class="chapter" data-level="2.2.2" data-path="intro.html"><a href="intro.html#logit-1"><i class="fa fa-check"></i><b>2.2.2</b> Logit</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#further-on-logit"><i class="fa fa-check"></i><b>2.3</b> Further on logit</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#references"><i class="fa fa-check"></i><b>2.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html"><i class="fa fa-check"></i><b>3</b> Linear Mixed Models</a><ul>
<li class="chapter" data-level="3.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#lm-and-glm"><i class="fa fa-check"></i><b>3.1</b> LM and GLM</a><ul>
<li class="chapter" data-level="3.1.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#lm"><i class="fa fa-check"></i><b>3.1.1</b> LM</a></li>
<li class="chapter" data-level="3.1.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#glm-definition"><i class="fa fa-check"></i><b>3.1.2</b> GLM-Definition</a></li>
<li class="chapter" data-level="3.1.3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#glm-log-link-example"><i class="fa fa-check"></i><b>3.1.3</b> GLM-log link example</a></li>
<li class="chapter" data-level="3.1.4" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#glm-reciprocal-link"><i class="fa fa-check"></i><b>3.1.4</b> GLM-Reciprocal link:</a></li>
<li class="chapter" data-level="3.1.5" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#glm-exponential-family"><i class="fa fa-check"></i><b>3.1.5</b> GLM-exponential family:</a></li>
<li class="chapter" data-level="3.1.6" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#canonical-exponential-family"><i class="fa fa-check"></i><b>3.1.6</b> Canonical exponential family</a></li>
<li class="chapter" data-level="3.1.7" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#canonical-exponential-family---expected-value-and-variance"><i class="fa fa-check"></i><b>3.1.7</b> Canonical exponential family - Expected value and variance</a></li>
<li class="chapter" data-level="3.1.8" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#expected-value-and-variance---possion-example"><i class="fa fa-check"></i><b>3.1.8</b> Expected value and variance - Possion Example</a></li>
<li class="chapter" data-level="3.1.9" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#canonical-link"><i class="fa fa-check"></i><b>3.1.9</b> Canonical link</a></li>
<li class="chapter" data-level="3.1.10" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#canonical-link---bernoulli"><i class="fa fa-check"></i><b>3.1.10</b> Canonical link - Bernoulli</a></li>
<li class="chapter" data-level="3.1.11" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#nr---bernoulli"><i class="fa fa-check"></i><b>3.1.11</b> NR - Bernoulli</a></li>
<li class="chapter" data-level="3.1.12" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#iteratively-re-weighted-least-squares"><i class="fa fa-check"></i><b>3.1.12</b> Iteratively Re-weighted Least Squares</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#lmm"><i class="fa fa-check"></i><b>3.2</b> LMM</a></li>
<li class="chapter" data-level="3.3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#calculate-mean"><i class="fa fa-check"></i><b>3.3</b> Calculate mean</a></li>
<li class="chapter" data-level="3.4" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#test-the-treatment-effect"><i class="fa fa-check"></i><b>3.4</b> Test the treatment effect</a></li>
<li class="chapter" data-level="3.5" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#another-example"><i class="fa fa-check"></i><b>3.5</b> Another example</a></li>
<li class="chapter" data-level="3.6" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#full-lmm-model"><i class="fa fa-check"></i><b>3.6</b> Full LMM model</a></li>
<li class="chapter" data-level="3.7" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#serial-correlations-in-time-and-space"><i class="fa fa-check"></i><b>3.7</b> Serial correlations in time and space</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html"><i class="fa fa-check"></i><b>4</b> Basic Stat Concepts</a><ul>
<li class="chapter" data-level="4.1" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#score"><i class="fa fa-check"></i><b>4.1</b> Score</a></li>
<li class="chapter" data-level="4.2" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#gradient-and-jacobian"><i class="fa fa-check"></i><b>4.2</b> Gradient and Jacobian</a></li>
<li class="chapter" data-level="4.3" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#hessian-and-fisher-information"><i class="fa fa-check"></i><b>4.3</b> Hessian and Fisher Information</a></li>
<li class="chapter" data-level="4.4" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#canonical-link-function"><i class="fa fa-check"></i><b>4.4</b> Canonical link function</a></li>
<li class="chapter" data-level="4.5" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#ordinary-least-squares-ols"><i class="fa fa-check"></i><b>4.5</b> Ordinary Least Squares (OLS)</a></li>
<li class="chapter" data-level="4.6" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#taylor-series"><i class="fa fa-check"></i><b>4.6</b> Taylor series</a></li>
<li class="chapter" data-level="4.7" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#fisher-scoring"><i class="fa fa-check"></i><b>4.7</b> Fisher scoring</a></li>
<li class="chapter" data-level="4.8" data-path="basic-stat-concepts.html"><a href="basic-stat-concepts.html#references-1"><i class="fa fa-check"></i><b>4.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="basic-r.html"><a href="basic-r.html"><i class="fa fa-check"></i><b>5</b> Basic R</a><ul>
<li class="chapter" data-level="5.1" data-path="basic-r.html"><a href="basic-r.html#apply-lapply-sapply"><i class="fa fa-check"></i><b>5.1</b> apply, lapply, sapply</a><ul>
<li class="chapter" data-level="5.1.1" data-path="basic-r.html"><a href="basic-r.html#apply"><i class="fa fa-check"></i><b>5.1.1</b> apply</a></li>
<li class="chapter" data-level="5.1.2" data-path="basic-r.html"><a href="basic-r.html#lapply"><i class="fa fa-check"></i><b>5.1.2</b> lapply</a></li>
<li class="chapter" data-level="5.1.3" data-path="basic-r.html"><a href="basic-r.html#sapply"><i class="fa fa-check"></i><b>5.1.3</b> sapply</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="basic-r.html"><a href="basic-r.html#c"><i class="fa fa-check"></i><b>5.2</b> C</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="computing-techniques.html"><a href="computing-techniques.html"><i class="fa fa-check"></i><b>6</b> Computing Techniques</a><ul>
<li class="chapter" data-level="6.1" data-path="computing-techniques.html"><a href="computing-techniques.html#monte-carlo-approximation"><i class="fa fa-check"></i><b>6.1</b> Monte carlo approximation</a></li>
<li class="chapter" data-level="6.2" data-path="computing-techniques.html"><a href="computing-techniques.html#importance-sampling"><i class="fa fa-check"></i><b>6.2</b> Importance sampling</a></li>
<li class="chapter" data-level="6.3" data-path="computing-techniques.html"><a href="computing-techniques.html#newton-raphson-algorithm"><i class="fa fa-check"></i><b>6.3</b> Newton Raphson algorithm</a><ul>
<li class="chapter" data-level="6.3.1" data-path="computing-techniques.html"><a href="computing-techniques.html#calculate-the-root"><i class="fa fa-check"></i><b>6.3.1</b> Calculate the root</a></li>
<li class="chapter" data-level="6.3.2" data-path="computing-techniques.html"><a href="computing-techniques.html#logistic-regression"><i class="fa fa-check"></i><b>6.3.2</b> Logistic regression</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="computing-techniques.html"><a href="computing-techniques.html#metropolis-hastings"><i class="fa fa-check"></i><b>6.4</b> Metropolis Hastings</a></li>
<li class="chapter" data-level="6.5" data-path="computing-techniques.html"><a href="computing-techniques.html#em"><i class="fa fa-check"></i><b>6.5</b> EM</a></li>
<li class="chapter" data-level="6.6" data-path="computing-techniques.html"><a href="computing-techniques.html#references-2"><i class="fa fa-check"></i><b>6.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html"><i class="fa fa-check"></i><b>7</b> Generalized Linear Mixed Models</a><ul>
<li class="chapter" data-level="7.1" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html#basics-of-glmm"><i class="fa fa-check"></i><b>7.1</b> Basics of GLMM</a></li>
<li class="chapter" data-level="7.2" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html#some-references"><i class="fa fa-check"></i><b>7.2</b> Some References</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="twitter-example.html"><a href="twitter-example.html"><i class="fa fa-check"></i><b>8</b> Twitter Example</a><ul>
<li class="chapter" data-level="8.1" data-path="twitter-example.html"><a href="twitter-example.html#model"><i class="fa fa-check"></i><b>8.1</b> Model</a></li>
<li class="chapter" data-level="8.2" data-path="twitter-example.html"><a href="twitter-example.html#simulating-data-of-senators-on-twitter"><i class="fa fa-check"></i><b>8.2</b> Simulating Data of Senators on Twitter</a></li>
<li class="chapter" data-level="8.3" data-path="twitter-example.html"><a href="twitter-example.html#simulating-data-of-conservative-users-on-twitter-and-model-testing"><i class="fa fa-check"></i><b>8.3</b> Simulating Data of Conservative Users on Twitter and Model Testing</a></li>
<li class="chapter" data-level="8.4" data-path="twitter-example.html"><a href="twitter-example.html#simulating-data-of-liberal-users-on-twitter-and-model-testing"><i class="fa fa-check"></i><b>8.4</b> Simulating Data of Liberal Users on Twitter and Model Testing</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="practice-learning-on-the-battle-field.html"><a href="practice-learning-on-the-battle-field.html"><i class="fa fa-check"></i><b>9</b> Practice: Learning on the Battle Field</a><ul>
<li class="chapter" data-level="9.1" data-path="practice-learning-on-the-battle-field.html"><a href="practice-learning-on-the-battle-field.html#r-code"><i class="fa fa-check"></i><b>9.1</b> R code</a></li>
<li class="chapter" data-level="9.2" data-path="practice-learning-on-the-battle-field.html"><a href="practice-learning-on-the-battle-field.html#references-3"><i class="fa fa-check"></i><b>9.2</b> References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="project-draft.html"><a href="project-draft.html"><i class="fa fa-check"></i><b>10</b> Project Draft</a><ul>
<li class="chapter" data-level="10.1" data-path="project-draft.html"><a href="project-draft.html#background"><i class="fa fa-check"></i><b>10.1</b> Background</a></li>
<li class="chapter" data-level="10.2" data-path="project-draft.html"><a href="project-draft.html#important-examples-with-r-code"><i class="fa fa-check"></i><b>10.2</b> Important Examples with R code</a></li>
<li class="chapter" data-level="10.3" data-path="project-draft.html"><a href="project-draft.html#references-4"><i class="fa fa-check"></i><b>10.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="trying.html"><a href="trying.html"><i class="fa fa-check"></i><b>11</b> Trying</a><ul>
<li class="chapter" data-level="11.1" data-path="trying.html"><a href="trying.html#the-basic-idea"><i class="fa fa-check"></i><b>11.1</b> The Basic Idea</a></li>
<li class="chapter" data-level="11.2" data-path="trying.html"><a href="trying.html#model-and-r-code"><i class="fa fa-check"></i><b>11.2</b> Model and R Code</a></li>
<li class="chapter" data-level="11.3" data-path="trying.html"><a href="trying.html#glmmtmb-package"><i class="fa fa-check"></i><b>11.3</b> glmmTMB package</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://www.williamsding.com/" target="blank">Bill's website</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">GLMM, Concepts, &amp; R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="trying" class="section level1">
<h1><span class="header-section-number">Chapter 11</span> Trying</h1>
<div id="the-basic-idea" class="section level2">
<h2><span class="header-section-number">11.1</span> The Basic Idea</h2>
<p><span class="math display">\[L(\beta,D|Y)=\int \prod_{i=1}^{n} f_{y_i|u}(y_i|b,\beta)f_{b_i}(b_i|D)db_i\]</span></p>
<p>Notations :</p>
<p><span class="math inline">\(y\)</span>: Variable for the fixed effect</p>
<p><span class="math inline">\(b\)</span>: Variable for the random effect</p>
<p><span class="math inline">\(\beta\)</span>: Parameters for the fixed effect</p>
<p><span class="math inline">\(D\)</span>: Parameters for the random effect</p>
<p>The dimension of the integral is equal to the levels of the random factors (i.e., the number of observations).</p>
</div>
<div id="model-and-r-code" class="section level2">
<h2><span class="header-section-number">11.2</span> Model and R Code</h2>
<p>Covarance Matrix for <span class="math inline">\(n\)</span> observations:</p>
<p><span class="math display">\[V=\sigma^2 \begin{bmatrix} 1 &amp; \rho &amp; \rho^2 &amp; ... &amp; \rho^{n-1} &amp; \rho^n \\ \rho &amp; 1 &amp; \rho &amp; ... &amp; \rho^{n-2}&amp; \rho^{n-1}\\ \rho^2 &amp; \rho &amp; 1 &amp; ... &amp; \rho^{n-3}&amp; \rho^{n-2} \\ ...\\ \rho^n &amp; \rho^{n-1} &amp; \rho^{n-2} &amp; ... &amp; \rho &amp; 1 \end{bmatrix}\]</span></p>
<p>The inverse matrix is as follows:</p>
<p><span class="math display">\[Q=V^{-1}=\frac{1}{\sigma^2(1-\rho)} \begin{bmatrix} 1 &amp; -\rho &amp; 0 &amp; ... &amp; 0 &amp; 0 \\ -\rho &amp; 1+\rho^2 &amp; -\rho &amp; ... &amp; 0 &amp; 0\\ 0 &amp; -\rho &amp; 1+\rho^2 &amp; ... &amp; 0 &amp; 0 \\ ...\\ 0 &amp; 0 &amp; 0 &amp; ... &amp; 1+\rho^2 &amp;-\rho\\ 0 &amp; 0 &amp; 0 &amp; ... &amp; -\rho &amp; 1 \end{bmatrix}\]</span></p>
<p><span class="math display">\[N(-\sum_{j\neq k} Q_{kj}b_j^{(m)}Q_{kk}^{-1},Q_{kk}^{-1})\]</span> <span class="math display">\[ln L(\beta, \theta; Y,b)=\ell=lnf_{Y|b}(Y|b,\beta)+lnf_b(b|\theta)\]</span></p>
<p><span class="math display">\[a^{(m+1)}=a^{(m)}+\tau(a^{(m)})^{-1} S(a^{(m)})\]</span> Where,</p>
<p><span class="math display">\[\tau(a) = -E(\frac{\partial^2 \ell}{\partial \alpha \partial \alpha^{&#39;}}|Y)\]</span></p>
<p><span class="math display">\[S(a) = E(\frac{\partial \ell}{\partial \alpha }|Y)\]</span> Note that, <span class="math inline">\(\alpha\)</span> is a combination of two sets of parameters.</p>
<p><span class="math display">\[\alpha = \binom{\beta}{b} \]</span></p>
<p><span class="math display">\[\ell=\sum_{i=1}^{n}\{[y_i ln (\frac{e^{\beta^Tx_i+b_i}}{1+e^{\beta^Tx_i+b_i}}) + (1-y_i) ln(1-\frac{e^{\beta^Tx_i+b_i}}{1+e^{\beta^Tx_i+b_i}})]+lnf_b(b_i|\theta)\}\]</span></p>
<p><span class="math display">\[\frac{\partial lnf(Y|b, \beta)}{\partial \beta}=X^{&#39;}(Y-E(Y|b))\]</span></p>
<p><span class="math display">\[\frac{\partial lnf(Y|b, \beta)}{\partial \beta \partial \beta^{&#39;}}=-X^{&#39;}(Y-E(Y|b))\]</span></p>
<p><span class="math display">\[\begin{aligned} \nabla \ell &amp;= \sum_{i=1}^{n} [y_i \frac{1}{p(\beta ^T x_i+b_i)} \frac{\partial p(\beta ^T x_i+b_i)}{\partial (\beta ^T x_i+b_i)}\frac{\partial (\beta ^T x_i+b_i)}{\partial \beta}+(1-y_i) \frac{1}{1-p(\beta ^T x_i+b_i)}(-1)\frac{\partial p(\beta ^T x_i+b_i)}{\partial (\beta ^T x_i+b_i)}\frac{\partial (\beta ^T x_i+b_i)}{\partial \beta}] \\ &amp;=\sum_{i=1}^{n} x_i^T[y_i-p(\beta ^T x_i+b_i)] \\ &amp;= \sum_{i=1}^{n} x_i^T[y_i-\frac{e^{\beta^Tx_i+b_i}}{1+e^{\beta^Tx_i+b_i}}] \end{aligned}\]</span></p>
<p>The Newton Raphson algorithm needs the second order.</p>
<p><span class="math display">\[\begin{aligned} \nabla^2 \ell &amp;=\frac{\partial \sum_{i=1}^{n} x_i^T[y_i-p(\beta ^T x_i+b_i)]}{\partial \beta} \\ &amp;=-\sum_{i=1}^{n} x_i^T\frac{\partial p(\beta ^T x_i+b_i) }{\partial \beta}\\ &amp;=-\sum_{i=1}^{n} x_i^T\frac{\partial p(\beta ^T x_i+b_i) }{\partial (\beta^Tx_i+b_i)} \frac{\partial (\beta^Tx_i+b_i)}{\partial \beta}\\ &amp;=-\sum_{i=1}^{n} x_i^T p(\beta ^T x_i+b_i)(1-p(\beta ^T x_i+b_i))x_i \\ &amp;=-\sum_{i=1}^{n} x_i^T \frac{e^{\beta^Tx_i+b_i}}{1+e^{\beta^Tx_i+b_i}}(1-\frac{e^{\beta^Tx_i+b_i}}{1+e^{\beta^Tx_i+b_i}})x_i \end{aligned}\]</span> Using the Newton Raphson, the following code calculates the basic logistic model, without any random effects. As we can see, it produces the same result as the R generic function of GLM. Note that, the function of Expit and the variables of y and are from the last block of R code.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#n&lt;-10</span>
x_intercept&lt;-<span class="kw">rep</span>(<span class="dv">1</span>,n)
x_intercept&lt;-<span class="kw">as.matrix</span>(x_intercept)

tolerance=<span class="fl">1e-3</span>
max_its=<span class="dv">2000</span>;iteration=<span class="dv">1</span>;difference=<span class="dv">2</span>
W&lt;-<span class="kw">matrix</span>(<span class="dv">0</span>,n,n)
beta_old&lt;-<span class="fl">0.4</span>

<span class="cf">while</span>(difference<span class="op">&gt;</span>tolerance <span class="op">&amp;</span><span class="st"> </span>iteration<span class="op">&lt;</span>max_its)
  {
  <span class="co"># The first order</span>
  f_firstorder&lt;-<span class="kw">t</span>(x_intercept)<span class="op">%*%</span>(y<span class="op">-</span><span class="kw">Expit</span>(x_intercept<span class="op">%*%</span>beta_old))
  
  <span class="co"># The second order</span>
  <span class="kw">diag</span>(W) =<span class="st"> </span><span class="kw">Expit</span>(x_intercept<span class="op">%*%</span>beta_old)<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">Expit</span>(x_intercept<span class="op">%*%</span>beta_old))
  
  f_secondorder&lt;-<span class="op">-</span><span class="kw">t</span>(x_intercept)<span class="op">%*%</span>W<span class="op">%*%</span>x_intercept
  
  <span class="co"># Calculate the beta_updated</span>
  beta_updated=beta_old<span class="op">-</span>(<span class="kw">solve</span>(f_secondorder)<span class="op">%*%</span>f_firstorder)
  
  difference=<span class="kw">max</span>(<span class="kw">abs</span>(beta_updated<span class="op">-</span>beta_old));
  
  iteration=iteration<span class="op">+</span><span class="dv">1</span>;
  
  beta_old=beta_updated}

beta_old

<span class="kw">glm</span>(y<span class="op">~</span><span class="dv">1</span>, <span class="dt">family=</span>binomial)<span class="op">$</span>coefficients</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#install.packages(&quot;CVTuningCov&quot;)</span>
<span class="kw">library</span>(CVTuningCov) <span class="co"># Will be used to generate AR1 matrix</span>

<span class="kw">set.seed</span>(<span class="dv">123</span>)
y&lt;-<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>) ## observations

n=<span class="kw">length</span>(y) <span class="co"># the number of observations</span>


<span class="co">#Establish the exp function</span>
Expit&lt;-<span class="cf">function</span>(x){<span class="kw">exp</span>(x)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(x))}
<span class="co">#Y: observations</span>
<span class="co">#b: random effect</span>
<span class="co">#beta_0:fixed effect-&gt;intercept (or, mean of Y)</span>

log_pdf_function&lt;-<span class="cf">function</span>(Y,b,beta_<span class="dv">0</span>)
  {mean_prob&lt;-<span class="kw">Expit</span>(beta_<span class="dv">0</span><span class="op">+</span>b)
  <span class="kw">dbinom</span>(Y,<span class="dv">1</span>,mean_prob,<span class="dt">log =</span> <span class="ot">TRUE</span>)
  }

b_records&lt;-<span class="kw">rep</span>(<span class="dv">0</span>,n)  <span class="co">#Initial values for the random effect</span>
rho_records&lt;-<span class="fl">0.5</span> <span class="co">#Initial value for rho</span>
sigma_recoards&lt;-<span class="dv">2</span>  <span class="co">#Initial value for sigma</span>
mean_<span class="dv">0</span>&lt;-<span class="dv">0</span> <span class="co"># Initial mean value for normal distribution (of the random effect)</span>
beta&lt;-<span class="fl">0.5</span> <span class="co"># Initial value for the intercept of Y</span>


f_random&lt;-<span class="cf">function</span>(sigma_recoards, rho_records,beta)
{
  
co_matrix&lt;-(sigma_recoards<span class="op">^</span><span class="dv">2</span>)<span class="op">*</span><span class="kw">AR1</span>(n,rho_records) <span class="co"># covariance matrix</span>
co_matrix_inverse&lt;-<span class="kw">solve</span>(co_matrix)  <span class="co"># inverse covariance matrix</span>


<span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n)
 {
  <span class="co"># Variance for the random effect</span>
  sd_<span class="dv">0</span>&lt;-<span class="dv">1</span><span class="op">/</span>(co_matrix_inverse[k,k])
  
  <span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n)
      { <span class="co"># Make sure that k is not equal to j, otherwise 0</span>
        Q_kj&lt;-<span class="kw">ifelse</span>(j<span class="op">!=</span>k,co_matrix_inverse[k,j],<span class="dv">0</span>)
        <span class="co"># Calculate the mean for the random effect; sum of mean in a loop</span>
        mean_<span class="dv">0</span>&lt;-mean_<span class="dv">0</span><span class="op">-</span>(Q_kj<span class="op">/</span>co_matrix_inverse[k,k])<span class="op">*</span>b_records[j]
      }
  <span class="co"># Draw a random number from the normal distribution for the random effect</span>
  b_candidate&lt;-<span class="kw">rnorm</span>(<span class="dv">1</span>,mean_<span class="dv">0</span>,sd_<span class="dv">0</span>)
  
  current_lp&lt;-<span class="kw">log_pdf_function</span>(y[k],b_records[k],beta)
  candidate_lp&lt;-<span class="kw">log_pdf_function</span>(y[k],b_candidate,beta)
  
  Smaller_value&lt;-<span class="kw">min</span>(<span class="kw">exp</span>(candidate_lp<span class="op">-</span>current_lp),<span class="dv">1</span>)
  <span class="co"># Draw a random number from the uniform distribution</span>
  Random_probability&lt;-<span class="kw">runif</span>(<span class="dv">1</span>)
  <span class="co"># Update b (i.e., random variable)</span>
  b_records[k]&lt;-<span class="kw">ifelse</span>(Random_probability<span class="op">&lt;</span>Smaller_value,b_candidate,b_records[k])
}

<span class="kw">return</span>(b_records)
}

<span class="co"># Print result</span>
<span class="co">#b_records&lt;-f_random(1,0.8,0.3) </span></code></pre></div>
<p>In the following, I will try to add the random effect.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x_intercept&lt;-<span class="kw">rep</span>(<span class="dv">1</span>,n)
x_intercept&lt;-<span class="kw">as.matrix</span>(x_intercept)

<span class="co">#We need to set random starting values.</span>

tolerance=<span class="fl">1e-3</span>
max_its=<span class="dv">2000</span>;iteration=<span class="dv">1</span>;difference=<span class="dv">2</span>
W&lt;-<span class="kw">matrix</span>(<span class="dv">0</span>,n,n)
beta_old&lt;-<span class="fl">0.4</span>

<span class="cf">while</span>(difference<span class="op">&gt;</span>tolerance <span class="op">&amp;</span><span class="st"> </span>iteration<span class="op">&lt;</span>max_its)
  {
  b_records&lt;-<span class="kw">f_random</span>(<span class="dv">2</span>,<span class="fl">0.9</span>,beta_old)
  <span class="kw">print</span>(<span class="st">&quot;first&quot;</span>)
  <span class="kw">print</span>(beta_old)
  <span class="kw">print</span>(b_records)
  <span class="co"># The first order</span>
  f_firstorder&lt;-<span class="kw">t</span>(x_intercept)<span class="op">%*%</span>(y<span class="op">-</span><span class="kw">Expit</span>(x_intercept<span class="op">%*%</span>beta_old<span class="op">+</span>b_records))
  <span class="kw">print</span>(f_firstorder)
  <span class="co"># The second order</span>
  <span class="kw">diag</span>(W) =<span class="st"> </span><span class="kw">Expit</span>(x_intercept<span class="op">%*%</span>beta_old<span class="op">+</span>b_records)<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">Expit</span>(x_intercept<span class="op">%*%</span>beta_old<span class="op">+</span>b_records))
  
  f_secondorder&lt;-<span class="op">-</span><span class="kw">t</span>(x_intercept)<span class="op">%*%</span>W<span class="op">%*%</span>x_intercept
  
  <span class="co"># Calculate the beta_updated</span>
  beta_updated=beta_old<span class="op">-</span>(<span class="kw">solve</span>(f_secondorder)<span class="op">%*%</span>f_firstorder)
  
  difference=<span class="kw">max</span>(<span class="kw">abs</span>(beta_updated<span class="op">-</span>beta_old));
  
  iteration=iteration<span class="op">+</span><span class="dv">1</span>;
  
  beta_old=beta_updated
  }

beta_old</code></pre></div>
</div>
<div id="glmmtmb-package" class="section level2">
<h2><span class="header-section-number">11.3</span> glmmTMB package</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># https://becarioprecario.bitbucket.io/inla-gitbook/ch-intro.html</span>
<span class="co">#https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html</span>
<span class="co">#install.packages(&quot;glmmTMB&quot;)</span>
<span class="kw">library</span>(glmmTMB)

times &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="dv">1</span><span class="op">:</span>n)
<span class="kw">levels</span>(times)
group &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">rep</span>(<span class="dv">1</span>,n))
dat0 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(y,times,group)

<span class="kw">glmmTMB</span>(y <span class="op">~</span><span class="st"> </span><span class="kw">ar1</span>(times <span class="op">+</span><span class="st"> </span><span class="dv">0</span> <span class="op">|</span><span class="st"> </span>group), <span class="dt">data=</span>dat0)</code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="project-draft.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/50-trying.rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
