[
["index.html", "GLMM, Concepts, &amp; R Preface: Motivation", " GLMM, Concepts, &amp; R Bill Last Updated: 12 January, 2020 Preface: Motivation All the notes I have done here are the preparation for my stat master project, which will be about Generalized Linear Mixed Models. While I have tried my best, probably there are still some typos and erros. Please feel free to let me know in case you find one. Thank you! "],
["basics.html", "Chapter 1 Basics 1.1 Logit 1.2 Probit", " Chapter 1 Basics 1.1 Logit \\[f(x)=log(\\frac{p(y=1)}{1-p(y=1)})\\] The basic idea of logistic regression: \\[p(y=1)=\\frac{1}{1+e^{-(\\beta_0+\\beta_1x_1+...+\\beta_nx_n)}}=\\frac{e^{\\beta_0+\\beta_1x_1+...+\\beta_nx_n}}{1+e^{\\beta_0+\\beta_1x_1+...+\\beta_nx_n}}\\] Thus, \\(e^{\\beta_0+\\beta_1x_1+...+\\beta_nx_n}\\) can be from \\(-\\infty\\) to \\(+\\infty\\), and \\(p(y=1)\\) will be always within the range of \\((0,1)\\). f&lt;-function(x){exp(x)/(1+exp(x))} data&lt;-seq(-10,10,1) plot(data,f(data),type = &quot;b&quot;) We can also write the function into another format as follows: \\[log \\frac{p(y=1)}{1-p(y=1)}= \\beta_0+\\beta_1x_1+...+\\beta_nx_n\\] Thus, we know that the regression coeficients of \\(\\beta_i\\) actually change the “log-odds” of the event. Of course, note that the magnitude of \\(\\beta_i\\) is dependent upon the units of \\(x_i\\). The following is an example testing whether that home teams are more likely to win in NFL games. The results show that the odd of winning is the same for both home and away teams. mydata = read.csv(url(&#39;https://raw.githubusercontent.com/nfl-football-ops/Big-Data-Bowl/master/Data/games.csv&#39;)) mydata$result_new&lt;-ifelse(mydata$HomeScore&gt;mydata$VisitorScore,1,0) summary(mydata$result_new) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0000 0.0000 0.0000 0.4945 1.0000 1.0000 mylogit1 = glm(result_new~1, family=binomial, data=mydata) summary(mylogit1) ## ## Call: ## glm(formula = result_new ~ 1, family = binomial, data = mydata) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.168 -1.168 -1.168 1.187 1.187 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.02198 0.20967 -0.105 0.917 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 126.14 on 90 degrees of freedom ## Residual deviance: 126.14 on 90 degrees of freedom ## AIC: 128.14 ## ## Number of Fisher Scoring iterations: 3 1.2 Probit As noted above, logit \\(f(x)=log(\\frac{p(y=1)}{1-p(y=1)})\\) provides the resulting range of \\((0,1)\\). Another way to provide the same rage is through the cdf of normal distribution.The following R code is used to illusrate this process. data2&lt;-seq(-5,5,1) plot(data2,pnorm(data2),type = &quot;b&quot;) Thus, the cdf of normal distribution can be used to indicate the probability of \\(p(y=1)\\). \\[\\Phi(\\beta_0+\\beta_1x_1+...+\\beta_nx_n )= p(y=1)\\] Similar to logit model, we can also write the inverse function of the cdf to get the function that can be from \\(-\\infty\\) to \\(+\\infty\\). \\[\\beta_0+\\beta_1x_1+...+\\beta_nx_n =\\Phi^{-1}(p(y=1))\\] Thus, for example, if \\(X\\beta\\) = -2, based on \\(\\Phi(\\beta_0+\\beta_1x_1+...+\\beta_nx_n )= p(y=1)\\) we can get that the \\(p(y=1)=0.023\\). In contrast, if \\(X\\beta\\) = 3, the \\(p(y=1)=0.999\\). pnorm(-2) ## [1] 0.02275013 pnorm(3) ## [1] 0.9986501 Let’s assume that there is a latent variable called \\(Y^*\\) such that \\[Y^*=X\\beta+\\epsilon, \\epsilon \\sim N(0,\\sigma^2)\\] You could think of \\(Y^*\\) as a kind of “proxy” between \\(X\\beta+\\epsilon\\) and the observed \\(Y (1 or 0)\\). Thus, we can get the following. Note that, it does not have to be zero, and can be any constant. \\[ Y^*=\\begin{cases} 0 \\;\\;\\: if \\; y_i^* \\leq 0 \\\\ 1 \\;\\;\\: if \\; y_i^* &gt; 0 \\end{cases} \\] Thus, \\[y_i^* &gt; 0 \\Rightarrow \\beta^{&#39;}X_i + \\epsilon_i &gt;0 \\Rightarrow \\epsilon_i &gt; -\\beta^{&#39;}X_i\\] Thus, we can write it as follows. Note that \\(\\frac{ \\epsilon_i}{\\sigma} \\sim N(0,1)\\) \\[p(y=1|x_i)= p(y_i^* &gt;0|x_i)=p(\\epsilon_i &gt; -\\beta^{&#39;}X_i)= p(\\frac{ \\epsilon_i}{\\sigma}&gt;\\frac{-\\beta^{&#39;}X_i}{\\sigma})=\\Phi(\\frac{\\beta^{&#39;}X_i}{\\sigma}) \\] We thus can get: \\[p(y=0|x_i)=1-\\Phi(\\frac{\\beta^{&#39;}X_i}{\\sigma})\\] For \\(p(y=1|x_i)=\\Phi(\\frac{\\beta^{&#39;}X_i}{\\sigma})\\), we can not really estimate both \\(\\beta\\) and \\(\\sigma\\) as they are in a ratio. We can assume \\(\\sigma =1\\), then \\(\\epsilon \\sim N(0,1)\\). We know \\(y_i\\) and \\(x_i\\) since we observe them. Thus, we can write it as follows. \\[p(y=1|x_i)=\\Phi(\\beta^{&#39;}X_i)\\] "],
["intro.html", "Chapter 2 MLE 2.1 Basic idea of MLE 2.2 Coin flip example, probit, and logit 2.3 Further on logit 2.4 References", " Chapter 2 MLE 2.1 Basic idea of MLE Suppose that we flip a coin, \\(y_i=0\\) for tails and \\(y_i=1\\) for heads. If we get \\(p\\) heads from \\(n\\) trials, we can get the proportion of heads is \\(p/n\\), which is the sample mean. If we do not do any further calculation, this is our best guess. Suppose that the true proablity is \\(\\rho\\), then we can get: \\[ \\mathbf{L}(y_i)=\\begin{cases} \\rho \\;\\;\\: y_i = 1 \\\\ 1-\\rho \\;\\;\\: y_i = 0 \\end{cases} \\] Thus, we can also write it as follows. \\[\\mathbf{L}(y_i) = \\rho^{y_i}(1-\\rho)^{1-y_i}\\] Thus, we can get: \\[\\prod \\mathbf{L}(y_i|\\rho)=\\rho^{\\sum y_i}(1-\\rho)^{\\sum(1-y_i)}\\] Further, we can get a log-transformed format. \\[log (\\prod \\mathbf{L}(y_i|\\rho))=\\sum y_i log \\rho + \\sum(1-y_i) log(1-\\rho)\\] To maximize the log-function above, we can calculate the derivative with respect to \\(\\rho\\). \\[\\frac{\\partial log (\\prod \\mathbf{L}(y_i|\\rho)) }{\\partial \\rho}=\\sum y_i \\frac{1}{\\rho}-\\sum(1-y_i) \\frac{1}{1-\\rho}\\] Set the derivative to zero and solve for \\(\\rho\\), we can get \\[\\sum y_i \\frac{1}{\\rho}-\\sum(1-y_i) \\frac{1}{1-\\rho}=0\\] \\[\\Rightarrow (1-\\rho)\\sum y_i - \\rho \\sum(1-y_i) =0\\] \\[\\Rightarrow \\sum y_i-\\rho\\sum y_i - n\\rho +\\rho\\sum y_i =0\\] \\[\\Rightarrow \\sum y_i - n\\rho =0\\] \\[\\Rightarrow \\rho = \\frac{\\sum y_i}{n}=\\frac{p}{n}\\] Thus, we can see that the \\(\\rho\\) maximizing the likelihood function is equal to the sample mean. 2.2 Coin flip example, probit, and logit In the example above, we are not really trying to estimate a lot of regression coefficients. What we are doing actually is to calculate the sample mean, or intercept in the regresion sense. What does it mean? Let’s use some data to explain it. Suppose that we flip a coin 20 times and observe 8 heads. We can use the R’s glm function to esimate the \\(\\rho\\). If the result is consistent with what we did above, we should observe that the \\(cdf\\) of the esimate of \\(\\beta_0\\) (i.e., intercept) should be equal to \\(8/20=0.4\\). coins&lt;-c(rep(1,times=8),rep(0,times=12)) table(coins) ## coins ## 0 1 ## 12 8 coins&lt;-as.data.frame(coins) 2.2.1 Probit probitresults &lt;- glm(coins ~ 1, family = binomial(link = &quot;probit&quot;), data = coins) probitresults ## ## Call: glm(formula = coins ~ 1, family = binomial(link = &quot;probit&quot;), ## data = coins) ## ## Coefficients: ## (Intercept) ## -0.2533 ## ## Degrees of Freedom: 19 Total (i.e. Null); 19 Residual ## Null Deviance: 26.92 ## Residual Deviance: 26.92 AIC: 28.92 pnorm(probitresults$coefficients) ## (Intercept) ## 0.4 As we can see the intercept is \\(-0.2533\\), and thus \\(\\Phi(-0.2533471)=0.4\\) 2.2.2 Logit We can also use logit link to calculate the intercept as well. Recall that \\[p(y=1)=\\frac{1}{1+e^{-(\\beta_0+\\beta_1x_1+...+\\beta_nx_n)}}=\\frac{e^{\\beta_0+\\beta_1x_1+...+\\beta_nx_n}}{1+e^{\\beta_0+\\beta_1x_1+...+\\beta_nx_n}}\\] Thus, \\[p(y=1)=\\frac{e^{\\beta_0}}{1+e^{\\beta_0}}\\] logitresults &lt;- glm(coins ~ 1, family = binomial(link = &quot;logit&quot;), data = coins) logitresults$coefficients ## (Intercept) ## -0.4054651 exp(logitresults$coefficients)/(1+exp(logitresults$coefficients)) ## (Intercept) ## 0.4 Note that, the defaul link for the binomial in the glm function in logit. 2.3 Further on logit The probablity of \\(y=1\\) is as follows: \\[p=p(y=1)=\\frac{1}{1+e^{-(\\beta_0+\\beta_1x_1+...+\\beta_nx_n)}}=\\frac{e^{\\beta_0+\\beta_1x_1+...+\\beta_nx_n}}{1+e^{\\beta_0+\\beta_1x_1+...+\\beta_nx_n}}\\] Thus, the likelihood function is as follows: \\[L=\\prod p^{y_i}(1-p)^{1-y_i}=\\prod (\\frac{1}{1+e^{-(\\beta_0+\\beta_1x_1+...+\\beta_nx_n)}})^{y_i}(\\frac{1}{1+e^{\\beta_0+\\beta_1x_1+...+\\beta_nx_n}})^{1-y_i}\\] \\[=\\prod (1+e^{-(\\beta_0+\\beta_1x_1+...+\\beta_nx_n)})^{-y_i}(1+e^{\\beta_0+\\beta_1x_1+...+\\beta_nx_n})^{-(1-y_i)}\\] Thus, the log-likelihood is as follows: \\[logL=\\sum (-y_i \\cdot log(1+e^{-(\\beta_0+\\beta_1x_1+...+\\beta_nx_n)})-(1-y_i)\\cdot log(1+e^{\\beta_0+\\beta_1x_1+...+\\beta_nx_n}))\\] Typically, optimisers minimize a function, so we use negative log-likelihood as minimising that is equivalent to maximising the log-likelihood or the likelihood itself. #Source of R code: https://www.r-bloggers.com/logistic-regression/ mle.logreg = function(fmla, data) { # Define the negative log likelihood function logl &lt;- function(theta,x,y){ y &lt;- y x &lt;- as.matrix(x) beta &lt;- theta[1:ncol(x)] # Use the log-likelihood of the Bernouilli distribution, where p is # defined as the logistic transformation of a linear combination # of predictors, according to logit(p)=(x%*%beta) loglik &lt;- sum(-y*log(1 + exp(-(x%*%beta))) - (1-y)*log(1 + exp(x%*%beta))) return(-loglik) } # Prepare the data outcome = rownames(attr(terms(fmla),&quot;factors&quot;))[1] dfrTmp = model.frame(data) x = as.matrix(model.matrix(fmla, data=dfrTmp)) y = as.numeric(as.matrix(data[,match(outcome,colnames(data))])) # Define initial values for the parameters theta.start = rep(0,(dim(x)[2])) names(theta.start) = colnames(x) # Calculate the maximum likelihood mle = optim(theta.start,logl,x=x,y=y, method = &#39;BFGS&#39;, hessian=T) out = list(beta=mle$par,vcov=solve(mle$hessian),ll=2*mle$value) } mydata = read.csv(url(&#39;https://stats.idre.ucla.edu/stat/data/binary.csv&#39;)) mylogit1 = glm(admit~gre+gpa+as.factor(rank), family=binomial, data=mydata) mydata$rank = factor(mydata$rank) #Treat rank as a categorical variable fmla = as.formula(&quot;admit~gre+gpa+rank&quot;) #Create model formula mylogit2 = mle.logreg(fmla, mydata) #Estimate coefficients print(cbind(coef(mylogit1), mylogit2$beta)) ## [,1] [,2] ## (Intercept) -3.989979073 -3.772676422 ## gre 0.002264426 0.001375522 ## gpa 0.804037549 0.898201239 ## as.factor(rank)2 -0.675442928 -0.675543009 ## as.factor(rank)3 -1.340203916 -1.356554831 ## as.factor(rank)4 -1.551463677 -1.563396035 2.4 References http://www.columbia.edu/~so33/SusDev/Lecture_9.pdf "],
["linear-mixed-models.html", "Chapter 3 Linear Mixed Models 3.1 LM and GLM 3.2 LMM 3.3 Calculate mean 3.4 Test the treatment effect 3.5 Another example 3.6 Full LMM model 3.7 Serial correlations in time and space", " Chapter 3 Linear Mixed Models 3.1 LM and GLM Before moving to LMM, I would like to review LM and GLM first. 3.1.1 LM \\[Y|X \\sim N(\\mu(X),\\sigma^2 I)\\] \\[E(Y|X)=\\mu(X)=X^T \\beta\\] where, \\(\\mu(X): random component\\) \\(X^T \\beta: covariates\\) 3.1.2 GLM-Definition Ref: https://ocw.mit.edu/courses/mathematics/18-650-statistics-for-applications-fall-2016/lecture-slides/MIT18_650F16_GLM.pdf \\[Y \\sim exponential family\\] Link function \\[g(\\mu(X))=X^T \\beta\\] 3.1.3 GLM-log link example \\[\\mu_i = \\gamma e^{\\delta t_i}\\] Link function is log link, and it becomes: \\[log(\\mu_i) = log(\\gamma) + log(\\delta t_i)=\\beta_0+\\beta_1 t_i\\] (This is somehow similar to Poisson distribution.) 3.1.4 GLM-Reciprocal link: \\[\\mu_i=\\frac{\\alpha x_i}{h+x_i}\\] Reciprocal link: \\[g(\\mu_i)=\\frac{1}{\\mu_i}=\\frac{1}{\\alpha}+\\frac{h}{\\alpha}\\frac{1}{x_i}=\\beta_0+\\beta_1 \\frac{1}{x_i}\\] 3.1.5 GLM-exponential family: In a more general sense, for exponential family: \\[\\begin{aligned} P_{\\theta}(X)=P(X, \\theta)&amp;= e^{\\sum \\eta_i(\\theta)T_i(X)} C(\\theta)h(x)\\\\ &amp;=e^{\\sum \\eta_i(\\theta)T_i(X)} e^{-log(\\frac{1}{c(\\theta)})}h(x) \\\\ &amp;= e^{\\sum \\eta_i(\\theta)T_i(X)-log(\\frac{1}{c(\\theta)})} h(x) \\\\&amp;= e^{\\sum \\eta_i(\\theta)T_i(X)-B(\\theta)} h(x) \\end{aligned}\\] Normal distribution For normal distributions, it belongs to exponential family. \\[\\begin{aligned} P_{\\theta}(X) &amp;= \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}\\frac{(x-\\mu)^2}{\\sigma^2}}\\\\ &amp;=e^{-\\frac{1}{2}\\frac{(x-\\mu)^2}{\\sigma^2}} e^{log(\\frac{1}{\\sigma\\sqrt{2\\pi}})} \\\\ &amp;= e^{-\\frac{1}{2}\\frac{(x-\\mu)^2}{\\sigma^2}-log (\\sigma\\sqrt{2\\pi})} \\\\ &amp;= e^{-\\frac{1}{2\\sigma^2}x^2-\\frac{1}{2\\sigma^2} \\mu^2+\\frac{x\\mu}{\\sigma^2}-log(\\sqrt{2\\pi}\\sigma)}\\\\ &amp;=e^{-\\frac{1}{2\\sigma^2}x^2+\\frac{x\\mu}{\\sigma^2}-(\\frac{1}{2\\sigma^2} \\mu^2+log(\\sqrt{2\\pi}\\sigma))} \\end{aligned}\\] Where, \\(\\eta_1 =-\\frac{1}{2\\sigma^2}\\) and \\(T_1(x)=x^2\\) \\(\\eta_2 =-\\frac{\\mu}{\\sigma^2}\\) and \\(T_2(x)=x\\) \\(B(\\theta)=\\frac{1}{2\\sigma^2} \\mu^2+log(\\sqrt{2\\pi}\\sigma)\\) \\(h(x)=1\\) In the case above, \\(\\theta=(\\mu, \\sigma^2)\\). If \\(\\sigma^2\\) is known, \\(\\theta=\\mu\\). In this case, we can rewrite the normal pdf as follows. \\[\\begin{aligned} P_{\\theta}(X) &amp;=e^{-\\frac{1}{2\\sigma^2}x^2-\\frac{1}{2\\sigma^2} \\mu^2+\\frac{x\\mu}{\\sigma^2}-log(\\sqrt{2\\pi}\\sigma)}\\\\ &amp;=e^{\\frac{x\\mu}{\\sigma^2}-\\frac{1}{2\\sigma^2} \\mu^2}e^{-\\frac{1}{2\\sigma^2}x^2-log(\\sqrt{2\\pi}\\sigma)} \\end{aligned}\\] Where, \\(\\eta_1 =-\\frac{\\mu}{\\sigma^2}\\) and \\(T_1(x)=x\\) \\(B(\\theta)=\\frac{1}{2\\sigma^2} \\mu^2\\) \\(\\begin{aligned} h(x) &amp;=e^{-\\frac{1}{2\\sigma^2}x^2-log(\\sqrt{2\\pi}\\sigma)} \\\\&amp;=\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\frac{x^2}{\\sigma^2}} \\end{aligned}\\) Thus, we can see that \\(h(x)\\) is a normal pdf \\(\\sim N(0, \\sigma^2)\\). Bernoulli Another example, \\(x\\) is descrete. For example, Bernoulli: \\[ \\begin{aligned} &amp;= p^x(1-p)^{1-x} \\\\ &amp;=e^{log(p^x(1-p)^{1-x})} \\\\ &amp;= e^{xlog(p)+(1-x)log(1-p)}\\\\ &amp;= e^{xlog(p)-xlog(1-p)+log(1-p)}\\\\ &amp;=e^{xlog(\\frac{p}{1-p})+log(1-p)} \\end{aligned}\\] Where, \\(\\eta_1 =log(\\frac{p}{1-p})\\) and \\(T_1(x)=x\\) \\(B(\\theta)=log(\\frac{1}{1-p})\\) \\(h(x) =1\\) 3.1.6 Canonical exponential family Canonical exponential family: \\[f_{\\theta}(x)=e^{\\frac{x\\theta-b(\\theta)}{\\phi}+c(x,\\phi)}\\] where, \\(b(.)\\) and \\(c(.,.)\\) are known. Normal distribution Again, use the normal pdf: \\[\\begin{aligned} P_{\\theta}(X) &amp;= \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}\\frac{(x-\\mu)^2}{\\sigma^2}}\\\\ &amp;=e^{-\\frac{1}{2}\\frac{(x-\\mu)^2}{\\sigma^2}} e^{log(\\frac{1}{\\sigma\\sqrt{2\\pi}})} \\\\ &amp;= e^{-\\frac{1}{2}\\frac{(x-\\mu)^2}{\\sigma^2}-log (\\sigma\\sqrt{2\\pi})} \\\\ &amp;= e^{-\\frac{1}{2\\sigma^2}x^2-\\frac{1}{2\\sigma^2} \\mu^2+\\frac{x\\mu}{\\sigma^2}-log(\\sqrt{2\\pi}\\sigma)}\\\\ &amp;= e^{\\frac{x\\mu}{\\sigma^2}-\\frac{\\mu^2}{2\\sigma^2}+(-\\frac{1}{2\\sigma^2}x^2-log(\\sqrt{2\\pi}\\sigma)) } \\\\ &amp;=e^{\\frac{x\\mu-\\frac{1}{2}\\mu^2}{\\sigma^2}+(-\\frac{1}{2\\sigma^2}x^2-log(\\sqrt{2\\pi}\\sigma)) } \\end{aligned}\\] Where (we assume \\(\\sigma^2\\) is known.), \\(\\theta=\\mu\\) \\(\\phi =\\sigma^2\\) \\(b(\\theta)=\\frac{1}{2}\\theta^2\\) \\(\\begin{aligned} c(x, \\phi) &amp;=-\\frac{1}{2\\sigma^2}x^2-log(\\sqrt{2\\pi}\\sigma) \\\\ &amp;=-\\frac{1}{2\\sigma^2}x^2-\\frac{1}{2}log(2\\pi\\sigma^2) \\\\ &amp;=-\\frac{1}{2}(\\frac{x^2}{\\sigma^2}+log(2\\pi\\sigma^2)) \\\\ &amp;=-\\frac{1}{2}(\\frac{x^2}{\\phi}+log(2\\pi \\phi)) \\end{aligned}\\) 3.1.7 Canonical exponential family - Expected value and variance First derivative Canonical exponential family: \\[f_{\\theta}(x)=e^{\\frac{x\\theta-b(\\theta)}{\\phi}+c(x,\\phi)}\\] log likelihood (only one observation) \\[log f_{\\theta}(x)\\] \\[\\begin{aligned} E[\\frac{\\partial (logf_{\\theta}(X))}{\\partial \\theta} ] &amp;=E[\\frac{\\frac{\\partial f_{\\theta}(X)}{\\partial \\theta}}{f_{\\theta}(X)}] \\\\ &amp;= \\int \\frac{\\frac{\\partial f_{\\theta}(X)}{\\partial \\theta}}{f_{\\theta}(X)} f_{\\theta}(X) dx \\\\ &amp;= \\int \\frac{\\partial f_{\\theta}(X)}{\\partial \\theta} dx \\\\ &amp;= \\frac{\\partial}{\\partial \\theta} \\int f_{\\theta}(X)dx \\\\ &amp;= \\frac{\\partial 1}{\\partial \\theta} \\\\ &amp;=0 \\end{aligned}\\] Second derivative Second derivative \\[\\begin{aligned} E[\\frac{\\partial^2 (logf_{\\theta}(X))}{\\partial \\theta^2} ] &amp;=E[ \\frac{\\partial}{\\partial \\theta}(\\frac{\\frac{\\partial f_{\\theta}(X)}{\\partial \\theta}}{f_{\\theta}(X)})] \\\\ &amp;=E[\\frac{\\frac{\\partial^2 f_{\\theta}(X)}{\\partial \\theta^2}f_{\\theta}(X)-(\\frac{\\partial f_{\\theta}(X)}{\\partial \\theta})^2}{f^2_{\\theta}(X)}] \\\\ &amp;= \\int \\frac{\\frac{\\partial^2 f_{\\theta}(X)}{\\partial \\theta^2}f_{\\theta}(X)-(\\frac{\\partial f_{\\theta}(X)}{\\partial \\theta})^2}{f_{\\theta}(X)}dx \\\\ &amp;=\\int (\\frac{\\partial^2 f_{\\theta}(X)}{\\partial \\theta^2} - \\frac{(\\frac{\\partial f_{\\theta}(X)}{\\partial \\theta})^2}{f_{\\theta}(X)})dx \\\\ &amp;= \\int \\frac{\\partial^2 f_{\\theta}(X)}{\\partial \\theta^2} dx -\\int \\frac{(\\frac{\\partial f_{\\theta}(X)}{\\partial \\theta})^2}{f_{\\theta}(X)}dx \\\\ &amp;=\\frac{\\partial^2}{\\partial \\theta^2}\\int f_{\\theta}(X) dx -\\int \\frac{(\\frac{\\partial f_{\\theta}(X)}{\\partial \\theta})^2}{f_{\\theta}(X)}dx \\\\ &amp;=0-\\int \\frac{(\\frac{\\partial f_{\\theta}(X)}{\\partial \\theta})^2}{f_{\\theta}(X)}dx \\\\ &amp;=0-\\int \\frac{(\\frac{\\partial f_{\\theta}(X)}{\\partial \\theta})^2}{(f_{\\theta}(X))^2}f_{\\theta}(x)dx \\\\ &amp;= - E[(\\frac{\\frac{\\partial f_{\\theta}(X)}{\\partial \\theta}}{f_{\\theta}(X)})^2]\\\\ &amp;= -E[(\\frac{\\partial (logf_{\\theta}(X))}{\\partial \\theta})^2] \\end{aligned}\\] Based on the first derivative, we can get: \\[log(f_{\\theta}(X))=\\frac{X\\theta-b(\\theta)}{\\phi}+c(X,\\phi)\\] \\[E[\\frac{\\partial (log(f_{\\theta}(X)))}{\\partial \\theta}]= E[\\frac{X-b^{&#39;}(\\theta)}{\\phi}]=\\frac{E(X)-b^{&#39;}(\\theta)}{\\phi}=0\\] Thus, we can get, \\[E(X)=b^{&#39;}(\\theta)\\] For second derivative, from the calculation above, we know that, \\[\\begin{aligned} E[\\frac{\\partial^2 (logf_{\\theta}(X))}{\\partial \\theta^2}]&amp;=-E[(\\frac{\\partial (logf_{\\theta}(X))}{\\partial \\theta})^2] \\\\ &amp;= -E[(\\frac{X-b^{&#39;}(\\theta)}{\\phi})^2]\\\\ &amp;=-E[(\\frac{X-E(X)}{\\phi})^2] \\\\ &amp;= -\\frac{Var(X)}{\\phi^2}\\end{aligned}\\] At the same time, \\[\\begin{aligned} E[\\frac{\\partial^2 (logf_{\\theta}(X))}{\\partial \\theta^2}]&amp;=E[\\frac{\\partial (\\frac{X-b^{&#39;}(\\theta)}{\\phi})}{\\partial \\theta}] \\\\ &amp;= E[-\\frac{b^{&#39;&#39;}(\\theta)}{\\phi}]\\\\ &amp;= - \\frac{b^{&#39;&#39;}(\\theta)}{\\phi} \\end{aligned}\\] Thus, \\[Var(X)=b^{&#39;&#39;}(\\theta) \\phi\\] 3.1.8 Expected value and variance - Possion Example Example of possion distribution \\[P(\\lambda)=\\frac{\\lambda^k e^{-\\lambda}}{k!}\\] If we put \\(k\\) as \\(y\\), and \\(\\lambda\\) as \\(\\mu\\), we can get: \\[P(\\mu)=\\frac{\\mu^y e^{-\\mu}}{y!}\\] Compare to, \\[f_{\\theta}(y)=e^{\\frac{y\\theta-b(\\theta)}{\\phi}+c(y,\\phi)}\\] We can write it as the exponential format: \\[\\begin{aligned} P(\\mu) &amp;=\\frac{\\mu^y e^{-\\mu}}{y!} \\\\ &amp;= e^{log(\\mu^y)+log(e^{-\\mu})-log(y!)} \\\\ &amp;= e^{ylog(\\mu)-\\mu-log(y!)}\\end{aligned}\\] We thus know that \\(\\theta=log(\\mu)\\). We can contintue to write the equation above as follows. \\[=e^{y\\theta-e^{\\theta}-log(y!)}\\] Thus, we can get: \\[E(X)=\\frac{\\partial (e^{\\theta})}{\\partial \\theta}=e^{\\theta}=\\mu\\] \\[Var(X)=\\frac{\\partial^{&#39;&#39;} (e^{\\theta})}{\\partial \\theta^2} \\phi=\\frac{\\partial^{&#39;&#39;} (e^{\\theta})}{\\partial \\theta^2}=\\mu\\] 3.1.9 Canonical link A link functin can link \\(X^T \\beta\\) to the mean \\(\\mu\\). That is, \\[g(\\mu)=X^T \\beta \\rightarrow \\mu = g^{-1}(X^T \\beta)\\] We know that \\[\\mu = b^{&#39;}(\\theta)\\] Thus, \\[ b^{&#39;}(\\theta)=g^{-1}(X^T \\beta)\\] Thus, \\[g=b^{&#39; -1}(\\theta)\\] 3.1.10 Canonical link - Bernoulli PMF of Bernoulli: \\[ \\begin{aligned} &amp;= p^y(1-p)^{1-y} \\\\ &amp;=e^{log(p^y(1-p)^{1-y})} \\\\ &amp;= e^{ylog(p)+(1-y)log(1-p)}\\\\ &amp;= e^{ylog(p)-ylog(1-p)+log(1-p)}\\\\ &amp;=e^{ylog(\\frac{p}{1-p})+log(1-p)} \\end{aligned} \\] Copared to the following: \\[f_{\\theta}(y)=e^{\\frac{y\\theta-b(\\theta)}{\\phi}+c(y,\\phi)}\\] We need to change the format of Bernoulli: \\[\\theta= log \\frac{p}{1-p}\\] Thus, \\[e^{\\theta}=\\frac{p}{1-p} \\rightarrow p=\\frac{e^{\\theta}}{1+e^{\\theta}} \\] After that, we can contintue the Bernoulli: \\[\\begin{aligned} &amp;= e^{y\\theta+log(1-\\frac{e^{\\theta}}{1+e^{\\theta}})} \\\\ &amp;=e^{y\\theta+log(\\frac{1}{1+e^{\\theta}})} \\\\ &amp;=e^{y\\theta-log(1+e^{\\theta})} \\end{aligned}\\] Where, \\[b(\\theta)=log(1+e^{\\theta})\\] We can then try to calculate the derivative: \\[b^{&#39;}(\\theta)=\\frac{\\partial (log(1+e^{\\theta}))}{\\partial \\theta}=\\frac{e^{\\theta}}{1+e^{\\theta}}\\] We know that \\[b^{&#39;}(\\theta)=\\mu\\] Thus, we can get \\[\\mu=\\frac{e^{\\theta}}{1+e^{\\theta}}\\] We can then calculate the inverse function: \\[\\theta=log(\\frac{\\mu}{1-\\mu})\\] Thus, \\[g(\\mu)=log(\\frac{\\mu}{1-\\mu})=X^T \\beta\\] 3.1.11 NR - Bernoulli We know that the PMF for Bernoulli: \\[\\begin{aligned} &amp;= p^y(1-p)^{1-y} \\\\ &amp;=e^{y\\theta-log(1+e^{\\theta})} \\\\ &amp;=e^{yx^T \\beta-log(1+e^{x^T \\beta})} \\end{aligned}\\] Thus, \\[\\ell(\\beta|Y,X)=\\sum_{i=1}^{n}(Y_iX_i^{T}\\beta-log(1+e^{X_i^T \\beta}))\\] Thus, teh gradient is: \\[\\nabla_{\\ell}(\\beta)=\\sum_{i=1}^{n}(Y_iX_i - \\frac{e^{X_i^T \\beta}}{1+e^{X_i^T \\beta}})\\] The Hessian is: \\[H_{\\ell}(\\beta)=-\\sum_{i=1}^{n}\\frac{e^{X_i^T \\beta}}{(1+e^{X_i^T \\beta})^2}X_iX_i^T\\] Thus, \\[\\beta^{k+1}=\\beta^k-(H_{\\ell}(\\beta^k))^{-1}\\nabla_{\\ell}(\\beta^k) \\] 3.1.12 Iteratively Re-weighted Least Squares 3.2 LMM The following is a shortened version of Jonathan Rosenblatt’s LMM tutorial. http://www.john-ros.com/Rcourse/lme.html. In addition, another reference is from Douglas Bates’s R package document. https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf?fbclid=IwAR1nmmRP9A0BrhKdgBibNjM5acR_spTpXV8QlQGdmTWyQz3ZtV3LYn6kCbQ Assume that \\(y\\) is a function of \\(x\\) and \\(u\\), where \\(x\\) is the fixed effect and \\(u\\) is the random effect. Thus, we can get, \\[y|x, u = x&#39;\\beta+z&#39;u+\\epsilon\\] For random effect, one example can be that you want to test the treatment effect, and sample 8 observations from 4 groups. You measure before and after the treatment. In this case, \\(x\\) represents the treatment effect, whereas \\(z\\) represents the group effect (i.e., random effect). Note that, in this case, it reminds the paired t-test. Remember in SPSS, why do we do paired t-test? Typically, it is the case when we measure a subject (or, participant) twice. In this case, we can consider each participant as an unit of random effect (rather than as group in the last example.) 3.3 Calculate mean The following code generates 4 numbers (\\(N(0,10)\\)) for 4 groups. Then, replicate it within each group.That is, in the end, there are 8 observations. Note that, in the following code, there are no “independent variables”. Both the linear model and mixed model are actually just trying to calculate the mean. Note that lmer(y~1+1|groups) and lmer(y~1|groups) will generate the same results. set.seed(123) n.groups &lt;- 4 # number of groups n.repeats &lt;- 2 # samples per group #Generating index for observations belong to the same group groups &lt;- as.factor(rep(1:n.groups, each=n.repeats)) n &lt;- length(groups) #Generating 4 random numbers, assuming normal distribution z0 &lt;- rnorm(n.groups, 0, 10) z &lt;- z0[as.numeric(groups)] # generate and inspect random group effects z ## [1] -5.6047565 -5.6047565 -2.3017749 -2.3017749 15.5870831 15.5870831 0.7050839 ## [8] 0.7050839 epsilon &lt;- rnorm(n,0,1) # generate measurement error beta0 &lt;- 2 # this is the actual parameter of interest! The global mean. y &lt;- beta0 + z + epsilon # sample from an LMM # fit a linear model assuming independence # i.e., assume that there is no &quot;group things&quot;. lm.5 &lt;- lm(y~1) # fit a mixed-model that deals with the group dependence #install.packages(&quot;lme4&quot;) library(lme4) ## Loading required package: Matrix lme.5.a &lt;- lmer(y~1+1|groups) lme.5.b &lt;- lmer(y~1|groups) lm.5 ## ## Call: ## lm(formula = y ~ 1) ## ## Coefficients: ## (Intercept) ## 4.283 lme.5.a ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: y ~ 1 + 1 | groups ## REML criterion at convergence: 36.1666 ## Random effects: ## Groups Name Std.Dev. ## groups (Intercept) 8.8521 ## Residual 0.8873 ## Number of obs: 8, groups: groups, 4 ## Fixed Effects: ## (Intercept) ## 4.283 lme.5.b ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: y ~ 1 | groups ## REML criterion at convergence: 36.1666 ## Random effects: ## Groups Name Std.Dev. ## groups (Intercept) 8.8521 ## Residual 0.8873 ## Number of obs: 8, groups: groups, 4 ## Fixed Effects: ## (Intercept) ## 4.283 3.4 Test the treatment effect As we can see that, LLM and paired t-test generate the same t-value. times&lt;-rep(c(1,2),4) # first time and second time times ## [1] 1 2 1 2 1 2 1 2 data_combined&lt;-cbind(y,groups,times) data_combined ## y groups times ## [1,] -3.4754687 1 1 ## [2,] -1.8896915 1 2 ## [3,] 0.1591413 2 1 ## [4,] -1.5668361 2 2 ## [5,] 16.9002303 3 1 ## [6,] 17.1414212 3 2 ## [7,] 3.9291657 4 1 ## [8,] 3.0648977 4 2 lme_diff_times&lt;- lmer(y~times+(1|groups)) t_results&lt;-t.test(y~times, paired=TRUE) lme_diff_times ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: y ~ times + (1 | groups) ## REML criterion at convergence: 35.0539 ## Random effects: ## Groups Name Std.Dev. ## groups (Intercept) 8.845 ## Residual 1.013 ## Number of obs: 8, groups: groups, 4 ## Fixed Effects: ## (Intercept) times ## 4.5691 -0.1908 print(&quot;The following results are from paired t-test&quot;) ## [1] &quot;The following results are from paired t-test&quot; t_results$statistic ## t ## 0.2664793 3.5 Another example data(Dyestuff, package=&#39;lme4&#39;) attach(Dyestuff) Dyestuff ## Batch Yield ## 1 A 1545 ## 2 A 1440 ## 3 A 1440 ## 4 A 1520 ## 5 A 1580 ## 6 B 1540 ## 7 B 1555 ## 8 B 1490 ## 9 B 1560 ## 10 B 1495 ## 11 C 1595 ## 12 C 1550 ## 13 C 1605 ## 14 C 1510 ## 15 C 1560 ## 16 D 1445 ## 17 D 1440 ## 18 D 1595 ## 19 D 1465 ## 20 D 1545 ## 21 E 1595 ## 22 E 1630 ## 23 E 1515 ## 24 E 1635 ## 25 E 1625 ## 26 F 1520 ## 27 F 1455 ## 28 F 1450 ## 29 F 1480 ## 30 F 1445 lme_batch&lt;- lmer( Yield ~ 1 + (1|Batch) , Dyestuff ) summary(lme_batch) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Yield ~ 1 + (1 | Batch) ## Data: Dyestuff ## ## REML criterion at convergence: 319.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.4117 -0.7634 0.1418 0.7792 1.8296 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Batch (Intercept) 1764 42.00 ## Residual 2451 49.51 ## Number of obs: 30, groups: Batch, 6 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 1527.50 19.38 78.8 3.6 Full LMM model In the following, I used the data from the package of lme4. For Days + (1 | Subject), it only has random intercept; in contrast, Days + ( Days| Subject ) has both random intercept and random slope for Days. Note that, random effects do not generate specific slopes for each level of Days, but rather just a variance of all the slopes. Therefore, we can see that “Days + ( Days| Subject )” and “Days + ( 1+Days| Subject )” generate the same results. For more discussion, you can refer to the following link: https://www.jaredknowles.com/journal/2013/11/25/getting-started-with-mixed-effect-models-in-r data(sleepstudy, package=&#39;lme4&#39;) attach(sleepstudy) fm1 &lt;- lmer(Reaction ~ Days + (1 | Subject), sleepstudy) summary(fm1) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Reaction ~ Days + (1 | Subject) ## Data: sleepstudy ## ## REML criterion at convergence: 1786.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2257 -0.5529 0.0109 0.5188 4.2506 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Subject (Intercept) 1378.2 37.12 ## Residual 960.5 30.99 ## Number of obs: 180, groups: Subject, 18 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 251.4051 9.7467 25.79 ## Days 10.4673 0.8042 13.02 ## ## Correlation of Fixed Effects: ## (Intr) ## Days -0.371 fm2&lt;-lmer ( Reaction ~ Days + ( Days| Subject ) , data= sleepstudy ) summary(fm2) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Reaction ~ Days + (Days | Subject) ## Data: sleepstudy ## ## REML criterion at convergence: 1743.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.9536 -0.4634 0.0231 0.4633 5.1793 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Subject (Intercept) 611.90 24.737 ## Days 35.08 5.923 0.07 ## Residual 654.94 25.592 ## Number of obs: 180, groups: Subject, 18 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 251.405 6.824 36.843 ## Days 10.467 1.546 6.771 ## ## Correlation of Fixed Effects: ## (Intr) ## Days -0.138 fm3&lt;-lmer ( Reaction ~ Days + (1+Days| Subject ) , data= sleepstudy ) summary(fm3) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Reaction ~ Days + (1 + Days | Subject) ## Data: sleepstudy ## ## REML criterion at convergence: 1743.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.9536 -0.4634 0.0231 0.4633 5.1793 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Subject (Intercept) 611.90 24.737 ## Days 35.08 5.923 0.07 ## Residual 654.94 25.592 ## Number of obs: 180, groups: Subject, 18 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 251.405 6.824 36.843 ## Days 10.467 1.546 6.771 ## ## Correlation of Fixed Effects: ## (Intr) ## Days -0.138 3.7 Serial correlations in time and space The hierarchical model of \\(y|x, u = x&#39;\\beta+z&#39;u+\\epsilon\\) can work well for correlations within blocks, but not for correlations in time as the correlations decay in time. The following uses nlme package to calculate time serial data. library(nlme) ## ## Attaching package: &#39;nlme&#39; ## The following object is masked from &#39;package:lme4&#39;: ## ## lmList head(nlme::Ovary,n=50) ## Grouped Data: follicles ~ Time | Mare ## Mare Time follicles ## 1 1 -0.13636360 20 ## 2 1 -0.09090910 15 ## 3 1 -0.04545455 19 ## 4 1 0.00000000 16 ## 5 1 0.04545455 13 ## 6 1 0.09090910 10 ## 7 1 0.13636360 12 ## 8 1 0.18181820 14 ## 9 1 0.22727270 13 ## 10 1 0.27272730 20 ## 11 1 0.31818180 22 ## 12 1 0.36363640 15 ## 13 1 0.40909090 18 ## 14 1 0.45454550 17 ## 15 1 0.50000000 14 ## 16 1 0.54545450 18 ## 17 1 0.59090910 14 ## 18 1 0.63636360 16 ## 19 1 0.68181820 17 ## 20 1 0.72727270 18 ## 21 1 0.77272730 18 ## 22 1 0.81818180 17 ## 23 1 0.86363640 14 ## 24 1 0.90909090 12 ## 25 1 0.95454550 12 ## 26 1 1.00000000 14 ## 27 1 1.04545500 10 ## 28 1 1.09090900 11 ## 29 1 1.13636400 16 ## 30 2 -0.15000000 6 ## 31 2 -0.10000000 6 ## 32 2 -0.05000000 8 ## 33 2 0.00000000 7 ## 34 2 0.05000000 16 ## 35 2 0.10000000 10 ## 36 2 0.15000000 13 ## 37 2 0.20000000 9 ## 38 2 0.25000000 7 ## 39 2 0.30000000 6 ## 40 2 0.35000000 8 ## 41 2 0.40000000 8 ## 42 2 0.45000000 6 ## 43 2 0.50000000 8 ## 44 2 0.55000000 7 ## 45 2 0.60000000 9 ## 46 2 0.65000000 6 ## 47 2 0.70000000 4 ## 48 2 0.75000000 5 ## 49 2 0.80000000 8 ## 50 2 0.85000000 11 fm1Ovar.lme &lt;- nlme::lme(fixed=follicles ~ sin(2*pi*Time) + cos(2*pi*Time), data = Ovary, random = pdDiag(~sin(2*pi*Time)), correlation=corAR1() ) summary(fm1Ovar.lme) ## Linear mixed-effects model fit by REML ## Data: Ovary ## AIC BIC logLik ## 1563.448 1589.49 -774.724 ## ## Random effects: ## Formula: ~sin(2 * pi * Time) | Mare ## Structure: Diagonal ## (Intercept) sin(2 * pi * Time) Residual ## StdDev: 2.858385 1.257977 3.507053 ## ## Correlation Structure: AR(1) ## Formula: ~1 | Mare ## Parameter estimate(s): ## Phi ## 0.5721866 ## Fixed effects: follicles ~ sin(2 * pi * Time) + cos(2 * pi * Time) ## Value Std.Error DF t-value p-value ## (Intercept) 12.188089 0.9436602 295 12.915760 0.0000 ## sin(2 * pi * Time) -2.985297 0.6055968 295 -4.929513 0.0000 ## cos(2 * pi * Time) -0.877762 0.4777821 295 -1.837159 0.0672 ## Correlation: ## (Intr) s(*p*T ## sin(2 * pi * Time) 0.000 ## cos(2 * pi * Time) -0.123 0.000 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.34910093 -0.58969626 -0.04577893 0.52931186 3.37167486 ## ## Number of Observations: 308 ## Number of Groups: 11 "],
["basic-stat-concepts.html", "Chapter 4 Basic Stat Concepts 4.1 Score 4.2 Gradient and Jacobian 4.3 Hessian and Fisher Information 4.4 Canonical link function 4.5 Ordinary Least Squares (OLS) 4.6 Taylor series 4.7 Fisher scoring 4.8 References", " Chapter 4 Basic Stat Concepts 4.1 Score The score is the gradient (the vector of partial derivatives) of \\(log L(\\theta)\\), with respect to an m-dimensional parameter vector \\(\\theta\\). \\[S(\\theta) = \\frac{\\partial\\ell}{\\partial \\theta}\\] Typically, they use \\(\\nabla\\) to denote the partical derivative. \\[\\nabla \\ell\\] Such differentiation will generate a \\(m \\times 1\\) row vector, which indicates the sensitivity of the likelihood. Quote from Steffen Lauritzen’s slides: “Generally the solution to this equation must be calculated by iterative methods. One of the most common methods is the Newton–Raphson method and this is based on successive approximations to the solution, using Taylor’s theorem to approximate the equation.” For instance, using logit link, we can get the first derivative of log likelihood logistic regression as follows. We can not really find \\(\\beta\\) easily to make the equation to be 0. \\[\\begin{aligned} \\frac{\\partial \\ell} {\\partial \\beta} &amp;= \\sum_{i=1}^{n}x_i^T[y_i-\\frac{e^{\\beta^Tx_i}}{1+e^{\\beta^Tx_i}}] \\\\ &amp;=\\sum_{i=1}^{n} x_i^T[y_i-\\hat{y_i}] \\end{aligned}\\] 4.2 Gradient and Jacobian Remarks: This part discusses gradient in a more general sense. When \\(f(x)\\) is only in a single dimension space: \\(\\mathbb{R}^n \\rightarrow \\mathbb{R}\\) \\[\\nabla f(x)=[\\frac{\\partial f}{\\partial x_1},\\frac{\\partial f}{\\partial x_2},...,\\frac{\\partial f}{\\partial x_n}]\\] When \\(f(x)\\) is only in a m-dimension space (i.e., Jacobian): \\(\\mathbb{R}^n \\rightarrow \\mathbb{R^m}\\) \\[Jac(f)=\\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_1} &amp; \\frac{\\partial f_1}{\\partial x_2} &amp; \\frac{\\partial f_1}{\\partial x_3} &amp; ... &amp; \\frac{\\partial f_1}{\\partial x_n}\\\\ \\frac{\\partial f_2}{\\partial x_1} &amp; \\frac{\\partial f_2}{\\partial x_2} &amp; \\frac{\\partial f_2}{\\partial x_3} &amp; ... &amp; \\frac{\\partial f_2}{\\partial x_n} \\\\ ...\\\\ \\frac{\\partial f_m}{\\partial x_1} &amp; \\frac{\\partial f_m}{\\partial x_2} &amp; \\frac{\\partial f_n}{\\partial x_3} &amp; ... &amp; \\frac{\\partial f_m}{\\partial x_n} \\end{bmatrix}\\] For instance, \\(\\mathbb{R}^n \\rightarrow \\mathbb{R}\\): \\[f(x,y)=x^2+2y\\] \\[\\nabla f(x,y)=[\\frac{\\partial f}{\\partial x},\\frac{\\partial f}{\\partial y}]=[2x,2]\\] \\(\\mathbb{R}^n \\rightarrow \\mathbb{R^m}\\) \\[f(x,y)=(x^2+2y,x^3)\\] \\[Jac(f)=\\begin{bmatrix} 2x &amp; 2\\\\ 2x^2 &amp; 0 \\end{bmatrix}\\] 4.3 Hessian and Fisher Information Hessian matrix or Hessian is a square matrix of second-order partial derivatives of a scalar-valued function, or scalar field. \\(\\mathbb{R}^n \\rightarrow \\mathbb{R}\\) \\[Hessian=\\nabla ^2(f) =\\begin{bmatrix} \\frac{\\partial^2 f}{\\partial x_1^2} &amp; \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} &amp; \\frac{\\partial^2 f}{\\partial x_1 \\partial x_3} &amp; ... &amp; \\frac{\\partial^2 f}{\\partial x_1 \\partial x_n}\\\\ \\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} &amp; \\frac{\\partial^2 f}{\\partial x_2^2} &amp; \\frac{\\partial^2 f}{\\partial x_2 \\partial x_3} &amp; ... &amp; \\frac{\\partial^2 f}{\\partial x_2 \\partial x_n} \\\\ \\frac{\\partial^2 f}{\\partial x_3 \\partial x_1} &amp; \\frac{\\partial^2 f}{\\partial x_3 \\partial x_2} &amp; \\frac{\\partial^2 f}{\\partial x_3^2} &amp; ... &amp; \\frac{\\partial^2 f}{\\partial x_3 \\partial x_n} \\\\ ...\\\\ \\frac{\\partial^2 f}{\\partial x_n \\partial x_1} &amp; \\frac{\\partial^2 f}{\\partial x_n \\partial x_2} &amp; \\frac{\\partial^2 f}{\\partial x_n \\partial x_3} &amp; ... &amp; \\frac{\\partial^2 f}{\\partial x_n^2} \\end{bmatrix}\\] As a special case, in the context of logit: Suppose that the log likelihood function is \\(\\ell (\\theta)\\). \\(\\theta\\) is a \\(m\\) demension vector. \\[ \\theta = \\begin{bmatrix}\\theta_1 \\\\ \\theta_2 \\\\ \\theta_3 \\\\ \\theta_4 \\\\ ...\\\\ \\theta_m \\\\ \\end{bmatrix}\\] \\[Hessian=\\nabla ^2(\\ell) =\\begin{bmatrix} \\frac{\\partial^2 \\ell}{\\partial \\theta_1^2} &amp; \\frac{\\partial^2 \\ell}{\\partial \\theta_1 \\partial \\theta_2} &amp; \\frac{\\partial^2 \\ell}{\\partial \\theta_1 \\partial \\theta_3} &amp; ... &amp; \\frac{\\partial^2 \\ell}{\\partial \\theta_1 \\partial \\theta_m}\\\\ \\frac{\\partial^2 \\ell}{\\partial \\theta_2 \\partial \\theta_1} &amp; \\frac{\\partial^2 \\ell}{\\partial \\theta_2^2 } &amp; \\frac{\\partial^2 \\ell}{\\partial \\theta_1 \\partial \\theta_3} &amp; ... &amp; \\frac{\\partial^2 \\ell}{\\partial \\theta_1 \\partial \\theta_m} \\\\ \\frac{\\partial^2 \\ell}{\\partial \\theta_3 \\partial \\theta_1} &amp; \\frac{\\partial^2 \\ell}{\\partial \\theta_3 \\theta_2 } &amp; \\frac{\\partial^2 \\ell}{\\partial \\theta_3^2} &amp; ... &amp; \\frac{\\partial^2 \\ell}{\\partial \\theta_3 \\partial \\theta_m} \\\\ ...\\\\ \\frac{\\partial^2 \\ell}{\\partial \\theta_m \\partial \\theta_1} &amp; \\frac{\\partial^2 \\ell}{\\partial \\theta_m \\theta_2 } &amp; \\frac{\\partial^2 \\ell}{\\partial \\theta_m \\partial \\theta_3} &amp; ... &amp; \\frac{\\partial^2 \\ell}{\\partial \\theta_m \\partial \\theta_m} \\end{bmatrix}\\] “In statistics, the observed information, or observed Fisher information, is the negative of the second derivative (the Hessian matrix) of the”log-likelihood&quot; (the logarithm of the likelihood function). It is a sample-based version of the Fisher information.&quot; (Direct quote from Wikipedia.) Thus, the observed information matrix: \\[-Hessian=-\\nabla ^2(\\ell) \\] Expected (Fisher) information matrix: \\[E[-\\nabla ^2(\\ell)] \\] 4.4 Canonical link function Inspired by a Stack Exchange post, I created the following figure: \\[ \\frac{Paramter}{\\theta} \\longrightarrow \\gamma^{&#39;}(\\theta) = \\mu \\longrightarrow \\frac{Mean}{\\mu} \\longrightarrow g(\\mu) = \\eta \\longrightarrow \\frac{ Linear predictor}{\\eta} \\] For the case of \\(n\\) time Bernoulli (i.e., Binomial), its canonical link function is logit. Specifically, \\[ \\frac{Paramter}{\\theta=\\beta^Tx_i} \\longrightarrow \\gamma^{&#39;}(\\theta)= \\frac{e^{\\beta^Tx_i}}{1+e^{\\beta^Tx_i}}\\longrightarrow \\frac{Mean}{\\mu=\\frac{e^{\\beta^Tx_i}}{1+e^{\\beta^Tx_i}}}\\longrightarrow g(\\mu) = log \\frac{\\frac{e^{\\beta^Tx_i}}{1+e^{\\beta^Tx_i}}}{1-\\frac{e^{\\beta^Tx_i}}{1+e^{\\beta^Tx_i}}}\\longrightarrow \\frac{ Linear predictor}{\\eta = \\beta^Tx_i}\\] Thus, we can see that, \\[\\theta \\equiv \\eta \\] The link function \\(g(\\mu)\\) relates the linear predictor \\(\\eta = \\beta^Tx_i\\) to the mean \\(\\mu\\). Remarks: Parameter is \\(\\theta = \\beta ^T x_i\\) (Not \\(\\mu\\)!). \\(\\mu=p(y=1)=\\frac{e^{\\beta^Tx_i}}{1+e^{\\beta^Tx_i}}\\) (Not logit!). Link function (i.e., \\(g(\\mu)\\)) = logit = logarithm of odds = log \\(\\frac{Event - Happened }{Event - Not - Happened}\\). \\(g(\\mu) = log \\frac{\\mu}{1-\\mu}=\\beta^T x_i\\). Thus, link function = linear predictor = log odds! Quote from the Stack Exchange post “Newton Method and Fisher scoring for finding the ML estimator coincide, these links simplify the derivation of the MLE.” (Recall, we know that \\(\\mu\\) or \\(p(y=1)\\) is the mean function. Recall that, \\(n\\) trails of coin flips, and get \\(p\\) heads. Thus \\(\\mu = \\frac{p}{n}\\).) 4.5 Ordinary Least Squares (OLS) Suppose we have \\(n\\) observation, and \\(m\\) variables. \\[\\begin{bmatrix} x_{11} &amp; x_{12} &amp; x_{13} &amp; ... &amp; x_{1m}\\\\ x_{21} &amp; x_{22} &amp; x_{23} &amp; ... &amp; x_{2m} \\\\ ...\\\\ x_{n1} &amp; x_{n2} &amp; x_{n3} &amp; ... &amp; x_{nm} \\end{bmatrix}\\] Thus, we can write it as the following \\(n\\) equations. \\[y_1=\\beta_0+\\beta_1 x_{11}+\\beta_2 x_{12}+...+ \\beta_m x_{1m}\\] \\[y_2=\\beta_0+\\beta_1 x_{21}+\\beta_2 x_{22}+...+ \\beta_m x_{2m}\\] \\[y_3=\\beta_0+\\beta_1 x_{31}+\\beta_2 x_{32}+...+ \\beta_m x_{3m}\\] \\[...\\] \\[y_n=\\beta_0+\\beta_1 x_{n1}+\\beta_2 x_{n2}+...+ \\beta_m x_{nm}\\] We can combine all the \\(n\\) equations as the following one: \\[y_i=\\beta_0+\\beta_1 x_{i1}+\\beta_2 x_{i2}+...+ \\beta_m x_{im} (i \\in [1,n])\\] We can further rewrite it as a matrix format as follows. \\[y= X \\beta\\] Where, \\[y = \\begin{bmatrix}y_1 \\\\ y_2 \\\\ y_3 \\\\ y_4 \\\\ ...\\\\ y_n \\\\ \\end{bmatrix}\\] \\[X=\\begin{bmatrix} 1 &amp; x_{11} &amp; x_{12} &amp; x_{13} &amp; ... &amp; x_{1m}\\\\ 1 &amp; x_{21} &amp; x_{22} &amp; x_{23} &amp; ... &amp; x_{2m} \\\\ ...\\\\ 1 &amp; x_{n1} &amp; x_{n2} &amp; x_{n3} &amp; ... &amp; x_{nm} \\end{bmatrix}\\] \\[\\beta = \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\\\ ...\\\\ \\beta_m \\\\ \\end{bmatrix}\\] Since later we need the inverse of \\(X\\), we need to make it into a square matrix. \\[X^Ty=X^TX \\hat{\\beta} \\Rightarrow \\hat{\\beta} = (X^TX)^{-1} X^Ty\\] We can use R to implement this calculation. As we can see, there is no need to do any iterations at all, but rather just pure matrix calculation. X&lt;-matrix(rnorm(1000),ncol=2) # we define a 2 column matrix, with 500 rows X&lt;-cbind(1,X) # add a 1 constant beta_true&lt;-c(2,1,2) # True regression coefficients beta_true&lt;-as.matrix(beta_true) y=X%*%beta_true+rnorm(500) transposed_X&lt;-t(X) beta_hat&lt;-solve(transposed_X%*%X)%*%transposed_X%*%y beta_hat ## [,1] ## [1,] 2.017690 ## [2,] 1.054682 ## [3,] 2.037671 Side Notes The function of as.matrix will automatically make c(2,1,2) become the dimension of \\(3 \\times 1\\), you do not need to transpose the \\(\\beta\\). 4.6 Taylor series \\[\\begin{aligned} f(x)|_{a} &amp;=f(a)+\\frac{f^{&#39;}(a)}{1!}(x-a)+\\frac{f^{&#39;}(a)}{2!}(x-a)^2+\\frac{f^{&#39;&#39;}(a)}{3!}(x-a)^{3}+...\\\\&amp;=\\sum_{n=0}^{\\infty} \\frac{f^{n}(a)}{n!}(x-a)^n \\end{aligned}\\] For example: \\[\\begin{aligned} e^x |_{a=0} &amp;= e^a+ \\frac{e^a}{1!}(x-a)+\\frac{e^a}{2!}(x-a)^2+...+\\frac{e^a}{n!}(x-a)^n \\\\ &amp;= 1+ \\frac{1}{1!}x+\\frac{1}{2!}x^2+...+\\frac{1}{n!}x^n \\end{aligned}\\] if \\(x=2\\) \\(e^2 = 7.389056\\) \\(e^2 \\approx 1+\\frac{1}{1!}x =1+\\frac{1}{1!}2=3\\) \\(e^2 \\approx 1+\\frac{1}{1!}x+\\frac{1}{2!}x^2 =1+\\frac{1}{1!}2 + \\frac{1}{2!}2 =5\\) … \\(e^2 \\approx 1+\\frac{1}{1!}x+\\frac{1}{2!}x^2 +\\frac{1}{3!}x^2+\\frac{1}{4!}x^2+\\frac{1}{5!}x^2=7.2666...\\) 4.7 Fisher scoring [I will come back to this later.] https://www2.stat.duke.edu/courses/Fall00/sta216/handouts/diagnostics.pdf https://stats.stackexchange.com/questions/176351/implement-fisher-scoring-for-linear-regression 4.8 References Steffen Lauritzen’s slides: http://www.stats.ox.ac.uk/~steffen/teaching/bs2HT9/scoring.pdf The Stack Exchange post: https://stats.stackexchange.com/questions/40876/what-is-the-difference-between-a-link-function-and-a-canonical-link-function Wilipedia for OLS https://en.wikipedia.org/wiki/Ordinary_least_squares Gradient and Jacobian https://math.stackexchange.com/questions/1519367/difference-between-gradient-and-jacobian https://www.youtube.com/watch?v=3xVMVT-2_t4 https://math.stackexchange.com/questions/661195/what-is-the-difference-between-the-gradient-and-the-directional-derivative Hessian https://en.wikipedia.org/wiki/Hessian_matrix Observed information https://en.wikipedia.org/wiki/Observed_information Fisher information https://people.missouristate.edu/songfengzheng/Teaching/MTH541/Lecture%20notes/Fisher_info.pdf Link function https://en.wikipedia.org/wiki/Generalized_linear_model#Link_function https://stats.stackexchange.com/questions/40876/what-is-the-difference-between-a-link-function-and-a-canonical-link-function "],
["basic-r.html", "Chapter 5 Basic R 5.1 apply, lapply, sapply 5.2 C", " Chapter 5 Basic R This section is about R coding. 5.1 apply, lapply, sapply 5.1.1 apply m_trying &lt;- matrix(C&lt;-(1:10),nrow=2, ncol=5) m_trying ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 3 5 7 9 ## [2,] 2 4 6 8 10 ## Operating on the columns apply(m_trying, 2, sum) ## [1] 3 7 11 15 19 ## Operating on the rows apply(m_trying, 1, sum) ## [1] 25 30 5.1.2 lapply “lapply returns a list of the same length as X, each element of which is the result of applying FUN to the corresponding element of X.” lapply operates on lists. Thus, as we can see below, even if m_trying is not a list, each cell becomes a list. results1&lt;-lapply(m_trying,sum) str(results1) ## List of 10 ## $ : int 1 ## $ : int 2 ## $ : int 3 ## $ : int 4 ## $ : int 5 ## $ : int 6 ## $ : int 7 ## $ : int 8 ## $ : int 9 ## $ : int 10 is.list(results1) ## [1] TRUE 5.1.3 sapply “sapply() function takes list, vector or data frame as input and gives output in vector or matrix.” results2&lt;-sapply(m_trying, sum) str(results2) ## int [1:10] 1 2 3 4 5 6 7 8 9 10 is.list(results2) ## [1] FALSE is.matrix(results2) ## [1] FALSE is.data.frame(results2) ## [1] FALSE is.vector(results2) ## [1] TRUE 5.2 C mydata1&lt;-matrix(runif(4*2),4,2) mydata1 ## [,1] [,2] ## [1,] 0.7767640 0.3839558 ## [2,] 0.8404593 0.9506320 ## [3,] 0.8705815 0.7041046 ## [4,] 0.9530419 0.4219814 str(mydata1) ## num [1:4, 1:2] 0.777 0.84 0.871 0.953 0.384 ... mydata2&lt;-c(mydata1) mydata2 ## [1] 0.7767640 0.8404593 0.8705815 0.9530419 0.3839558 0.9506320 0.7041046 ## [8] 0.4219814 str(mydata2) ## num [1:8] 0.777 0.84 0.871 0.953 0.384 ... "],
["computing-techniques.html", "Chapter 6 Computing Techniques 6.1 Monte carlo approximation 6.2 Importance sampling 6.3 Newton Raphson algorithm 6.4 Metropolis Hastings 6.5 EM 6.6 References", " Chapter 6 Computing Techniques Since GLMM can use EM algorithm in its maximum likelihood calculation (see McCulloch, 1994), it is practically useful to rehearse EM and other computing techniques. 6.1 Monte carlo approximation Example: calculate the integral of \\(p(z&gt;2)\\) when \\(z \\sim N(0,1)\\). To use Monte Carlo approximation, we can have an indicator function, which will determine whether the sample from \\(N(0,1)\\) will be included into the calculation of the integral. Nsim=10^4 indicator=function(x){ y=ifelse((x&gt;2),1,0) return(y)} newdata&lt;-rnorm(Nsim, 0,1 ) mc=c(); v=c(); upper=c(); lower=c() for (j in 1:Nsim) { mc[j]=mean(indicator(newdata[1:j])) v[j]=(j^{-1})*var(indicator(newdata[1:j])) upper[j]=mc[j]+1.96*sqrt(v[j]) lower[j]=mc[j]-1.96*sqrt(v[j]) } library(ggplot2) values=c(mc,upper,lower) type=c(rep(&quot;mc&quot;,Nsim),rep(&quot;upper&quot;,Nsim),rep(&quot;lower&quot;,Nsim)) iter=rep(seq(1:Nsim),3) data=data.frame(val=values, tp=type, itr=iter) Rcode&lt;-ggplot(data,aes(itr,val,col=tp))+geom_line(size=0.5) Rcode+geom_hline(yintercept=1-pnorm(2),color=&quot;green&quot;,size=0.5) ## Warning: Removed 2 rows containing missing values (geom_path). 6.2 Importance sampling Importance sampling has samples generated from a different distribution than the distribution of interest. Specifically, assume that we want to calculate the expected value of \\(h(x)\\), and \\(x \\sim f(x)\\). \\[E(h(x))=\\int h(x) f(x) dx = \\int h(x) \\frac{f(x)}{g(x)} g(x) dx \\] We can sample \\(x_i\\) from \\(g(x)\\) and then calculate the mean of \\(h(x_i) \\frac{f(x_i)}{g(x_i)}\\). Using the same explane above, we can use a shifted exponential distribution to help calculate the intergral for normal distribution. Specifically, \\[\\int_2^{\\infty} \\frac{1}{2 \\pi} e^{-\\frac{1}{2}x^2}dx = \\int_2^{\\infty} \\frac{\\frac{1}{2 \\pi} e^{-\\frac{1}{2}x^2}}{e^{-(x-2)}} e^{-(x-2)}dx \\] The idea is that, we can generate \\(x_i\\) from exponential distribution of \\(e^{-(x-2)}\\), and then insert them into the targeted “expected (value) function” of \\(\\frac{\\frac{1}{2 \\pi} e^{-\\frac{1}{2}x^2}}{e^{-(x-2)}}\\). Thus, as you can see, importance sampling is based on the law of large numbers (i.e., If the same experiment or study is repeated independently a large number of times, the average of the results of the trials must be close to the expected value). We can use it to calculate integral based on link of the definition of expected value. Nsim=10^4 normal_density=function(x) {y=(1/sqrt(2*pi))*exp(-0.5*(x^2)) return(y)} x=2-log(runif(Nsim)) ImpS=c(); v=c(); upper=c(); lower=c() for (j in 1:Nsim) { ImpS[j]=mean(normal_density(x[1:j])/exp(-(x[1:j]-2))) v[j]=(j^{-1})*var(normal_density(x[1:j])/exp(-(x[1:j]-2))) upper[j]=ImpS[j]+1.96*sqrt(v[j]) lower[j]=ImpS[j]-1.96*sqrt(v[j]) } library(ggplot2) values=c(ImpS,upper,lower) type=c(rep(&quot;mc&quot;,Nsim),rep(&quot;upper&quot;,Nsim),rep(&quot;lower&quot;,Nsim)) iter=rep(seq(1:Nsim),3) data=data.frame(val=values, tp=type, itr=iter) ggplot(data,aes(itr,val,col=tp))+geom_line(size=0.5)+ geom_hline(yintercept=1-pnorm(2),color=&quot;green&quot;,size=0.5) ## Warning: Removed 2 rows containing missing values (geom_path). 6.3 Newton Raphson algorithm The main purpose of Newton Raphson algorithm is to calculate the root of a function (e.g., \\(x^2-3=0\\)). We know that in order to maximize the MLE, we need to calculate the first derivatice of the function and then set it to zero \\(\\ell^{&#39;}(x)=0\\). Thus, we can use the same Newton Raphson method to help calculate the MLE maximization as well. There are different ways to understand Newton Raphson method, but I found the method fo geometric the most easy way to explain. Credit of this figure: https://www.math.ubc.ca/~anstee/math104/newtonmethod.pdf Specifically, suppose that you want to calculate the root of a function \\(f(x)=0\\). We assume the root is \\(r\\). However, we do not that, and we randomly guess a point of \\(a\\). Thus, we can get a tangent line with slope of \\(f^{&#39;}(a)\\) and a point of \\((a,f(a))\\). Since we know the slope and one of its points, we can write the function for this tangent line. \\[y-f(a)=f^{&#39;}(a)(x-a)\\] To calculate the \\(x-intercept\\), namely \\(b\\) in the figure, we can set \\(y=0\\), and get the following: \\[-f(a)=f^{&#39;}(a)(x-a) \\Rightarrow x (or, b)= a-\\frac{f(a)}{f^{&#39;}(a)}\\] If there is significant difference of \\(|a-b|\\), we know that our orginal guess of \\(a\\) is not good. We better use \\(b\\) as the next guess, and calculate its tangent line again. To generalize, we can write it as follows. \\[x_{t+1}=x_{t}-\\frac{f(x_t)}{f^{&#39;}(x_t)}\\] Okay, this method above is to calculate the root. For MLE, we can also use this method to calculate the root for the \\(\\ell ^{&#39;}=0\\). We can write it as follows. \\[x_{t+1}=x_{t}-\\frac{\\ell^{&#39;}(x_t)}{\\ell^{&#39;&#39;}(x_t)}\\] Often, \\(x\\) is not just a single unknow parameter, but a vector. For this case, we can write it as follows. \\[\\beta_{t+1}=\\beta_{t}-\\frac{\\ell^{&#39;}(\\beta_t)}{\\ell^{&#39;&#39;}(\\beta_t)}\\] 6.3.1 Calculate the root \\(x^3-5=0\\) Note that, this is obviously not a maximization problem. In contrast, it involves a function with zero. As we can see, we can think it as the first order of Taylor approximation. That is, \\(f^{&#39;}(x)=x^3-5=0\\). As we can see the following plot, it converts very quickly. f_firstorder=function(x){x^3-5} f_secondorder=function(x){3*x} x_old=1;tolerance=1e-3 max_its=2000;iteration=1;difference=2 c_iteration&lt;-c() ## to collect numbers generated in the iteration process while(difference&gt;tolerance &amp; iteration&lt;max_its){ x_updated=x_old-(f_firstorder(x_old)/f_secondorder(x_old)) difference=abs(x_updated-x_old); iteration=iteration+1; x_old=x_updated c_iteration&lt;-c(c_iteration,x_updated)} plot(c_iteration,type=&quot;b&quot;) 6.3.2 Logistic regression Suppose we have \\(n\\) observation, and \\(m\\) variables. \\[\\begin{bmatrix} x_{11} &amp; x_{12} &amp; x_{13} &amp; ... &amp; x_{1m}\\\\ x_{21} &amp; x_{22} &amp; x_{23} &amp; ... &amp; x_{2m} \\\\ ...\\\\ x_{n1} &amp; x_{n2} &amp; x_{n3} &amp; ... &amp; x_{nm} \\end{bmatrix}\\] Typically, we add a vector of \\(1\\) being used to estimate the constant. \\[\\begin{bmatrix} 1 &amp; x_{11} &amp; x_{12} &amp; x_{13} &amp; ... &amp; x_{1m}\\\\ 1 &amp; x_{21} &amp; x_{22} &amp; x_{23} &amp; ... &amp; x_{2m} \\\\ ...\\\\ 1 &amp; x_{n1} &amp; x_{n2} &amp; x_{n3} &amp; ... &amp; x_{nm} \\end{bmatrix}\\] And, we have observe a vector of \\(n\\) \\(y_i\\) as well, which is a binary variable: \\[Y = \\begin{bmatrix}1 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ ...\\\\ 1 \\\\ \\end{bmatrix}\\] Using the content from the MLE chapter, we can get: \\[\\mathbf{L}=\\prod_{i=1}^{n} p_i^{ y_i}(1-p_i)^{(1-y_i)}\\] Further, we can get a log-transformed format. \\[log (\\mathbf{L})=\\sum_{i=1}^{n}[y_i log (p_i) + (1-y_i) log(1-p_i)]\\] Given that \\(p_i=\\frac{e^{\\beta_0+\\beta_1x_1+...+\\beta_nx_n}}{1+e^{\\beta_0+\\beta_1x_1+...+\\beta_nx_n}}=\\frac{e^{\\beta^Tx}}{1+e^{\\beta^Tx}}\\), we can rewrite it as follows: \\[log (\\mathbf{L})=\\ell=\\sum_{i=1}^{n}[y_i log (\\frac{e^{\\beta^Tx_i}}{1+e^{\\beta^Tx_i}}) + (1-y_i) log(1-\\frac{e^{\\beta^Tx_i}}{1+e^{\\beta^Tx_i}})]\\] Before doing the derivative, we set. \\[\\frac{e^{\\beta^Tx_i}}{1+e^{\\beta^Tx_i}} = p(\\beta ^T x_i)\\] \\[log (\\mathbf{L})=\\ell=\\sum_{i=1}^{n}[y_i log (p(\\beta ^T x_i)) + (1-y_i) log(1-p(\\beta ^T x_i))]\\] Note that, \\(\\frac{\\partial p(\\beta ^T x_i)}{\\partial (\\beta ^T x_i)} = p(\\beta ^T x_i)(1-p(\\beta ^T x_i))\\). We will use it later. \\[\\begin{aligned} \\nabla \\ell &amp;= \\sum_{i=1}^{n} [y_i \\frac{1}{p(\\beta ^T x_i)} \\frac{\\partial p(\\beta ^T x_i)}{\\partial (\\beta ^T x_i)}\\frac{\\partial (\\beta ^T x_i)}{\\partial \\beta}+(1-y_i) \\frac{1}{1-p(\\beta ^T x_i)}(-1)\\frac{\\partial p(\\beta ^T x_i)}{\\partial (\\beta ^T x_i)}\\frac{\\partial (\\beta ^T x_i)}{\\partial \\beta}] \\\\ &amp;= \\sum_{i=1}^{n} x_i^T[y_i \\frac{1}{p(\\beta ^T x_i)} p(\\beta ^T x_i)(1-p(\\beta ^T x_i))+(1-y_i) \\frac{1}{1-p(\\beta ^T x_i)}(-1)p(\\beta ^T x_i)(1-p(\\beta ^T x_i))] \\\\ &amp;= \\sum_{i=1}^{n} x_i^T[y_i \\frac{1}{p(\\beta ^T x_i)} p(\\beta ^T x_i)(1-p(\\beta ^T x_i))-(1-y_i) \\frac{1}{1-p(\\beta ^T x_i)}p(\\beta ^T x_i)(1-p(\\beta ^T x_i))] \\\\ &amp;= \\sum_{i=1}^{n} x_i^T[y_i (1-p(\\beta ^T x_i))-(1-y_i) p(\\beta ^T x_i)] \\\\ &amp;=\\sum_{i=1}^{n} x_i^T[y_i-y_ip(\\beta ^T x_i)-p(\\beta ^T x_i)+y_i p(\\beta ^T x_i)] \\\\ &amp;=\\sum_{i=1}^{n} x_i^T[y_i-p(\\beta ^T x_i)] \\\\ &amp;= \\sum_{i=1}^{n} x_i^T[y_i-\\frac{e^{\\beta^Tx_i}}{1+e^{\\beta^Tx_i}}] \\end{aligned}\\] As noted, the Newton Raphson algorithm needs the second order. \\[\\begin{aligned} \\nabla^2 \\ell &amp;=\\frac{\\partial \\sum_{i=1}^{n} x_i^T[y_i-p(\\beta ^T x_i)]}{\\partial \\beta} \\\\ &amp;=-\\sum_{i=1}^{n} x_i^T\\frac{\\partial p(\\beta ^T x_i) }{\\partial \\beta}\\\\ &amp;=-\\sum_{i=1}^{n} x_i^T\\frac{\\partial p(\\beta ^T x_i) }{\\partial (\\beta^Tx_i)} \\frac{\\partial (\\beta^Tx_i)}{\\partial \\beta}\\\\ &amp;=-\\sum_{i=1}^{n} x_i^T p(\\beta ^T x_i)(1-p(\\beta ^T x_i))x_i \\end{aligned}\\] The following are the data simulation (3 IVs and 1 DV) and Newton Raphson analysis. # Data generation set.seed(123) n=500 x1_norm&lt;-rnorm(n) x2_norm&lt;-rnorm(n,3,4) x3_norm&lt;-rnorm(n,4,6) x_combined&lt;-cbind(1,x1_norm,x2_norm,x3_norm) # dimension: n*4 coefficients_new&lt;-c(1,2,3,4) #true regression coefficient inv_logit&lt;-function(x,b){exp(x%*%b)/(1+exp(x%*%b))} prob_generated&lt;-inv_logit(x_combined,coefficients_new) y&lt;-c() for (i in 1:n) {y[i]&lt;-rbinom(1,1,prob_generated[i])} # Newton Raphson #We need to set random starting values. beta_old&lt;-c(1,1,1,1) tolerance=1e-3 max_its=2000;iteration=1;difference=2 W&lt;-matrix(0,n,n) while(difference&gt;tolerance &amp; iteration&lt;max_its) { # The first order f_firstorder&lt;-t(x_combined)%*%(y-inv_logit(x_combined,beta_old)) # The second order diag(W) = inv_logit(x_combined,beta_old)*(1-inv_logit(x_combined,beta_old)) f_secondorder&lt;--t(x_combined)%*%W%*%x_combined # Calculate the beta_updated beta_updated=beta_old-(solve(f_secondorder)%*%f_firstorder) difference=max(abs(beta_updated-beta_old)); iteration=iteration+1; beta_old=beta_updated} beta_old ## [,1] ## 0.9590207 ## x1_norm 1.7974165 ## x2_norm 3.0072303 ## x3_norm 3.9578107 \\[\\frac{\\partial \\ell} {\\partial \\beta} = \\sum_{i=1}^{n} [y_i \\frac{1}{p(\\beta ^T x_i)} \\frac{\\partial p(\\beta ^T x_i)}{\\partial (\\beta ^T x_i)}\\frac{\\partial (\\beta ^T x_i)}{\\partial \\beta}+(1-y_i) \\frac{1}{1-p(\\beta ^T x_i)}(-1)\\frac{\\partial p(\\beta ^T x_i)}{\\partial (\\beta ^T x_i)}\\frac{\\partial (\\beta ^T x_i)}{\\partial \\beta}] \\] \\[=\\sum_{i=1}^{n} [y_i \\frac{1}{p(\\beta ^T x_i)} \\phi (\\beta ^T x_i)-(1-y_i) \\frac{1}{1-p(\\beta ^T x_i)}\\phi (\\beta ^T x_i)]x_i\\] \\[\\Phi(\\beta_0+\\beta_1x_1+\\beta_2x_2+\\beta_3x_3)= p(y=1)\\] # Data generation n=500 x1_norm&lt;-rnorm(n) x2_norm&lt;-rnorm(n) x3_norm&lt;-rnorm(n) x_combined&lt;-cbind(1,x1_norm,x2_norm,x3_norm) coefficients_new&lt;-c(2,2,3,3) #true regression coefficient inv_norm&lt;-function(x,b){pnorm(x%*%b)} prob_generated&lt;-inv_norm(x_combined,coefficients_new) y&lt;-c() for (i in 1:n) {y[i]&lt;-rbinom(1,1,prob_generated[i])} # Newton Raphson #We need to set random starting values. x_old&lt;-c(1,1,1,1) tolerance=1e-3 max_its=2000;iteration=1;difference=2 while(difference&gt;tolerance &amp; iteration&lt;max_its){ x_updated=x_old-(f_firstorder(x_old)/f_secondorder(x_old)) difference=abs(x_updated-x_old); iteration=iteration+1; x_old=x_updated c_iteration&lt;-c(c_iteration,x_updated)} plot(c_iteration,type=&quot;b&quot;) 6.4 Metropolis Hastings Metropolis–Hastings is a MCMC method for obtaining a sequence of random samples from a probability distribution from which direct sampling is difficult. By using the samples, we can plot the distribution (through histgram), or we can calculate the integral (e.g., you need to calculate the expected value). (Side note: does this remind you the importance sampling? Very similiar!) Basic logic (my own summary): Set up a random starting value of \\(x_0\\). Sample a \\(y_0\\) from the instrumental function of \\(q(x)\\). Calculate the following: \\(p =\\frac{f(y_0)}{f(x_0)}\\frac{q(x_0)}{q(y_0)}\\) \\(\\rho=min(p, 1)\\) \\(x_{1}=\\begin{cases} y_0 &amp; p \\\\ x_0 &amp; 1-p \\end{cases}\\) Repeat \\(n\\) times (\\(n\\) is set subjectively.) Use normal pdf to sample gamma distribution alpha=2.7; beta=6.3 # I randomly chose alpha and beta values for the target gamma function Nsim=5000 ## define the number of iteration X=c(rgamma(1,1)) # initialize the chain from random starting numbers mygamma&lt;-function(Nsim,alpha,beta){ for (i in 2:Nsim){ Y=rnorm(1) rho=dgamma(Y,alpha,beta)*dnorm(X[i-1])/(dgamma(X[i-1],alpha,beta)*dnorm(Y)) X[i]=X[i-1] + (Y-X[i-1])*(runif(1)&lt;rho) } X } hist(mygamma(Nsim,alpha,beta), breaks = 100) 6.5 EM EM algorithm is an iterative method to find ML or maximum a posteriori (MAP) estimates of parameters. Direct Ref: http://www.di.fc.ul.pt/~jpn/r/EM/EM.html Suppose that we only observe \\(X\\), and do not know \\(Z\\). We thus need to construct the complete data of \\((X, Z)\\). Given \\(p(Z|X,\\theta)\\), we can compute the likelihood of the complete dataset: \\[p(X, Z|\\theta)=p(Z|X,\\theta)p(X|\\theta)\\] The EM algorithm: We got \\(X\\) and \\(p(Z|X,\\theta)\\) Random assign a \\(\\theta_0\\), since we do not know any of them. E-step: \\(Q_{\\theta_i} = E_{Z|X,\\theta_i}[log p(X,Z|\\theta)]\\) M-step: compute \\(\\theta_{i+1} \\leftarrow argmax Q_{\\theta_i}\\) If \\(\\theta_i\\) and \\(\\theta_{i+1}\\) are not close enough, \\(\\theta_i \\leftarrow \\theta_{i+1}\\). Goto step 2. For examples, you can refer to the following link: http://www.di.fc.ul.pt/~jpn/r/EM/EM.html (It is em_R.r in R_codes folder. Personally, I can also refer to Quiz 2 in 536.) 6.6 References The UBC PDF about Newton https://www.math.ubc.ca/~anstee/math104/newtonmethod.pdf Some other pages about Newton and logistic regression http://www.win-vector.com/blog/2011/09/the-simpler-derivation-of-logistic-regression/ https://stats.stackexchange.com/questions/344309/why-using-newtons-method-for-logistic-regression-optimization-is-called-iterati https://tomroth.com.au/logistic/ https://www.stat.cmu.edu/~cshalizi/350/lectures/26/lecture-26.pdf https://www.stat.cmu.edu/~cshalizi/402/lectures/14-logistic-regression/lecture-14.pdf http://hua-zhou.github.io/teaching/biostatm280-2017spring/slides/18-newton/newton.html MH https://www.youtube.com/watch?v=VGRVRjr0vyw "],
["generalized-linear-mixed-models.html", "Chapter 7 Generalized Linear Mixed Models 7.1 Basics of GLMM 7.2 Some References", " Chapter 7 Generalized Linear Mixed Models 7.1 Basics of GLMM Recall the formula in the probit model: \\[Y^*=X\\beta+\\epsilon, \\epsilon \\sim N(0,\\sigma^2)=N(0,I)\\] Similar to LMM, binary model with random effect can be written as follows. \\[Y^*=X\\beta+ Z u+\\epsilon\\] where, \\[\\epsilon \\sim N(0,I)\\] \\[u \\sim N(0, D)\\] We also assume \\(\\epsilon\\) and \\(u\\) are independent.Thus, we know that \\(D\\) represents the virances of the random effects. If we make \\(u =1\\), the model becomes the usual probit model. McCulloch (1994) states that there are a few advantages to use probit, rather than logit models. (Note that, however, probit is not canonical link function, but logit is!) The following is the note from Charle E. McCulloch’s “Maximum likelihood algorithems for Generalized Linear Mixed Models” 7.2 Some References http://www.biostat.umn.edu/~baolin/teaching/linmods/glmm.html http://www.biostat.umn.edu/~baolin/teaching/probmods/GLMM_mcmc.html https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html "],
["twitter-example.html", "Chapter 8 Twitter Example 8.1 Model 8.2 Simulating Data of Senators on Twitter 8.3 Simulating Data of Conservative Users on Twitter and Model Testing 8.4 Simulating Data of Liberal Users on Twitter and Model Testing", " Chapter 8 Twitter Example The following is part of my course project for Stat 536. It aims to replicate part of the findings from Barbera (2015) Birds of the Same Feather Tweet Together: Bayesian Ideal Point Estimation Using Twitter Data. Political Analysis 23 (1). Note that, the following model is much simpler than that in the original paper. 8.1 Model Suppose that a Twitter user is presented with a choice between following or not following another target \\(j \\in \\{ 1, ..., m\\}\\). Let \\(y_{j}=1\\) if the user decides to follow \\(j\\), and \\(y_{j}=0\\) otherwise. \\[y_{j}=\\begin{cases} 1 &amp; Following \\\\ 0 &amp; Not Following \\end{cases}\\] \\[p(y_{j}=1|\\theta) = \\frac{exp(- \\theta_0|\\theta_1 - x_j|^2)}{1+exp(- \\theta_0|\\theta_1 - x_j|^2)}\\] We additionally know the priors of \\(\\theta\\). \\[\\theta_i \\sim N(0,10^2) (i = 0, 1)\\] The likelihood function is as follows. \\[L(Y|\\theta)=\\prod_{j=1}^{m} (\\frac{exp(- \\theta_0|\\theta_1 - x_j|^2)}{1+exp(- \\theta_0|\\theta_1 - x_j|^2)})^{y_j}(1-\\frac{exp(- \\theta_0|\\theta_1 - x_j|^2)}{1+exp(- \\theta_0|\\theta_1 - x_j|^2)})^{(1-y_j)}\\] Thus, the posterior is as follows. \\[L(Y|\\theta) \\cdot N(\\theta_0|0,10) \\cdot N(\\theta_1|0,10)\\] \\[\\propto \\prod_{j=1}^{m} (\\frac{exp(- \\theta_0|\\theta_1 - x_j|^2)}{1+exp(- \\theta_0|\\theta_1 - x_j|^2)})^{y_j}(1-\\frac{exp(- \\theta_0|\\theta_1 - x_j|^2)}{1+exp(- \\theta_0|\\theta_1 - x_j|^2)})^{(1-y_j)}\\cdot exp(-\\frac{1}{2}(\\frac{\\theta_0}{10})^2)\\cdot exp(-\\frac{1}{2}(\\frac{\\theta_1}{10})^2)\\] #Establish the function for logistic regression Expit&lt;-function(x){exp(x)/(1+exp(x))} #Construct the posterior - in a log-format #To make sure that the estimate of theta_1 is stable, #the following code wants to make sure that theta_0 is always greater than zero. log_post&lt;-function(Y, X, theta) { if(theta[1]&lt;=0){post=-Inf} if(theta[1]&gt;0){ prob1&lt;-Expit(-theta[1]*((theta[2]-X)^2)) likelihood&lt;-sum(dbinom(Y,1,prob1,log = TRUE)) priors&lt;-sum(dnorm(theta,0,10,log=TRUE)) post=likelihood+priors} return(post) } Bayes_logit&lt;-function (Y,X,n_samples=2000) { #Initial values theta&lt;-c(5,5) #store data keep.theta&lt;-matrix(0,n_samples,2) keep.theta[1,]&lt;-theta #acceptance and rejection acc&lt;-att&lt;-rep(0,2) #current log posterior current_lp&lt;-log_post(Y,X,theta) for (i in 2:n_samples) { for(j in 1:2) { #attempt + 1 att[j]&lt;-att[j]+1 can_theta&lt;-theta can_theta[j]&lt;-rnorm(1,theta[j],0.5) #candidate of log posterior candidate_lp&lt;-log_post(Y,X,can_theta) Rho&lt;-min(exp(candidate_lp-current_lp),1) Random_probability&lt;-runif(1) if (Random_probability&lt;Rho) { theta&lt;-can_theta current_lp&lt;-candidate_lp #acceptance + 1, as long as Random_probability&lt;Rho acc[j]&lt;-acc[j]+1 } } #save theta keep.theta[i,]&lt;-theta } #Return: including theta and acceptance rate list(theta=keep.theta,acceptance_rate=acc/att) } 8.2 Simulating Data of Senators on Twitter Assume that we have 100 senators, 50 Democrats and 50 Republicans, who we know their ideology. Assume that Democrats have negative ideology scores to indicate that they are more liberal, whereas Republicans have positive scores to indicate that they are more conservative. The following is data simulation for senators. # Republicans are more conservative, and they have positive numbers. Republicans&lt;-c() Republicans&lt;-rnorm(50,1,0.5) No_Republicans&lt;-rep(1:50,1) Part_1&lt;-cbind(No_Republicans,Republicans) # Democrats are more liberal, and they have negative numbers. Democrats&lt;-c() Democrats&lt;-rnorm(50,-1,0.5) No_Democrats&lt;-rep(51:100,1) Part_2&lt;-cbind(No_Democrats,Democrats) Data_Elites&lt;-rbind(Part_1,Part_2) Data_Elites&lt;-as.data.frame(Data_Elites) colnames(Data_Elites) &lt;- c(&quot;Elite_No&quot;,&quot;Elite_ideology&quot;) head(Data_Elites) ## Elite_No Elite_ideology ## 1 1 1.0541992 ## 2 2 0.3805544 ## 3 3 1.3568577 ## 4 4 0.9922547 ## 5 5 1.0089966 ## 6 6 0.8878271 8.3 Simulating Data of Conservative Users on Twitter and Model Testing Assume that we observe one Twitter user, who is more conservative. To simulate Twitter following data for this user, I assign this user to follow more Republican senators. Thus, if the Metropolis Hastings algorithm works as intended, we would expect to see a positive estimated value for their ideology. Importantly, as we can see in the histogram below, the estimated value indeed is positive, providing preliminary evidence for the statistical model and the algorithm. In addition, for the acceptance rate, we can see that the constant has a lower number than ideology, since we only accept a constant when it is positive. #This user approximately follows 45 Republican Senators and 10 Democrat Senators. Data_user&lt;-as.data.frame(matrix(c(ifelse(runif(50)&lt;.1,0,1),ifelse(runif(50)&lt;.8,0,1))), 100, 1) colnames(Data_user)&lt;-c(&quot;R_User&quot;) Data_combined&lt;-cbind(Data_Elites,Data_user) X_data&lt;-Data_combined$Elite_ideology Y_data&lt;-Data_combined$R_User fit_C&lt;-Bayes_logit(Y_data,X_data) fit_C$acceptance_rate ## [1] 0.1320660 0.5557779 plot(fit_C$theta[,1],main=&quot;Constant (Conservative Users)&quot;, xlab=&quot;Iteration Process&quot;,ylab=&quot;Estimated Scores&quot;,type=&quot;l&quot;) plot(fit_C$theta[,2],main=&quot;Estimated Ideology Scores (Conservative Users)&quot;, xlab=&quot;Iteration Process&quot;,ylab=&quot;Ideology Scores&quot;,type=&quot;l&quot;) hist(fit_C$theta[,2],main=&quot;Estimated Ideology Scores (Conservative Users)&quot;, xlab=&quot;Ideology Scores&quot;,breaks = 100) 8.4 Simulating Data of Liberal Users on Twitter and Model Testing To further verify the Metropolis Hastings algorithm, I plan to test the opposite estimate. Specifically, assume that we observe another user, who is more liberal. To simulate Twitter following data for this user, I assign this user to follow more Democrat senators. In this case, we would expect to see a negative value for their estimated ideology. As we can see in the histogram shown below, as expected, the estimated value is negative, providing convergent evidence for the model and the algorithm. #This user approximately follows 10 Republican Senators and 45 Democrat Senators. Data_user&lt;-as.data.frame(matrix(c(ifelse(runif(50)&lt;.8,0,1),ifelse(runif(50)&lt;.1,0,1))), 100, 1) colnames(Data_user)&lt;-c(&quot;L_User&quot;) Data_combined&lt;-cbind(Data_Elites,Data_user) X_data&lt;-Data_combined$Elite_ideology Y_data&lt;-Data_combined$L_User fit_L&lt;-Bayes_logit(Y_data,X_data) fit_L$acceptance_rate ## [1] 0.1585793 0.5092546 plot(fit_L$theta[,1],main=&quot;Constant (Liberal Users)&quot;, xlab=&quot;Iteration Process&quot;,ylab=&quot;Estimated Scores&quot;,type=&quot;l&quot;) plot(fit_L$theta[,2],main=&quot;Estimated Ideology Scores (Liberal Users)&quot;, xlab=&quot;Iteration Process&quot;,ylab=&quot;Ideology Scores&quot;,type=&quot;l&quot;) hist(fit_L$theta[,2],main=&quot;Estimated Ideology Scores (Liberal Users)&quot;, xlab=&quot;Ideology Scores&quot;,breaks = 100) "],
["practice-learning-on-the-battle-field.html", "Chapter 9 Practice: Learning on the Battle Field 9.1 R code 9.2 References", " Chapter 9 Practice: Learning on the Battle Field 9.1 R code #https://fivethirtyeight.com/contributors/josh-hermsmeyer/ # https://github.com/ryurko/nflscrapR-data/blob/master/legacy_data/README.md #mydata1 = read.csv(&#39;plays.txt&#39;) #unique(mydata1$gameId) #unique(mydata1$PassLength) #table(mydata1$PassLength) #table(mydata1$PassResult) #table(mydata1$numberOfPassRushers) ##mydata3 = read.csv(url(&#39;https://raw.githubusercontent.com/ryurko/nflscrapR-data/master/legacy_data/season_play_by_play/pbp_2017.csv&#39;)) ##write.csv(mydata3,&#39;2017playbyplay.csv&#39;) mydata3&lt;-read.csv(&#39;2017playbyplay.csv&#39;) nrow(mydata3) table(mydata3$Passer) table(mydata3$PlayType) #mydata5&lt;-mydata3[!duplicated(mydata3[,c(&#39;GameID&#39;,&#39;Passer&#39;)]),] #unique(mydata3$GameID) mydata6&lt;-subset(mydata3,down==1) mydata7&lt;-subset(mydata6,PlayType==&#39;Pass&#39;|PlayType==&#39;Run&#39;) #table(mydata7$PlayType) #table(droplevels(mydata7$PlayType)) mydata7$PlayType&lt;-droplevels(mydata7$PlayType) table(mydata7$PlayType) #http://rstudio-pubs-static.s3.amazonaws.com/6975_c4943349b6174f448104a5513fed59a9.html source(&quot;http://pcwww.liv.ac.uk/~william/R/crosstab.r&quot;) mydata8&lt;-mydata7[,c(&#39;Passer&#39;,&#39;PlayType&#39;,&#39;GameID&#39;,&#39;posteam&#39;,&#39;DefensiveTeam&#39;,&#39;Yards.Gained&#39;,&#39;FirstDown&#39;,&#39;TimeSecs&#39;)] #results&lt;-crosstab(mydata8, row.vars = &quot;GameID&quot;, col.vars = &quot;PlayType&quot;, type = &quot;r&quot;) #p1&lt;-results$crosstab #hist(p1[,1],20) library(plyr) count_vector&lt;-count(mydata8, &quot;GameID&quot;) l_new&lt;-length(count_vector$freq) time&lt;-c() for(i in 1:l_new) {time&lt;-append(time,rep(1:count_vector$freq[i]))} nrow(time) mydata8$time&lt;-time mydata8$play_new&lt;-ifelse(mydata8$PlayType==&#39;Pass&#39;,1,0) n_counting&lt;-0 # help counting the number of pairs ## The following code collects all the rows of each pair. However, it is difficult to analyze data # in such a format. #empty_df = mydata8[FALSE,] #for (i in 1:l_new) # level of different game #{ # for(j in 1:((count_vector$freq[i])-1)) # within the same game # { # if(i==1) # {row_id&lt;-j} # else {row_id&lt;-sum(count_vector$freq[1:(i-1)])+j} # # #print(row_id) # if(as.character(mydata8[row_id,]$posteam)!=as.character(mydata8[row_id+1,]$posteam)) # { # print(&quot;not same team&quot;) # if (nrow(empty_df)==0) # {empty_df&lt;-mydata8[row_id:(row_id+1),]} # else # { # if(row.names(mydata8[row_id,])!=row.names(tail(empty_df,1))) # {empty_df&lt;-rbind(empty_df,mydata8[row_id,])} # empty_df&lt;-rbind(empty_df,mydata8[row_id+1,]) # } # n_counting&lt;-n_counting+1 # } # } #} # The following code only collects the second row of the pair, but adds data of ### PT_L: type of play in the last first down from the other team ### TG_L: Yards.Gained in the last play ### FirstDown: did they get first down or not. Note that, if yes, it means it was a fumble. PT_L=&quot;Pass&quot; TG_L=0 FD_L=0 pari_data= mydata8[1,] pari_data&lt;-cbind(pari_data,PT_L,TG_L,FD_L) pari_data&lt;-pari_data[FALSE,] for (i in 1:l_new) # level of different game { for(j in 1:((count_vector$freq[i])-1)) # within the same game { if(i==1) {row_id&lt;-j} else {row_id&lt;-sum(count_vector$freq[1:(i-1)])+j} print(row_id) if(as.character(mydata8[row_id,]$posteam)!=as.character(mydata8[row_id+1,]$posteam)) { print(&quot;not same team&quot;) PT_L&lt;-as.character(mydata8[row_id,]$PlayType) TG_L&lt;-mydata8[row_id,]$Yards.Gained FD_L&lt;-mydata8[row_id,]$FirstDown new_row&lt;-cbind(mydata8[(row_id+1),],PT_L,TG_L,FD_L) pari_data&lt;-rbind(pari_data,new_row) } n_counting&lt;-n_counting+1 } } pari_data$same&lt;-ifelse(pari_data$PlayType==pari_data$PT_L,1,0) #write.csv(pari_data,&#39;pari_data.csv&#39;) write.table(pari_data, file = &quot;pari_data.csv&quot;,row.names=FALSE,na = &quot;&quot;, sep=&quot;,&quot;) Remarks mylogit1: in general, a team has a different play in their first down, compared to the other team in the last first down. mylogit2: If the defence team passed in the last first down, the offence team is less likely to use pass. If the defence team gained more yards, the offence team is more likely to pass in the next first down. If the defence team fumbled, it will reduce the chance the offence team to do the pass. pari_data2&lt;-read.csv(&#39;pari_data.csv&#39;) mylogit1 = glm(same~1, family=binomial, data=pari_data2) summary(mylogit1) ## ## Call: ## glm(formula = same ~ 1, family = binomial, data = pari_data2) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.117 -1.117 -1.117 1.239 1.239 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.14395 0.02809 -5.124 3e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 7035.5 on 5093 degrees of freedom ## Residual deviance: 7035.5 on 5093 degrees of freedom ## AIC: 7037.5 ## ## Number of Fisher Scoring iterations: 3 mylogit2 = glm(play_new~same+TG_L+FD_L, family=binomial, data=pari_data2) summary(mylogit2) ## ## Call: ## glm(formula = play_new ~ same + TG_L + FD_L, family = binomial, ## data = pari_data2) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.6114 -0.9783 -0.9382 1.0995 1.5672 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.175629 0.040712 4.314 1.6e-05 *** ## same -0.757822 0.057618 -13.152 &lt; 2e-16 *** ## TG_L 0.010439 0.003873 2.695 0.00704 ** ## FD_L -0.268115 0.148835 -1.801 0.07164 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 7034.3 on 5093 degrees of freedom ## Residual deviance: 6850.1 on 5090 degrees of freedom ## AIC: 6858.1 ## ## Number of Fisher Scoring iterations: 4 library(lme4) mylogit3 = glmer(same~play_new+TG_L+FD_L+(1|GameID), family= binomial(&quot;logit&quot;), data=pari_data2) ## boundary (singular) fit: see ?isSingular summary(mylogit3) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: same ~ play_new + TG_L + FD_L + (1 | GameID) ## Data: pari_data2 ## ## AIC BIC logLik deviance df.resid ## 6862.4 6895.1 -3426.2 6852.4 5089 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.3918 -0.7763 -0.7532 0.9061 1.6255 ## ## Random effects: ## Groups Name Variance Std.Dev. ## GameID (Intercept) 1.562e-15 3.953e-08 ## Number of obs: 5094, groups: GameID, 256 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.197140 0.040513 4.866 1.14e-06 *** ## play_new -0.757838 0.057619 -13.153 &lt; 2e-16 *** ## TG_L 0.006027 0.003824 1.576 0.11502 ## FD_L -0.392792 0.150715 -2.606 0.00916 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ply_nw TG_L ## play_new -0.627 ## TG_L -0.270 -0.043 ## FD_L -0.147 0.031 -0.041 ## convergence code: 0 ## boundary (singular) fit: see ?isSingular #Bill_1&lt;- bild(play_new ~ TG_L+FD_L, data = mydata8, id=&quot;GameID&quot;,start = NULL, dependence = &quot;MC1R&quot;) #summary(Bill_1) #locust2 &lt;- bild(as.factor(PlayType) ~ time + I(time^2), data = mydata8,id=&quot;GameID&quot;,start = NULL, dependence = &quot;MC2&quot;) 9.2 References https://arxiv.org/pdf/1403.7993.pdf http://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/Chapter11.pdf https://rpubs.com/JanpuHou/326048 "],
["project-draft.html", "Chapter 10 Project Draft 10.1 Background 10.2 Important Examples with R code 10.3 References", " Chapter 10 Project Draft mydata3&lt;-read.csv(&#39;Schnibbe 1502 Binary Data.csv&#39;) head(mydata3) ## X0 ## 1 0 ## 2 1 ## 3 0 ## 4 0 ## 5 1 ## 6 0 NO_new&lt;-rep(1:222) mydata4&lt;-cbind(mydata3,NO_new) head(mydata4) ## X0 NO_new ## 1 0 1 ## 2 1 2 ## 3 0 3 ## 4 0 4 ## 5 1 5 ## 6 0 6 a1 = glmer(X0 ~ 1 + (1|NO_new), data = mydata4,family=binomial) summary(a1) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: X0 ~ 1 + (1 | NO_new) ## Data: mydata4 ## ## AIC BIC logLik deviance df.resid ## 243.3 250.1 -119.6 239.3 220 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -0.5461 -0.5461 -0.5461 -0.5461 1.8311 ## ## Random effects: ## Groups Name Variance Std.Dev. ## NO_new (Intercept) 1.246e-07 0.000353 ## Number of obs: 222, groups: NO_new, 222 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.2098 0.1603 -7.549 4.38e-14 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 a2 = glm(X0 ~ 1, data = mydata4,family=binomial) summary(a2) ## ## Call: ## glm(formula = X0 ~ 1, family = binomial, data = mydata4) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.7225 -0.7225 -0.7225 -0.7225 1.7151 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.2098 0.1595 -7.583 3.38e-14 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 239.29 on 221 degrees of freedom ## Residual deviance: 239.29 on 221 degrees of freedom ## AIC: 241.29 ## ## Number of Fisher Scoring iterations: 4 10.1 Background The following code is from this website: http://www.biostat.umn.edu/~baolin/teaching/probmods/GLMM_mcmc.html. I will remove it on this page after I complete my practice and learning. In this example, it simulates a longitudinal data with 4 variables for each of 1000 separate individuals. Specifically, there are three continuous covariates (varying over time) and one ordinal covariate (constant over time). We will consider a random intercept model (mean zero and variance 100), and fit the data with glmer() from lme4 R package. The R code: n = 1000; p = 3; K = 4; sig = 10 set.seed(123) ## time varying covariates Xl = vector(&#39;list&#39;, K) # 4 list, each 1000 individuals for(i in 1:K) Xl[[i]] = matrix(rnorm(n*p), n,p) ## constant covariate Z = rbinom(n, 2,0.2) ## random effects #just 1000 random numubers? U = rnorm(n)*sig ## fixed effects # It ends a 1000*4 matrix etaX = sapply(Xl, rowSums) ## random errors eps = matrix(rnorm(n*K), n,K) ## logit model eta = etaX + U + eps # calculate probability prb = 1/(1+exp(-eta)) D = 1*(matrix(runif(n*K),n,K)&lt;prb) # comparing it to prb, and change to 1 and 0; 1000*4 # Select the first list from &quot;Xl&quot;, and then add other 3 lists--&gt; 4000 * 3 Xs = Xl[[1]] for(k in 2:K) Xs = rbind(Xs, Xl[[k]]) ## GLMM model library(lme4) sid = rep(1:n, K) # a vector of 1-1000, 4 repetitions ## model fit with GLMMM (default to Laplace approximation) # subjects as the random effect a1 = glmer(c(D) ~ Xs + Z[sid] + (1|sid), family=binomial) a1 ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: c(D) ~ Xs + Z[sid] + (1 | sid) ## AIC BIC logLik deviance df.resid ## 3213.666 3251.430 -1600.833 3201.666 3994 ## Random effects: ## Groups Name Std.Dev. ## sid (Intercept) 5.816 ## Number of obs: 4000, groups: sid, 1000 ## Fixed Effects: ## (Intercept) Xs1 Xs2 Xs3 Z[sid] ## 0.1537 0.6650 0.6429 0.6074 0.0199 ## MH sampling of random effects | data ## logit\\Pr(D_i|eta_i,U) = eta_i+U; U \\sim N(0,Vu) ## proposal dist: N(Uc,Vc) U.mh &lt;- function(Di,eta, Vu, Uc,Vc, B=100){ ub = rep(0, B) ub[1] = rnorm(1)*sqrt(Vc)+Uc # random starting value prb = 1/(1+exp(-eta-ub[1])) llk0 = dnorm(ub[1],sd=sqrt(Vu), log=TRUE) + sum(log(Di*prb+(1-Di)*(1-prb))) - dnorm(ub[1],Uc,sqrt(Vc), log=TRUE) # likelihood function? for(k in 2:B){ ub[k] = ub[k-1] uk = rnorm(1)*sqrt(Vc)+Uc prb = 1/(1+exp(-eta-uk)) llk1 = dnorm(uk,sd=sqrt(Vu), log=TRUE) + sum(log(Di*prb+(1-Di)*(1-prb))) - dnorm(uk,Uc,sqrt(Vc), log=TRUE) alpha = exp( llk1 - llk0 ) if(alpha&gt;=1){ ub[k] = uk llk0 = llk1 } else{ aa = runif(1) if(aa&lt;alpha){ ub[k] = uk llk0 = llk1 } } } return(ub) } library(numDeriv) UV.est &lt;- function(Di,eta,Vu,Uc){ llk0 = function(xpar){ Uc = xpar prb = 1/(1+exp(-eta-Uc)) res = dnorm(Uc,sd=sqrt(Vu), log=TRUE) + sum(log(Di*prb+(1-Di)*(1-prb))) -res } tmp = try(optim(Uc, llk0, method=&#39;Brent&#39;, lower=Uc-10,upper=Uc+10) ) if(class(tmp)==&#39;try-error&#39;) tmp = optim(Uc, llk0) Uc = tmp$par Vc = 1/hessian(llk0, Uc) c(Uc,Vc) } UV.mh &lt;- function(Vu,beta,Uc, D,X,subj){ ## Cov matrix sid = unique(subj); n = length(sid) Uc = Vc = rep(0,n) for(i in 1:n){ ij = which(subj==sid[i]); ni = length(ij) Xi = X[ij,,drop=FALSE] eta = Xi%*%beta zi = UV.est(D[ij],eta,Vu,Uc[i]) Uc[i] = zi[1]; Vc[i] = zi[2] } return(list(Uc=Uc,Vc=Vc) ) } #Newton Raphson update # Compute first/second derives of complete data log likelihood ## score and fisher information SF.mh &lt;- function(Vu,beta,Uc,Vc, D,X,subj){ ## S/hessian matrix sid = unique(subj); n = length(sid) p = dim(X)[2] S = rep(0, p) FI = matrix(0, p,p) sig2 = 0 for(i in 1:n) { ij = which(subj==sid[i]); ni = length(ij) Xi = X[ij,,drop=FALSE] eta = Xi%*%beta zi = U.mh(D[ij],eta,Vu,Uc[i],Vc[i], B=5e3)[-(1:1e3)] theta = sapply(eta, function(b0) mean(1/(1+exp(-b0-zi))) ) theta2 = sapply(eta, function(b0) mean(exp(b0+zi)/(1+exp(b0+zi))^2) ) FI = FI + t(Xi)%*%(theta2*Xi) S = S+colSums((D[ij]-theta)*Xi) sig2 = sig2 + mean(zi^2) } return(list(S=S, FI=FI, sig2=sig2/n) ) } library(lme4) sid = rep(1:n, K) a1 = glmer(c(D) ~ Xs + Z[sid] + (1|sid), family=binomial) ## extract variance and fixed effects parameters; + mode/variance of (random effects|data) Vu = (getME(a1,&#39;theta&#39;))^2; beta = fixef(a1); Um = ranef(a1,condVar=TRUE) D = c(D); X = cbind(1,Xs,Z[sid]); subj = sid Uc = unlist(Um[[1]]); Vc = c( attr(Um[[1]], &#39;postVar&#39;) ) for(b in 1:100){ ## NR updates with MH sampling obj = SF.mh(Vu,beta,Uc,Vc, D,X,subj) Vu = obj$sig2 tmp = solve(obj$FI,obj$S) beta = beta + tmp ## Proposal dist update tmp1 = UV.mh(Vu,beta,Uc, D,X,subj) Uc = tmp1$Uc; Vc = tmp1$Vc cat(b, &#39;:&#39;, tmp, &#39;;&#39;, obj$S/n, &#39;\\n\\t&#39;, sqrt(Vu), beta, &#39;\\n&#39;) } 10.2 Important Examples with R code Fitting mixed models with (temporal) correlations in R https://bbolker.github.io/mixedmodels-misc/notes/corr_braindump.html Mixed effects logistic regression https://stats.idre.ucla.edu/r/dae/mixed-effects-logistic-regression/ 10.3 References Data http://www.michelecoscia.com/?page_id=379 "],
["bayesian.html", "Chapter 11 Bayesian 11.1 Frequentist perspective 11.2 Bayesian perspective 11.3 Continous parameters 11.4 Bernoulli/binomial likelihood with uniform prior 11.5 Conjugate priors", " Chapter 11 Bayesian The following is the part of the class note that I took from the online course of “Bayesian Statistics: From Concept to Data Analysis.” (https://www.coursera.org/learn/bayesian-statistics/home/welcome) Important note: All the notes here are just for my own study purpose. I do not clain any copyright. You can use it for study purpose as well, but not for any business purposes. 11.1 Frequentist perspective \\[\\theta = \\{ fair , loaded \\}\\] \\[x \\sim Bin (5, \\theta)\\] \\[\\begin{aligned} f(x|\\theta) &amp;=\\begin{cases} \\binom{5}{x} (\\frac{1}{2})^5 &amp; if \\; \\theta=fair \\\\ \\binom{5}{x} (0.7)^x(0.3)^{5-x} &amp; if \\; \\theta=loaded \\end{cases} \\\\ &amp;= \\binom{5}{x} (\\frac{1}{2})^5 I_{\\{\\theta=fair \\}}+\\binom{5}{x} (0.7)^x(0.3)^{5-x}I_{\\{\\theta=loaded \\}}\\end{aligned}\\] When \\(x=2\\) \\[f(\\theta | x=2)=\\begin{cases} \\binom{5}{x} (\\frac{1}{2})^5 = 0.3125&amp; if \\; \\theta=fair \\\\ \\binom{5}{x} (0.7)^x(0.3)^{5-x} = 0.1323&amp; if \\; \\theta=loaded \\end{cases}\\] Thus, based on MLE, it suggests that it should be “fair”, since it has a greater probablity if we observe 2 head out of 5 trials. However, we can not know the following probability: given we observe \\(x=2\\), what is the probability that \\(\\theta\\) is fair. \\[P(\\theta=fair | X=2)\\] FOr frequentist’s perspective, the coin is the fixed coin, And thus, the probablity of \\(P(\\theta=fair|x=2)\\) is equal to \\(P(\\theta=fair)\\). \\[P(\\theta=fair|x=2)=P(\\theta=fair)\\] As, \\[P(\\theta=fair) \\in C(0,1) (i.e., either \\; 0 \\; or \\; 1)\\] 11.2 Bayesian perspective Prior \\(P(loaded)=0.6\\) \\[\\begin{aligned} f(\\theta | X) &amp;= \\frac{f(x|\\theta) f(\\theta)}{\\sum_{\\theta} f(x|\\theta)f(\\theta)} \\\\ &amp;=\\frac{\\binom{5}{x} [(\\frac{1}{2})^5 \\times 0.4 \\times I_{\\{\\theta=fair \\}}+ (0.7)^x(0.3)^{5-x} \\times 0.6 \\times I_{\\{\\theta=loaded \\}}]}{\\binom{5}{x} [(\\frac{1}{2})^5 \\times 0.4 + (0.7)^x(0.3)^{5-x} \\times 0.6]} \\end{aligned}\\] \\[\\begin{aligned} f(\\theta |X=2) &amp;=\\frac{0.0125 I_{\\{\\theta=fair \\}}+0.0079 I_{\\{\\theta=loaded \\}} }{0.0125+0.0079} \\\\ &amp;= 0.612 I_{\\{\\theta=fair \\}} + 0.388 I_{\\{\\theta=loaded \\}} \\end{aligned}\\] Thus, we can say that: \\[P(\\theta=loaded | X=2)=0.388\\] We can change the prior, and get different posterior probabilities: \\[P(\\theta=loaded)=\\frac{1}{2} \\rightarrow P(\\theta=loaded | X=2)=0.297\\] \\[P(\\theta=loaded)=\\frac{9}{10} \\rightarrow P(\\theta=loaded | X=2)=0.792\\] 11.3 Continous parameters In the examples above, \\(\\theta\\) is discrete. In contrast, the examples below use continous \\(\\theta\\). \\[f(\\theta |y)=\\frac{f(y|\\theta) f(\\theta)}{f(y)}=\\frac{f(y|\\theta) f(\\theta)}{\\int f(y|\\theta)f(\\theta)d\\theta}=\\frac{likelihood \\times prior}{normalizing-constant} \\propto likelihood \\times prior\\] Note that, the posterior is a PDF of \\(\\theta\\), which is not in the function of \\(f(y)\\). Thus, removing the denominator (i.e., the normalizing constant) does not change the form of the posterior. 11.3.1 Uniform Suppose that \\(\\theta\\) is the probablity of a coin getting head. We could assign a uniform distribution. \\[\\theta \\sim U[0,1]\\] \\[f(\\theta)=I_{ \\{0 \\leqq \\theta \\leqslant 1 \\}}\\] (It is interesting to see how to write the pdf for uniform distribution.) \\[f(\\theta | Y=1)= \\frac{\\theta^1(1-\\theta)^0 I_{\\{0 \\leqq \\theta \\leqslant 1\\}}}{\\int_{-\\infty}^{+\\infty} \\theta^1(1-\\theta)^0 I_{\\{0 \\leqq \\theta \\leqslant 1\\}} d\\theta}=\\frac{\\theta I_{\\{0 \\leqq \\theta \\leqslant 1 \\}}}{\\int_0^1 \\theta d\\theta}=2\\theta I_{ \\{0 \\leqq \\theta \\leqslant 1\\}}\\] If we ignore the normalizing constant, we will get \\[f(\\theta | Y=1) \\propto \\theta^1(1-\\theta)^0 I_{ \\{0 \\leqq \\theta \\leqslant 1\\} }=\\theta I_{ \\{0 \\leqq \\theta \\leqslant 1\\} }\\] Thus, we can see that with vs. without the noramlizing constant is the “2”. 11.3.2 Uniform: prior versus posterior When \\(\\theta\\) follows uniform distribution: Prior \\[P(0.025 &lt;\\theta&lt;0.975)=0.95\\] \\[P( 0.05&lt; \\theta )=0.95\\] Posterior \\[P(0.025&lt;\\theta&lt;0.975)=\\int_{0.025}^{0.975} 2\\theta d\\theta=0.95\\] \\[P(0.05&lt;\\theta)=1-P(\\theta &lt;0.05)=\\int_{0}^{0.05} 2\\theta d\\theta=1-0.05^2=0.9975\\] Thus, we can see that, while \\(P(0.025&lt;\\theta&lt;0.975)\\) is the same for prior and posterior, \\(P(0.05&lt;\\theta)\\) is not the same. 11.3.3 Uniform: equal tailed versus HPD Equal tailed \\[P(\\theta &lt; q|Y=1)=\\int_0^q 2\\theta d\\theta=q^2\\] \\[P(\\sqrt{0.025}&lt;\\theta&lt;\\sqrt{0.975}|Y=1)=P(0.158&lt;\\theta&lt;0.987)=0.95\\] We cab say that: there’s a 95% probability that \\(\\theta\\) is in between 0.158 and 0.987. Highest Posterior Density \\[P(\\theta &gt; \\sqrt{0.05}|Y=1)=P(\\theta &gt;0.224|Y=1)=0.95\\] 11.4 Bernoulli/binomial likelihood with uniform prior \\[\\begin{aligned} f(\\theta | Y=1) &amp;= \\frac{\\theta^{\\sum y_i}(1-\\theta)^{\\sum n-y_i} I_{\\{0 \\leqq \\theta \\leqslant 1\\}}}{\\int_{-\\infty}^{+\\infty} \\theta^{\\sum y_i}(1-\\theta)^{n-\\sum y_i} I_{\\{0 \\leqq \\theta \\leqslant 1\\}} d\\theta} \\\\ &amp;=\\frac{\\theta^{\\sum y_i}(1-\\theta)^{\\sum n-y_i} I_{\\{0 \\leqq \\theta \\leqslant 1\\}}}{\\frac{\\Gamma(\\sum y_i+1)\\Gamma(n-\\sum y_0+1)}{\\Gamma(n+2)} \\int_{-\\infty}^{+\\infty} \\frac{\\Gamma(n+2)}{\\Gamma(\\sum y_i+1)\\Gamma(n-\\sum y_0+1)} \\theta^{\\sum y_i}(1-\\theta)^{n-\\sum y_i} I_{\\{0 \\leqq \\theta \\leqslant 1\\}} d\\theta} \\\\ &amp;= \\frac{\\Gamma(n+2)}{\\Gamma(\\sum y_i+1)\\Gamma(n-\\sum y_0+1)}\\theta^{\\sum y_i}(1-\\theta)^{\\sum n-y_i} I_{\\{0 \\leqq \\theta \\leqslant 1\\}} \\end{aligned} \\] Thus, \\[\\theta | y \\sim Beta (\\sum y_i+1, n-\\sum y_i +1)\\] Side note: \\(Beta(1,1)=Uniform(0,1)\\): \\(Beta(\\alpha,\\beta)=\\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{B(\\alpha,\\beta)} I_{\\{0 \\leqq x \\leqslant 1\\}}\\) Thus, we can get the following since the support for beta distribution is \\([0,1]\\): \\(Beta(1,1)=\\frac{x^0(1-x)^0}{B(\\alpha,\\beta)}=1\\times I_{\\{0 \\leqq x \\leqslant 1\\}}\\) 11.5 Conjugate priors As noted above, beta prior (or, Uniform) leads to beta posterior. In a more general sense, Beta prior always leads to beta posterior. For instance, \\[ \\begin{aligned} f(\\theta |y) \\propto f(y|\\theta)f(\\theta)&amp;=\\theta^{\\sum y_i}(1-\\theta)^{\\sum n-y_i}\\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha,\\beta)} I_{\\{0 \\leqq \\theta \\leqslant 1\\}} \\\\ &amp;=\\frac{1}{B(\\alpha, \\beta)}\\theta^{\\sum y_i+\\alpha-1}(1-\\theta)^{\\sum n-y_i+\\beta-1} I_{\\{0 \\leqq \\theta \\leqslant 1\\}} \\\\ &amp;\\propto \\theta^{\\sum y_i+\\alpha-1}(1-\\theta)^{\\sum n-y_i+\\beta-1} I_{\\{0 \\leqq \\theta \\leqslant 1\\}} \\end{aligned}\\] Thus, \\[f(\\theta |y) \\sim Beta(\\alpha+\\sum y_i,\\beta+\\sum n-y_i)\\] Conjugate prior: prior and posterior share the same distribution. "],
["trying.html", "Chapter 12 Trying 12.1 The Basic Idea 12.2 Model and R Code 12.3 glmmTMB package", " Chapter 12 Trying 12.1 The Basic Idea \\[L(\\beta,D|Y)=\\int \\prod_{i=1}^{n} f_{y_i|u}(y_i|b,\\beta)f_{b_i}(b_i|D)db_i\\] Notations : \\(y\\): Variable for the fixed effect \\(b\\): Variable for the random effect \\(\\beta\\): Parameters for the fixed effect \\(D\\): Parameters for the random effect The dimension of the integral is equal to the levels of the random factors (i.e., the number of observations). 12.2 Model and R Code Covarance Matrix for \\(n\\) observations: \\[V=\\sigma^2 \\begin{bmatrix} 1 &amp; \\rho &amp; \\rho^2 &amp; ... &amp; \\rho^{n-1} &amp; \\rho^n \\\\ \\rho &amp; 1 &amp; \\rho &amp; ... &amp; \\rho^{n-2}&amp; \\rho^{n-1}\\\\ \\rho^2 &amp; \\rho &amp; 1 &amp; ... &amp; \\rho^{n-3}&amp; \\rho^{n-2} \\\\ ...\\\\ \\rho^n &amp; \\rho^{n-1} &amp; \\rho^{n-2} &amp; ... &amp; \\rho &amp; 1 \\end{bmatrix}\\] The inverse matrix is as follows: \\[Q=V^{-1}=\\frac{1}{\\sigma^2(1-\\rho)} \\begin{bmatrix} 1 &amp; -\\rho &amp; 0 &amp; ... &amp; 0 &amp; 0 \\\\ -\\rho &amp; 1+\\rho^2 &amp; -\\rho &amp; ... &amp; 0 &amp; 0\\\\ 0 &amp; -\\rho &amp; 1+\\rho^2 &amp; ... &amp; 0 &amp; 0 \\\\ ...\\\\ 0 &amp; 0 &amp; 0 &amp; ... &amp; 1+\\rho^2 &amp;-\\rho\\\\ 0 &amp; 0 &amp; 0 &amp; ... &amp; -\\rho &amp; 1 \\end{bmatrix}\\] \\[N(-\\sum_{j\\neq k} Q_{kj}b_j^{(m)}Q_{kk}^{-1},Q_{kk}^{-1})\\] \\[ln L(\\beta, \\theta; Y,b)=\\ell=lnf_{Y|b}(Y|b,\\beta)+lnf_b(b|\\theta)\\] \\[a^{(m+1)}=a^{(m)}+\\tau(a^{(m)})^{-1} S(a^{(m)})\\] Where, \\[\\tau(a) = -E(\\frac{\\partial^2 \\ell}{\\partial \\alpha \\partial \\alpha^{&#39;}}|Y)\\] \\[S(a) = E(\\frac{\\partial \\ell}{\\partial \\alpha }|Y)\\] Note that, \\(\\alpha\\) is a combination of two sets of parameters. \\[\\alpha = \\binom{\\beta}{b} \\] \\[\\ell=\\sum_{i=1}^{n}\\{[y_i ln (\\frac{e^{\\beta^Tx_i+b_i}}{1+e^{\\beta^Tx_i+b_i}}) + (1-y_i) ln(1-\\frac{e^{\\beta^Tx_i+b_i}}{1+e^{\\beta^Tx_i+b_i}})]+lnf_b(b_i|\\theta)\\}\\] \\[\\frac{\\partial lnf(Y|b, \\beta)}{\\partial \\beta}=X^{&#39;}(Y-E(Y|b))\\] \\[\\frac{\\partial lnf(Y|b, \\beta)}{\\partial \\beta \\partial \\beta^{&#39;}}=-X^{&#39;}(Y-E(Y|b))\\] \\[\\begin{aligned} \\nabla \\ell &amp;= \\sum_{i=1}^{n} [y_i \\frac{1}{p(\\beta ^T x_i+b_i)} \\frac{\\partial p(\\beta ^T x_i+b_i)}{\\partial (\\beta ^T x_i+b_i)}\\frac{\\partial (\\beta ^T x_i+b_i)}{\\partial \\beta}+(1-y_i) \\frac{1}{1-p(\\beta ^T x_i+b_i)}(-1)\\frac{\\partial p(\\beta ^T x_i+b_i)}{\\partial (\\beta ^T x_i+b_i)}\\frac{\\partial (\\beta ^T x_i+b_i)}{\\partial \\beta}] \\\\ &amp;=\\sum_{i=1}^{n} x_i^T[y_i-p(\\beta ^T x_i+b_i)] \\\\ &amp;= \\sum_{i=1}^{n} x_i^T[y_i-\\frac{e^{\\beta^Tx_i+b_i}}{1+e^{\\beta^Tx_i+b_i}}] \\end{aligned}\\] The Newton Raphson algorithm needs the second order. \\[\\begin{aligned} \\nabla^2 \\ell &amp;=\\frac{\\partial \\sum_{i=1}^{n} x_i^T[y_i-p(\\beta ^T x_i+b_i)]}{\\partial \\beta} \\\\ &amp;=-\\sum_{i=1}^{n} x_i^T\\frac{\\partial p(\\beta ^T x_i+b_i) }{\\partial \\beta}\\\\ &amp;=-\\sum_{i=1}^{n} x_i^T\\frac{\\partial p(\\beta ^T x_i+b_i) }{\\partial (\\beta^Tx_i+b_i)} \\frac{\\partial (\\beta^Tx_i+b_i)}{\\partial \\beta}\\\\ &amp;=-\\sum_{i=1}^{n} x_i^T p(\\beta ^T x_i+b_i)(1-p(\\beta ^T x_i+b_i))x_i \\\\ &amp;=-\\sum_{i=1}^{n} x_i^T \\frac{e^{\\beta^Tx_i+b_i}}{1+e^{\\beta^Tx_i+b_i}}(1-\\frac{e^{\\beta^Tx_i+b_i}}{1+e^{\\beta^Tx_i+b_i}})x_i \\end{aligned}\\] Using the Newton Raphson, the following code calculates the basic logistic model, without any random effects. As we can see, it produces the same result as the R generic function of GLM. Note that, the function of Expit and the variables of y and are from the last block of R code. x_intercept&lt;-rep(1,n) x_intercept&lt;-as.matrix(x_intercept) tolerance=1e-3 max_its=2000;iteration=1;difference=2 W&lt;-matrix(0,n,n) beta_old&lt;-0.4 while(difference&gt;tolerance &amp; iteration&lt;max_its) { # The first order f_firstorder&lt;-t(x_intercept)%*%(y-Expit(x_intercept%*%beta_old)) # The second order diag(W) = Expit(x_intercept%*%beta_old)*(1-Expit(x_intercept%*%beta_old)) f_secondorder&lt;--t(x_intercept)%*%W%*%x_intercept # Calculate the beta_updated beta_updated=beta_old-(solve(f_secondorder)%*%f_firstorder) difference=max(abs(beta_updated-beta_old)); iteration=iteration+1; beta_old=beta_updated} beta_old ## [,1] ## [1,] 1.643422 glm(y~1, family=binomial)$coefficients ## (Intercept) ## 1.643422 #install.packages(&quot;CVTuningCov&quot;) library(CVTuningCov) # Will be used to generate AR1 matrix set.seed(123) y&lt;-c(1,1,1,0,0,1,1,0,1,0) ## observations n=length(y) # the number of observations #Establish the exp function Expit&lt;-function(x){exp(x)/(1+exp(x))} #Y: observations #b: random effect #beta_0:fixed effect-&gt;intercept (or, mean of Y) log_pdf_function&lt;-function(Y,b,beta_0) {mean_prob&lt;-Expit(beta_0+b) dbinom(Y,1,mean_prob,log = TRUE) } b_records&lt;-rep(0,n) #Initial values for the random effect rho_records&lt;-0.5 #Initial value for rho sigma_recoards&lt;-2 #Initial value for sigma mean_0&lt;-0 # Initial mean value for normal distribution (of the random effect) beta&lt;-0.5 # Initial value for the intercept of Y f_random&lt;-function(sigma_recoards, rho_records,beta) { co_matrix&lt;-(sigma_recoards^2)*AR1(n,rho_records) # covariance matrix co_matrix_inverse&lt;-solve(co_matrix) # inverse covariance matrix for (k in 1:n) { # Variance for the random effect sd_0&lt;-1/(co_matrix_inverse[k,k]) for(j in 1:n) { # Make sure that k is not equal to j, otherwise 0 Q_kj&lt;-ifelse(j!=k,co_matrix_inverse[k,j],0) # Calculate the mean for the random effect; sum of mean in a loop mean_0&lt;-mean_0-(Q_kj/co_matrix_inverse[k,k])*b_records[j] } # Draw a random number from the normal distribution for the random effect b_candidate&lt;-rnorm(1,mean_0,sd_0) current_lp&lt;-log_pdf_function(y[k],b_records[k],beta) candidate_lp&lt;-log_pdf_function(y[k],b_candidate,beta) Smaller_value&lt;-min(exp(candidate_lp-current_lp),1) # Draw a random number from the uniform distribution Random_probability&lt;-runif(1) # Update b (i.e., random variable) b_records[k]&lt;-ifelse(Random_probability&lt;Smaller_value,b_candidate,b_records[k]) } return(b_records) } # Print result #b_records&lt;-f_random(1,0.8,0.3) In the following, I will try to add the random effect. x_intercept&lt;-rep(1,n) x_intercept&lt;-as.matrix(x_intercept) #We need to set random starting values. tolerance=1e-3 max_its=2000;iteration=1;difference=2 W&lt;-matrix(0,n,n) beta_old&lt;-0.4 while(difference&gt;tolerance &amp; iteration&lt;max_its) { b_records&lt;-f_random(2,0.9,beta_old) print(&quot;first&quot;) print(beta_old) print(b_records) # The first order f_firstorder&lt;-t(x_intercept)%*%(y-Expit(x_intercept%*%beta_old+b_records)) print(f_firstorder) # The second order diag(W) = Expit(x_intercept%*%beta_old+b_records)*(1-Expit(x_intercept%*%beta_old+b_records)) f_secondorder&lt;--t(x_intercept)%*%W%*%x_intercept # Calculate the beta_updated beta_updated=beta_old-(solve(f_secondorder)%*%f_firstorder) difference=max(abs(beta_updated-beta_old)); iteration=iteration+1; beta_old=beta_updated } beta_old 12.3 glmmTMB package # https://becarioprecario.bitbucket.io/inla-gitbook/ch-intro.html #https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html #install.packages(&quot;glmmTMB&quot;) library(glmmTMB) ## Warning: package &#39;glmmTMB&#39; was built under R version 3.6.2 ## Warning in checkMatrixPackageVersion(): Package version inconsistency detected. ## TMB was built with Matrix version 1.2.18 ## Current Matrix version is 1.2.17 ## Please re-install &#39;TMB&#39; from source using install.packages(&#39;TMB&#39;, type = &#39;source&#39;) or ask CRAN for a binary version of &#39;TMB&#39; matching CRAN&#39;s &#39;Matrix&#39; package times &lt;- factor(1:n) levels(times) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;10&quot; ## [11] &quot;11&quot; &quot;12&quot; &quot;13&quot; &quot;14&quot; &quot;15&quot; &quot;16&quot; &quot;17&quot; &quot;18&quot; &quot;19&quot; &quot;20&quot; ## [21] &quot;21&quot; &quot;22&quot; &quot;23&quot; &quot;24&quot; &quot;25&quot; &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; &quot;30&quot; ## [31] &quot;31&quot; &quot;32&quot; &quot;33&quot; &quot;34&quot; &quot;35&quot; &quot;36&quot; &quot;37&quot; &quot;38&quot; &quot;39&quot; &quot;40&quot; ## [41] &quot;41&quot; &quot;42&quot; &quot;43&quot; &quot;44&quot; &quot;45&quot; &quot;46&quot; &quot;47&quot; &quot;48&quot; &quot;49&quot; &quot;50&quot; ## [51] &quot;51&quot; &quot;52&quot; &quot;53&quot; &quot;54&quot; &quot;55&quot; &quot;56&quot; &quot;57&quot; &quot;58&quot; &quot;59&quot; &quot;60&quot; ## [61] &quot;61&quot; &quot;62&quot; &quot;63&quot; &quot;64&quot; &quot;65&quot; &quot;66&quot; &quot;67&quot; &quot;68&quot; &quot;69&quot; &quot;70&quot; ## [71] &quot;71&quot; &quot;72&quot; &quot;73&quot; &quot;74&quot; &quot;75&quot; &quot;76&quot; &quot;77&quot; &quot;78&quot; &quot;79&quot; &quot;80&quot; ## [81] &quot;81&quot; &quot;82&quot; &quot;83&quot; &quot;84&quot; &quot;85&quot; &quot;86&quot; &quot;87&quot; &quot;88&quot; &quot;89&quot; &quot;90&quot; ## [91] &quot;91&quot; &quot;92&quot; &quot;93&quot; &quot;94&quot; &quot;95&quot; &quot;96&quot; &quot;97&quot; &quot;98&quot; &quot;99&quot; &quot;100&quot; ## [101] &quot;101&quot; &quot;102&quot; &quot;103&quot; &quot;104&quot; &quot;105&quot; &quot;106&quot; &quot;107&quot; &quot;108&quot; &quot;109&quot; &quot;110&quot; ## [111] &quot;111&quot; &quot;112&quot; &quot;113&quot; &quot;114&quot; &quot;115&quot; &quot;116&quot; &quot;117&quot; &quot;118&quot; &quot;119&quot; &quot;120&quot; ## [121] &quot;121&quot; &quot;122&quot; &quot;123&quot; &quot;124&quot; &quot;125&quot; &quot;126&quot; &quot;127&quot; &quot;128&quot; &quot;129&quot; &quot;130&quot; ## [131] &quot;131&quot; &quot;132&quot; &quot;133&quot; &quot;134&quot; &quot;135&quot; &quot;136&quot; &quot;137&quot; &quot;138&quot; &quot;139&quot; &quot;140&quot; ## [141] &quot;141&quot; &quot;142&quot; &quot;143&quot; &quot;144&quot; &quot;145&quot; &quot;146&quot; &quot;147&quot; &quot;148&quot; &quot;149&quot; &quot;150&quot; ## [151] &quot;151&quot; &quot;152&quot; &quot;153&quot; &quot;154&quot; &quot;155&quot; &quot;156&quot; &quot;157&quot; &quot;158&quot; &quot;159&quot; &quot;160&quot; ## [161] &quot;161&quot; &quot;162&quot; &quot;163&quot; &quot;164&quot; &quot;165&quot; &quot;166&quot; &quot;167&quot; &quot;168&quot; &quot;169&quot; &quot;170&quot; ## [171] &quot;171&quot; &quot;172&quot; &quot;173&quot; &quot;174&quot; &quot;175&quot; &quot;176&quot; &quot;177&quot; &quot;178&quot; &quot;179&quot; &quot;180&quot; ## [181] &quot;181&quot; &quot;182&quot; &quot;183&quot; &quot;184&quot; &quot;185&quot; &quot;186&quot; &quot;187&quot; &quot;188&quot; &quot;189&quot; &quot;190&quot; ## [191] &quot;191&quot; &quot;192&quot; &quot;193&quot; &quot;194&quot; &quot;195&quot; &quot;196&quot; &quot;197&quot; &quot;198&quot; &quot;199&quot; &quot;200&quot; ## [201] &quot;201&quot; &quot;202&quot; &quot;203&quot; &quot;204&quot; &quot;205&quot; &quot;206&quot; &quot;207&quot; &quot;208&quot; &quot;209&quot; &quot;210&quot; ## [211] &quot;211&quot; &quot;212&quot; &quot;213&quot; &quot;214&quot; &quot;215&quot; &quot;216&quot; &quot;217&quot; &quot;218&quot; &quot;219&quot; &quot;220&quot; ## [221] &quot;221&quot; &quot;222&quot; &quot;223&quot; &quot;224&quot; &quot;225&quot; &quot;226&quot; &quot;227&quot; &quot;228&quot; &quot;229&quot; &quot;230&quot; ## [231] &quot;231&quot; &quot;232&quot; &quot;233&quot; &quot;234&quot; &quot;235&quot; &quot;236&quot; &quot;237&quot; &quot;238&quot; &quot;239&quot; &quot;240&quot; ## [241] &quot;241&quot; &quot;242&quot; &quot;243&quot; &quot;244&quot; &quot;245&quot; &quot;246&quot; &quot;247&quot; &quot;248&quot; &quot;249&quot; &quot;250&quot; ## [251] &quot;251&quot; &quot;252&quot; &quot;253&quot; &quot;254&quot; &quot;255&quot; &quot;256&quot; &quot;257&quot; &quot;258&quot; &quot;259&quot; &quot;260&quot; ## [261] &quot;261&quot; &quot;262&quot; &quot;263&quot; &quot;264&quot; &quot;265&quot; &quot;266&quot; &quot;267&quot; &quot;268&quot; &quot;269&quot; &quot;270&quot; ## [271] &quot;271&quot; &quot;272&quot; &quot;273&quot; &quot;274&quot; &quot;275&quot; &quot;276&quot; &quot;277&quot; &quot;278&quot; &quot;279&quot; &quot;280&quot; ## [281] &quot;281&quot; &quot;282&quot; &quot;283&quot; &quot;284&quot; &quot;285&quot; &quot;286&quot; &quot;287&quot; &quot;288&quot; &quot;289&quot; &quot;290&quot; ## [291] &quot;291&quot; &quot;292&quot; &quot;293&quot; &quot;294&quot; &quot;295&quot; &quot;296&quot; &quot;297&quot; &quot;298&quot; &quot;299&quot; &quot;300&quot; ## [301] &quot;301&quot; &quot;302&quot; &quot;303&quot; &quot;304&quot; &quot;305&quot; &quot;306&quot; &quot;307&quot; &quot;308&quot; &quot;309&quot; &quot;310&quot; ## [311] &quot;311&quot; &quot;312&quot; &quot;313&quot; &quot;314&quot; &quot;315&quot; &quot;316&quot; &quot;317&quot; &quot;318&quot; &quot;319&quot; &quot;320&quot; ## [321] &quot;321&quot; &quot;322&quot; &quot;323&quot; &quot;324&quot; &quot;325&quot; &quot;326&quot; &quot;327&quot; &quot;328&quot; &quot;329&quot; &quot;330&quot; ## [331] &quot;331&quot; &quot;332&quot; &quot;333&quot; &quot;334&quot; &quot;335&quot; &quot;336&quot; &quot;337&quot; &quot;338&quot; &quot;339&quot; &quot;340&quot; ## [341] &quot;341&quot; &quot;342&quot; &quot;343&quot; &quot;344&quot; &quot;345&quot; &quot;346&quot; &quot;347&quot; &quot;348&quot; &quot;349&quot; &quot;350&quot; ## [351] &quot;351&quot; &quot;352&quot; &quot;353&quot; &quot;354&quot; &quot;355&quot; &quot;356&quot; &quot;357&quot; &quot;358&quot; &quot;359&quot; &quot;360&quot; ## [361] &quot;361&quot; &quot;362&quot; &quot;363&quot; &quot;364&quot; &quot;365&quot; &quot;366&quot; &quot;367&quot; &quot;368&quot; &quot;369&quot; &quot;370&quot; ## [371] &quot;371&quot; &quot;372&quot; &quot;373&quot; &quot;374&quot; &quot;375&quot; &quot;376&quot; &quot;377&quot; &quot;378&quot; &quot;379&quot; &quot;380&quot; ## [381] &quot;381&quot; &quot;382&quot; &quot;383&quot; &quot;384&quot; &quot;385&quot; &quot;386&quot; &quot;387&quot; &quot;388&quot; &quot;389&quot; &quot;390&quot; ## [391] &quot;391&quot; &quot;392&quot; &quot;393&quot; &quot;394&quot; &quot;395&quot; &quot;396&quot; &quot;397&quot; &quot;398&quot; &quot;399&quot; &quot;400&quot; ## [401] &quot;401&quot; &quot;402&quot; &quot;403&quot; &quot;404&quot; &quot;405&quot; &quot;406&quot; &quot;407&quot; &quot;408&quot; &quot;409&quot; &quot;410&quot; ## [411] &quot;411&quot; &quot;412&quot; &quot;413&quot; &quot;414&quot; &quot;415&quot; &quot;416&quot; &quot;417&quot; &quot;418&quot; &quot;419&quot; &quot;420&quot; ## [421] &quot;421&quot; &quot;422&quot; &quot;423&quot; &quot;424&quot; &quot;425&quot; &quot;426&quot; &quot;427&quot; &quot;428&quot; &quot;429&quot; &quot;430&quot; ## [431] &quot;431&quot; &quot;432&quot; &quot;433&quot; &quot;434&quot; &quot;435&quot; &quot;436&quot; &quot;437&quot; &quot;438&quot; &quot;439&quot; &quot;440&quot; ## [441] &quot;441&quot; &quot;442&quot; &quot;443&quot; &quot;444&quot; &quot;445&quot; &quot;446&quot; &quot;447&quot; &quot;448&quot; &quot;449&quot; &quot;450&quot; ## [451] &quot;451&quot; &quot;452&quot; &quot;453&quot; &quot;454&quot; &quot;455&quot; &quot;456&quot; &quot;457&quot; &quot;458&quot; &quot;459&quot; &quot;460&quot; ## [461] &quot;461&quot; &quot;462&quot; &quot;463&quot; &quot;464&quot; &quot;465&quot; &quot;466&quot; &quot;467&quot; &quot;468&quot; &quot;469&quot; &quot;470&quot; ## [471] &quot;471&quot; &quot;472&quot; &quot;473&quot; &quot;474&quot; &quot;475&quot; &quot;476&quot; &quot;477&quot; &quot;478&quot; &quot;479&quot; &quot;480&quot; ## [481] &quot;481&quot; &quot;482&quot; &quot;483&quot; &quot;484&quot; &quot;485&quot; &quot;486&quot; &quot;487&quot; &quot;488&quot; &quot;489&quot; &quot;490&quot; ## [491] &quot;491&quot; &quot;492&quot; &quot;493&quot; &quot;494&quot; &quot;495&quot; &quot;496&quot; &quot;497&quot; &quot;498&quot; &quot;499&quot; &quot;500&quot; ## [501] &quot;501&quot; &quot;502&quot; &quot;503&quot; &quot;504&quot; &quot;505&quot; &quot;506&quot; &quot;507&quot; &quot;508&quot; &quot;509&quot; &quot;510&quot; ## [511] &quot;511&quot; &quot;512&quot; &quot;513&quot; &quot;514&quot; &quot;515&quot; &quot;516&quot; &quot;517&quot; &quot;518&quot; &quot;519&quot; &quot;520&quot; ## [521] &quot;521&quot; &quot;522&quot; &quot;523&quot; &quot;524&quot; &quot;525&quot; &quot;526&quot; &quot;527&quot; &quot;528&quot; &quot;529&quot; &quot;530&quot; ## [531] &quot;531&quot; &quot;532&quot; &quot;533&quot; &quot;534&quot; &quot;535&quot; &quot;536&quot; &quot;537&quot; &quot;538&quot; &quot;539&quot; &quot;540&quot; ## [541] &quot;541&quot; &quot;542&quot; &quot;543&quot; &quot;544&quot; &quot;545&quot; &quot;546&quot; &quot;547&quot; &quot;548&quot; &quot;549&quot; &quot;550&quot; ## [551] &quot;551&quot; &quot;552&quot; &quot;553&quot; &quot;554&quot; &quot;555&quot; &quot;556&quot; &quot;557&quot; &quot;558&quot; &quot;559&quot; &quot;560&quot; ## [561] &quot;561&quot; &quot;562&quot; &quot;563&quot; &quot;564&quot; &quot;565&quot; &quot;566&quot; &quot;567&quot; &quot;568&quot; &quot;569&quot; &quot;570&quot; ## [571] &quot;571&quot; &quot;572&quot; &quot;573&quot; &quot;574&quot; &quot;575&quot; &quot;576&quot; &quot;577&quot; &quot;578&quot; &quot;579&quot; &quot;580&quot; ## [581] &quot;581&quot; &quot;582&quot; &quot;583&quot; &quot;584&quot; &quot;585&quot; &quot;586&quot; &quot;587&quot; &quot;588&quot; &quot;589&quot; &quot;590&quot; ## [591] &quot;591&quot; &quot;592&quot; &quot;593&quot; &quot;594&quot; &quot;595&quot; &quot;596&quot; &quot;597&quot; &quot;598&quot; &quot;599&quot; &quot;600&quot; ## [601] &quot;601&quot; &quot;602&quot; &quot;603&quot; &quot;604&quot; &quot;605&quot; &quot;606&quot; &quot;607&quot; &quot;608&quot; &quot;609&quot; &quot;610&quot; ## [611] &quot;611&quot; &quot;612&quot; &quot;613&quot; &quot;614&quot; &quot;615&quot; &quot;616&quot; &quot;617&quot; &quot;618&quot; &quot;619&quot; &quot;620&quot; ## [621] &quot;621&quot; &quot;622&quot; &quot;623&quot; &quot;624&quot; &quot;625&quot; &quot;626&quot; &quot;627&quot; &quot;628&quot; &quot;629&quot; &quot;630&quot; ## [631] &quot;631&quot; &quot;632&quot; &quot;633&quot; &quot;634&quot; &quot;635&quot; &quot;636&quot; &quot;637&quot; &quot;638&quot; &quot;639&quot; &quot;640&quot; ## [641] &quot;641&quot; &quot;642&quot; &quot;643&quot; &quot;644&quot; &quot;645&quot; &quot;646&quot; &quot;647&quot; &quot;648&quot; &quot;649&quot; &quot;650&quot; ## [651] &quot;651&quot; &quot;652&quot; &quot;653&quot; &quot;654&quot; &quot;655&quot; &quot;656&quot; &quot;657&quot; &quot;658&quot; &quot;659&quot; &quot;660&quot; ## [661] &quot;661&quot; &quot;662&quot; &quot;663&quot; &quot;664&quot; &quot;665&quot; &quot;666&quot; &quot;667&quot; &quot;668&quot; &quot;669&quot; &quot;670&quot; ## [671] &quot;671&quot; &quot;672&quot; &quot;673&quot; &quot;674&quot; &quot;675&quot; &quot;676&quot; &quot;677&quot; &quot;678&quot; &quot;679&quot; &quot;680&quot; ## [681] &quot;681&quot; &quot;682&quot; &quot;683&quot; &quot;684&quot; &quot;685&quot; &quot;686&quot; &quot;687&quot; &quot;688&quot; &quot;689&quot; &quot;690&quot; ## [691] &quot;691&quot; &quot;692&quot; &quot;693&quot; &quot;694&quot; &quot;695&quot; &quot;696&quot; &quot;697&quot; &quot;698&quot; &quot;699&quot; &quot;700&quot; ## [701] &quot;701&quot; &quot;702&quot; &quot;703&quot; &quot;704&quot; &quot;705&quot; &quot;706&quot; &quot;707&quot; &quot;708&quot; &quot;709&quot; &quot;710&quot; ## [711] &quot;711&quot; &quot;712&quot; &quot;713&quot; &quot;714&quot; &quot;715&quot; &quot;716&quot; &quot;717&quot; &quot;718&quot; &quot;719&quot; &quot;720&quot; ## [721] &quot;721&quot; &quot;722&quot; &quot;723&quot; &quot;724&quot; &quot;725&quot; &quot;726&quot; &quot;727&quot; &quot;728&quot; &quot;729&quot; &quot;730&quot; ## [731] &quot;731&quot; &quot;732&quot; &quot;733&quot; &quot;734&quot; &quot;735&quot; &quot;736&quot; &quot;737&quot; &quot;738&quot; &quot;739&quot; &quot;740&quot; ## [741] &quot;741&quot; &quot;742&quot; &quot;743&quot; &quot;744&quot; &quot;745&quot; &quot;746&quot; &quot;747&quot; &quot;748&quot; &quot;749&quot; &quot;750&quot; ## [751] &quot;751&quot; &quot;752&quot; &quot;753&quot; &quot;754&quot; &quot;755&quot; &quot;756&quot; &quot;757&quot; &quot;758&quot; &quot;759&quot; &quot;760&quot; ## [761] &quot;761&quot; &quot;762&quot; &quot;763&quot; &quot;764&quot; &quot;765&quot; &quot;766&quot; &quot;767&quot; &quot;768&quot; &quot;769&quot; &quot;770&quot; ## [771] &quot;771&quot; &quot;772&quot; &quot;773&quot; &quot;774&quot; &quot;775&quot; &quot;776&quot; &quot;777&quot; &quot;778&quot; &quot;779&quot; &quot;780&quot; ## [781] &quot;781&quot; &quot;782&quot; &quot;783&quot; &quot;784&quot; &quot;785&quot; &quot;786&quot; &quot;787&quot; &quot;788&quot; &quot;789&quot; &quot;790&quot; ## [791] &quot;791&quot; &quot;792&quot; &quot;793&quot; &quot;794&quot; &quot;795&quot; &quot;796&quot; &quot;797&quot; &quot;798&quot; &quot;799&quot; &quot;800&quot; ## [801] &quot;801&quot; &quot;802&quot; &quot;803&quot; &quot;804&quot; &quot;805&quot; &quot;806&quot; &quot;807&quot; &quot;808&quot; &quot;809&quot; &quot;810&quot; ## [811] &quot;811&quot; &quot;812&quot; &quot;813&quot; &quot;814&quot; &quot;815&quot; &quot;816&quot; &quot;817&quot; &quot;818&quot; &quot;819&quot; &quot;820&quot; ## [821] &quot;821&quot; &quot;822&quot; &quot;823&quot; &quot;824&quot; &quot;825&quot; &quot;826&quot; &quot;827&quot; &quot;828&quot; &quot;829&quot; &quot;830&quot; ## [831] &quot;831&quot; &quot;832&quot; &quot;833&quot; &quot;834&quot; &quot;835&quot; &quot;836&quot; &quot;837&quot; &quot;838&quot; &quot;839&quot; &quot;840&quot; ## [841] &quot;841&quot; &quot;842&quot; &quot;843&quot; &quot;844&quot; &quot;845&quot; &quot;846&quot; &quot;847&quot; &quot;848&quot; &quot;849&quot; &quot;850&quot; ## [851] &quot;851&quot; &quot;852&quot; &quot;853&quot; &quot;854&quot; &quot;855&quot; &quot;856&quot; &quot;857&quot; &quot;858&quot; &quot;859&quot; &quot;860&quot; ## [861] &quot;861&quot; &quot;862&quot; &quot;863&quot; &quot;864&quot; &quot;865&quot; &quot;866&quot; &quot;867&quot; &quot;868&quot; &quot;869&quot; &quot;870&quot; ## [871] &quot;871&quot; &quot;872&quot; &quot;873&quot; &quot;874&quot; &quot;875&quot; &quot;876&quot; &quot;877&quot; &quot;878&quot; &quot;879&quot; &quot;880&quot; ## [881] &quot;881&quot; &quot;882&quot; &quot;883&quot; &quot;884&quot; &quot;885&quot; &quot;886&quot; &quot;887&quot; &quot;888&quot; &quot;889&quot; &quot;890&quot; ## [891] &quot;891&quot; &quot;892&quot; &quot;893&quot; &quot;894&quot; &quot;895&quot; &quot;896&quot; &quot;897&quot; &quot;898&quot; &quot;899&quot; &quot;900&quot; ## [901] &quot;901&quot; &quot;902&quot; &quot;903&quot; &quot;904&quot; &quot;905&quot; &quot;906&quot; &quot;907&quot; &quot;908&quot; &quot;909&quot; &quot;910&quot; ## [911] &quot;911&quot; &quot;912&quot; &quot;913&quot; &quot;914&quot; &quot;915&quot; &quot;916&quot; &quot;917&quot; &quot;918&quot; &quot;919&quot; &quot;920&quot; ## [921] &quot;921&quot; &quot;922&quot; &quot;923&quot; &quot;924&quot; &quot;925&quot; &quot;926&quot; &quot;927&quot; &quot;928&quot; &quot;929&quot; &quot;930&quot; ## [931] &quot;931&quot; &quot;932&quot; &quot;933&quot; &quot;934&quot; &quot;935&quot; &quot;936&quot; &quot;937&quot; &quot;938&quot; &quot;939&quot; &quot;940&quot; ## [941] &quot;941&quot; &quot;942&quot; &quot;943&quot; &quot;944&quot; &quot;945&quot; &quot;946&quot; &quot;947&quot; &quot;948&quot; &quot;949&quot; &quot;950&quot; ## [951] &quot;951&quot; &quot;952&quot; &quot;953&quot; &quot;954&quot; &quot;955&quot; &quot;956&quot; &quot;957&quot; &quot;958&quot; &quot;959&quot; &quot;960&quot; ## [961] &quot;961&quot; &quot;962&quot; &quot;963&quot; &quot;964&quot; &quot;965&quot; &quot;966&quot; &quot;967&quot; &quot;968&quot; &quot;969&quot; &quot;970&quot; ## [971] &quot;971&quot; &quot;972&quot; &quot;973&quot; &quot;974&quot; &quot;975&quot; &quot;976&quot; &quot;977&quot; &quot;978&quot; &quot;979&quot; &quot;980&quot; ## [981] &quot;981&quot; &quot;982&quot; &quot;983&quot; &quot;984&quot; &quot;985&quot; &quot;986&quot; &quot;987&quot; &quot;988&quot; &quot;989&quot; &quot;990&quot; ## [991] &quot;991&quot; &quot;992&quot; &quot;993&quot; &quot;994&quot; &quot;995&quot; &quot;996&quot; &quot;997&quot; &quot;998&quot; &quot;999&quot; &quot;1000&quot; group &lt;- factor(rep(1,n)) dat0 &lt;- data.frame(y,times,group) glmmTMB(y ~ ar1(times + 0 | group), data=dat0) ## Formula: y ~ ar1(times + 0 | group) ## Data: dat0 ## AIC BIC logLik df.resid ## 843.4275 863.0585 -417.7138 996 ## Random-effects (co)variances: ## ## Conditional model: ## Groups Name Std.Dev. Corr ## group times1 0.1833 0.29 (ar1) ## Residual 0.3196 ## ## Number of obs: 1000 / Conditional model: group, 1 ## ## Dispersion estimate for gaussian family (sigma^2): 0.102 ## ## Fixed Effects: ## ## Conditional model: ## (Intercept) ## 0.8379 "]
]
